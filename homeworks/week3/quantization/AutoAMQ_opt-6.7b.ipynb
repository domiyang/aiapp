{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_D9kG_efts3"
   },
   "source": [
    "# Quantization with AutoAMQ for opt-6.7b\n",
    "\n",
    "```\n",
    "第三周作业一: \n",
    "1、使用 GPTQ 量化 OPT-6.7B 模型。课程代码（ https://github.com/DjangoPeng/LLM-quickstart/blob/main/quantization/AutoGPTQ_opt-2.7b.ipynb ）\n",
    "2、使用 AWQ 量化 Facebook OPT-6.7B 模型。Facebook OPT 模型地址： https://huggingface.co/facebook?search_models=opt\n",
    "课程代码： https://github.com/DjangoPeng/LLM-quickstart/blob/main/quantization/AWQ_opt-2.7b.ipynb\n",
    "https://github.com/DjangoPeng/LLM-quickstart/blob/main/quantization/AWQ-opt-125m.ipynb ------> this notebook is for this task.\n",
    "\n",
    "第三周作业二： 根据硬件资源情况，在 AdvertiseGen 数据集上使用 QLoRA 微调 ChatGLM3-6B 至少 10K examples，观察 Loss 变化情况，并对比微调前后模型输出结果。\n",
    "课程代码： \n",
    "https://github.com/DjangoPeng/LLM-quickstart/blob/main/peft/peft_qlora_chatglm.ipynb\n",
    "https://github.com/DjangoPeng/LLM-quickstart/blob/main/peft/peft_chatglm_inference.ipynb\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468,
     "referenced_widgets": [
      "1880cdb18a7d438b8f76a2cf9d71b061",
      "3bc570100f374fca872d5f82ecb37c7c",
      "d68ff07b13044cd399d4982e6cb0e069",
      "86b65ec3d9054ff881a0110b3d07ce69",
      "a2712a9a39994d90989dea9cb0b5c549",
      "e6d6441389194757b047883c82795285",
      "5134b285e9d74fe394de3b0df4378a24",
      "6752ba954639416e94281eb3153d5ce6",
      "d281d0eee6fc47bf8ffae0a65b2844ef",
      "726e065027fe4692afc636472cc25a53",
      "1b9052ea55544078b369a88abe942a17",
      "d1f4c0fb1c8e44378a0e330d7aaf9b82",
      "2e6da10e20044181a102ec0509395075",
      "6f6780be37554de486ad2aa0c1079d08",
      "71c3a1a84487461bb16140e140f831a0",
      "92d77b8cdda142edb18e7925823f135b",
      "4f6f0bae65914ab69764932a811cdff1",
      "81a48c0fbbc548408a06eee2bb15cd98",
      "a9f229101e6a49eda5a2ecc62145781d",
      "181c67b7ca484b98a978630affcb7ddf",
      "f4292ce6c4f24dcb87be0b51935df8a2",
      "822286c9eb8d4cf1ae0200636cf015e5",
      "2ef116f4253e417fb461df6b79184692",
      "0326aff6a1854b35b0ad92f6836e7792",
      "b898db732a6d4f6a9001862c6d54fa45",
      "8970a6f89004494a9d9b7fe0c26e8b3d",
      "dae852e6cb354003a1a09d49ea19be71",
      "18338d52e9f2491b9820d531c8a410a1",
      "5989e3e43e204120a4073284986b4789",
      "b24d7b14fe6b482e9d2a36c123d73c1d",
      "e1c6b64a39ae422eb350fdee2cb79d68",
      "8e418b79775141c6839ec7ce366eede6",
      "ae6019d6385745978e18d3df6899ca75",
      "f4efacc1846545afa43850b3b9a0c701",
      "3a803fa0c5a94f3c9a7481603c024cbf",
      "d980cdfae6e5407c92c78d670f527dbf",
      "ab0d119687824938b0d5b6b5207806b2",
      "b3403daded6a4d37823d8ad758acca57",
      "590144bdfd824514b8603e50c00aa1d0",
      "ad530f96f2504ff5b8f14026d1cc34f9",
      "dbe1daa0ba564c189e6479d15166559e",
      "311246c2547548aead7033adec0cbd64",
      "132668df180e4ddf86fc23f19cdf913c",
      "5194d9be91eb45a2988eb17dffeb27b9",
      "cbc2319120e74be38cd38301a59e0ea5",
      "33874bd1cce04305b75ad9044f08dc4d",
      "cddef3367b62419abd4b7ae138d0d618",
      "7ead5371f54549f5819901ea2c262bac",
      "3fe09d88876d425db9c6c1706e76dc12",
      "dfdc242b63574f2eb0cc2370e441545e",
      "e21e50fd996549e79f3e630ac8abd9fe",
      "577bb7b27be04a47ab22bceec7ebe41b",
      "c0c02663859d49a59a927dad1c02fc89",
      "00ac2a926c0c460fa643e157b254b649",
      "9853c963f7de43f1a8840b7f6405e972",
      "8b7f95359d284c349bf2577a18c015cf",
      "2a6f4e0b10c84365a9ceb8478197aa94",
      "b50ad1c48bdb444f936bf6eb9ef16f32",
      "fc8549f4ce2d44679d71702c6c6831c1",
      "fe3730f721c1441897b0a8e1f1e82764",
      "392786affd2441a3b5e8f274eb0c903a",
      "2f06776b9fe647b28f3dd67734d0fa4b",
      "77aaa5569c2344f4844fdad5ce90f8a9",
      "16edfc3a246540b8a547a1f9ce51c0d1",
      "81d3c059e19341a5a120657ffdf1fc28",
      "375445fc761e44ccb33779e9ec60fe71",
      "4f81d19cb86849d59dfaebfbe2a10eea",
      "85dbd059e38343fbb38bf36006f3c9e1",
      "d2440685af434c9d927e9d810a6b423c",
      "6229c5c5d6184bc3b2af59edb4ee5599",
      "72bfadacbf154af0a637450035c65c42",
      "ecd42cbb519b4dfc8013dd72897b62c2",
      "4a673ed256864c3c82c4392cb7b6b261",
      "a69497b9c323430fae0b179d742993e1",
      "12f851dee22d4bffae5ae2c1126ec291",
      "369230435faf4320b05862e330cd2742",
      "c986acc6b50d4f4a9d27ee24e405e0d9",
      "566f2b9b1bef400d8f40f7498b3df8af",
      "fa5eebfd4c6a44f4abc6c171b3bdb4bf",
      "609349a1c50346b7955da961d0f4a9ab",
      "ead76ed1e47b47b38d015e58791e87cf",
      "c922bbbeed854f3fbbf3e324b0725bfe",
      "28ec0d5c26e24b0ba4d6ffb7222d7040",
      "bb382755558f41b8ac6b83d47dc0c06f",
      "a8a6b5b41d85461c8aaa7e7035dea8a3",
      "b9921b8bfbae426aba2bf658d3c5a5ff",
      "7f75ae4dd3164387b6128dcad4d8619b",
      "2b4f2f4516f04bb3b6a4f3aea71fdfac",
      "c7f13e84feaf44d694f70395a1fed7b3",
      "bbefcb7d560245f0b945741bb059d9e2",
      "8fefab0d44ab459ba870b91088901cc3",
      "ea42b0c8afba43ef83952ff1275357bc",
      "7257323c093d4aecad16b1c73963d99d",
      "be07ced9b72d417c9ef860f05205819d",
      "8cfb78d32c9d495384a37f2adad4f214",
      "c8c62f2212524da5ad8d15120a5994af",
      "720906051c7d4ba9be711d4dd265a237",
      "e0f9e91b03e641358461f2d910d2ffcc",
      "b41570ee27f14e0bad1364f5176976ea",
      "ff74dc2286464c7b8884c4702bdae74a",
      "5a54f4b13eb94d01bd769c5d48c94729",
      "cf9710af4c6c44e6bede27461724e6d2",
      "8c3a3257917a4c32b310146a447a7c54",
      "7df99f335e634352a6960e0966b57696",
      "8fe1cfba38a34a3d99b23d05cdd181d3",
      "cb18da2d2b8c41f1823b1689a8962179",
      "5a5ac3f8776f4372925fe601c63be684",
      "ec5b09e8599444e6ae9b22654f479f83",
      "f0f405585d184647afe9faf9a8f12bdc",
      "9cff1286ba114ac195600f89142c38f8",
      "af41858510eb478d8d9c69f8947c5261",
      "dcbc3809225c4c9485b5b680281a727f",
      "34e740eb3dd549d988d0b8c704f221d1",
      "d6ba78ca0f6f4e97b924b67d6da365db",
      "2fe019ca9a944f5fb73da1dd82c5579a",
      "b22a80bb6ed54aa988dfabc09c164794",
      "221f1d6f10774d5397ae21ecba375e99",
      "4c833e48ebc7486aa922e4b67782df18",
      "f82cf57aa6a74e8f85c233c63510588a",
      "ab73fb1b09904e389025fdc764830e24",
      "1e9b517d49354f3c8b722413267d9ba1",
      "c9ab1ea09ddc45db9c649bb0db4d4f4b",
      "2dec347917aa43a4af74869cb0d0751b",
      "526735fa31114c58b4e03f4648c59988",
      "9f4d37d31cc24e13a88548be94cb8dd5",
      "3a9d93fccc554551a5339936ff37f4f7",
      "5dbc8d8b58a7451aa442923587113e27",
      "381f6d6fc4e14b639d848c2321df9aea",
      "07cd986bd7bf4b2e91df6361df5e8cd2",
      "1c590dd7fd2d4b87a02e56a73e8c6cd2",
      "af8fb5b3924f4a148309b262fb31bcc5",
      "0e9bf4e276674429be46e818d6291a87",
      "097f3a4779a74e3180f66560b0347538",
      "f48fa46b4275460eb8c9092a9797ab2a",
      "ef0792efd8b64317b2cbf0e6c2504306",
      "39ae5f7f27204a6b9fcda0b716998417",
      "5cd2d916a67742b28be710135bdbe3fa",
      "0e1b96fb7a08458e801c3b162789b5bb",
      "6647de8a3df94a278d108144c64d969e",
      "286cb3c79d8747b9b1e5de3ab1aff4d5",
      "95080788a5424cd597e2c5c204535ff0",
      "891a9558c5804916a033fee94d06599c",
      "b49e5c81472d4aa895799d70890d61b6",
      "0f5c4ef239d44c02a9c1c53117c12fbc",
      "c2ce4fb2bea342b6b02635d1adc63b96",
      "ca2cdea1d81f4671ad2d4d0a1147f931",
      "f6bb7d77160b481d939c9faa21f61f49",
      "497b8e88c1534c879166fc1b0ecb4184",
      "77cfbcec7a39470ab8d142cd67dcc676",
      "bd159193f35e43aca8ad6244c497ac44",
      "c2028ebe67824dee9932c196679c6920",
      "2a121a81a37943bf99d3cd92e961cedc",
      "9876d27262c6400b88416dd43f3f6c4f",
      "8f4991db20864f48aa025c0f75b4b621",
      "17a4f65808b94b7cb637a4ddddd227e5",
      "c352f759377b4a8ca3bad246dc1a2dca",
      "598e4fa641ec491ebb5f26122ada5d6b",
      "6736dd8ceb3b4aca9ab0b938614f9075",
      "f68b5eead14e4b3a811afc3cb9f57ed8",
      "80952a605cc0468b9e6fb429ed299539",
      "5cf71707e6384f36a8dc8856e6c7b39c",
      "f0be42152fe743efafef518a061aba25",
      "545ab0836c0a43b5b5745f23ff798958",
      "f4494dd20e43415a8016b0fdeb242cff",
      "7956965b0d234142a07f2c1335f19428",
      "6388485b85b241d6839a1addc0004d81",
      "3beeabc17cdd4d30b1c1384d3ff23e7b",
      "d4a027ebea7c425c86f51e1bb55926c5",
      "0aa92a076cac40f7bc17a72490455968",
      "5530b0a841fe4820845e48558fdb994a",
      "249ec68bb4a34a1299dfbf2bc00d3813",
      "0323969428f04db7bb8df5a44b2020e5",
      "dda41887c13d445289fe0068bc640545",
      "830d39cf23b14b538282da200adfc71a",
      "1bc543af85e440649fa963bcb5083b55",
      "4c5d443d664b473faea1c8098d1e8ce3",
      "31518489c13b4039a9fc03ca0fffa933",
      "65da4d3df6c44299b97a7cefc137d2ef",
      "68da191926d44c60bf7e91f253c97ab9",
      "79f62289aeaa45ad9241e5046970a56a",
      "b058e34960e941e3aebc8f61b1fd5cda",
      "ceafeec551f543039d7d1d953c2d54d4",
      "87b19fdbd10147638fc14c91f14403b9",
      "12cb229b02ed443da4305af5f1742531",
      "1f44c06e2aa44422a542c3a608b45808",
      "ba269ea147324c7c9ee419e2d99045bf",
      "5d47b0910292477fb9f10462d1fa831b",
      "235090a2c98c4a9484f4988cf7f003f5",
      "38b6d0e2c6db4feabee91af07a88ec3c",
      "a31e6da7013643c48a7225726313fa55",
      "1a2818686dd44374a54f3aaf439e37b3",
      "c314f57a0b0b451aad29e9fbde5385e1",
      "946f1b4aff26458493e270bbb4136d75",
      "cbc18ed207314bfabfa9cccc975c146f",
      "4d2c30c3d9c14ccaba8434993e049c97",
      "bce94beb47834bcea253a6b5bf12b435",
      "c59bdca7575d4c9d9b1cb4f80dc130a7",
      "a39c7540f3ca44aeac2e7484579588b0",
      "2b4c09e0dae64e76b7b9b47d2d382b25",
      "3358d452584644e6b6bb31c52f7c5371",
      "93016a890b3d43c583a1927d1e59f2a2",
      "0fbd48759430447fb4ab05fb0d7467a6",
      "13511c3ee3364f2e9d94621f20ca7328",
      "c6fb60096ed9409cacbce03d86eced11",
      "f031d1805c76486f82a9d0f8e6a1aa9f",
      "4240fd28cec94147aedeae6ac48cf50b",
      "814d245033494cd4b96829fb130bd3e0",
      "94ca2181c5a844f9b0002a12cf8c02d1",
      "2a22739f4d2148fcb70a137ec7f3702b",
      "dff3485601944cc1a4956708ba5288e9",
      "f3416ca9de19408abed068da001dba95",
      "4a7bf23d815b4e478ba8667214f7dccc",
      "a5dbede577d14b94a9d26aff86c8ce2e",
      "888a1231ca4c47f89008113d36712390",
      "2bc16b4e785644d88c7325ac1f4dcf4e",
      "612bd4ef0b75466badfa63654d017eec",
      "f54145d621cd4df8be0e80da4dac13bb",
      "35f1ed92b3ff428ea74ea3395aada797",
      "af6d993d60d44fed90601e1288f90867",
      "7ee1819aa09a4ba7b204f4b6683bcd9e",
      "0bc89951f2b24688931fc8b14610cf7e",
      "c7f066cde8824f1ea5c155e1b2b8b33b",
      "e6d3859f4e424c569e52b97289a7cb25",
      "b5261f2aacbf473688d14ea34c017899",
      "f63c36a82f7e4ef1b023f5049304c7e1",
      "d899fd79ab434f4ea0400cfdd37716f2",
      "60c2919930bb4fa0aa85af4a1296a7bb",
      "61ce448e5d344ca0a3b01e7e5c3ee15c",
      "7c3c78d176e341a4add7dd15d3bfeb2c",
      "fb8ce606d501414cbb0ab353326f13bc",
      "3d1a5e881bd34a1291edef34cd77a629",
      "da795b06bb414b6a8a45b2a546fbc68d",
      "da5e019c5a5346c9a4093d1ead8912b6",
      "cf6e275b025443b5a20dc9d627297d0b",
      "ac42fda6d5154e81a393c94ad658a46a",
      "4eda0df91473445e983deedd58ab2983",
      "1118675d45c444368cae2473d866057b",
      "991b0a14377246d6b299241bf0f6ead3",
      "8db8b51a3e5d43ee9b78ce809b451a09",
      "911af1b0fe304b7482d945c025ecdf74",
      "eced428220be4f0e82f13d0e76d618cd",
      "6d3ff118b32840a891d5b7e1cbd9fce7",
      "555aed75863b4637aa8174e4ec8a76b2",
      "fd5b5608909d40e8b9eb8241c01b223b",
      "ce7914f77e8a4398838a5667f0df0582",
      "1587ceae6a5a4d8b9fa9ea1f1081d113",
      "826bf7e8f20d4876a53a26de5018acd0",
      "f0fbd37b109d4778837aba5ddf27ba1a",
      "156a2ae5a8664526835d6e23274bf46a",
      "2a86b9d9bfbf4cc8ac46cce25c3b01c2",
      "27beeda60e2144ba82b52533234f274d",
      "07740f4a064c4d82bb86a1ee20ea9fca",
      "879c6c9a602647aa954ecca70c795557",
      "077cba201cbf436dac4ff29df159bcf2",
      "8d0e189719ef4ed39ade7ca1b660e354",
      "b8aa181525924e37b302900688a3341b",
      "fd5fcf2072df4f6aa5571dbf00297e4d",
      "058e321ee0a74cee899b0a7ee5e85dd0",
      "7ee12dfce54040988ab9223ca81b5c8f",
      "37a044abaa6843a69ab8f183937e564e",
      "a0ef8976938446378d9d79f4336c9ec0",
      "1492496deaeb44278442b6db0a2a3d26",
      "7e47af150fb4406593a92f3428bc9f6b",
      "c58046d2e6844ecd856daa5eec19b197",
      "cd3e9031b41e49b19ef10837975b831e",
      "59d34d17db45411fb37c1203fb7c9735",
      "9c8008fda5934608aad96cb82e73a384",
      "f6fffe1f25a24fa599ede7603eabba7f",
      "77684995463340e29a20da2ab825ef43",
      "22dd1e8e03e94fb89b1415986125ad19",
      "24755e3625284e8080444420266454af",
      "85137b58cc40482daa65e95c75efe090",
      "c4ac94030e534f54927d0e1bbab354ad",
      "98060f217abc4f03bf70ec32488456d9",
      "4504cda13d4241858ac49c8e9b8611d6"
     ]
    },
    "id": "gEdeadOEoRzq",
    "outputId": "f9943b07-f19e-4f41-9063-21710fbee8af"
   },
   "outputs": [],
   "source": [
    "# this to be run once\n",
    "from awq import AutoAWQForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AwqConfig, AutoConfig\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "def quantize_and_save_awq_model(\n",
    "    model_name_or_path: str,\n",
    "    quant_model_dir: str,\n",
    "    w_bit: int = 4,\n",
    "    q_group_size: int = 128,\n",
    "    zero_point: bool = True,\n",
    "    version: str = \"GEMM\",\n",
    "    trust_remote_code: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Quantize a model using AWQ, save the quantized model & tokenizer.\n",
    "\n",
    "    Args:\n",
    "        model_name_or_path (str): Path or name of the FP32 model (e.g., \"facebook/opt-2.7b\")\n",
    "        quant_model_dir (str): Directory to save the quantized model & tokenizer\n",
    "        w_bit (int): Number of bits for weights (e.g., 4)\n",
    "        q_group_size (int): Group size for quantization (e.g., 128)\n",
    "        zero_point (bool): Whether to use zero-point quantization\n",
    "        version (str): AWQ kernel version, e.g., \"GEMM\" or \"NEW\"\n",
    "        trust_remote_code (bool): Whether to trust remote code when loading the model\n",
    "    \"\"\"\n",
    "    # Define AWQ quantization config\n",
    "    quant_config = {\n",
    "        \"zero_point\": zero_point,\n",
    "        \"q_group_size\": q_group_size,\n",
    "        \"w_bit\": w_bit,\n",
    "        \"version\": version\n",
    "    }\n",
    "\n",
    "    print(f\"🔃 Loading model from: {model_name_or_path}, w_bit: {w_bit}, q_group_size: {q_group_size}, zero_point: {zero_point}, version: {version}\")\n",
    "    # Load the FP32 model using AutoAWQ\n",
    "    model = AutoAWQForCausalLM.from_pretrained(\n",
    "        model_name_or_path,\n",
    "        trust_remote_code=trust_remote_code\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_name_or_path,\n",
    "        trust_remote_code=trust_remote_code\n",
    "    )\n",
    "\n",
    "    print(\"⚙️  Quantizing model with AWQ...\")\n",
    "    # Quantize the model\n",
    "    model.quantize(tokenizer, quant_config=quant_config)\n",
    "\n",
    "    # Convert AWQ config to Transformers-compatible format\n",
    "    transformers_quant_config = AwqConfig(\n",
    "        bits=w_bit,\n",
    "        group_size=q_group_size,\n",
    "        zero_point=zero_point,\n",
    "        version=version.lower(),  # e.g., \"gemm\"\n",
    "    ).to_dict()\n",
    "\n",
    "    # Set the quantization config to the model's config (optional but useful for tracking)\n",
    "    model.model.config.quantization_config = transformers_quant_config\n",
    "\n",
    "    # Save quantized model and tokenizer\n",
    "    print(f\"💾 Saving quantized model to: {quant_model_dir}\")\n",
    "    model.save_quantized(quant_model_dir)\n",
    "    print(f\"💾 Saving quantized tokenizer to: {quant_model_dir}\")\n",
    "    tokenizer.save_pretrained(quant_model_dir)\n",
    "\n",
    "    # Set model to eval mode\n",
    "    model.eval()\n",
    "    print(\"Model change to eval mode.\")\n",
    "\n",
    "    print(\"✅ Quantization and save complete.\")\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using quant_model_dir: models/opt-6.7b-awq\n",
      "🔃 Loading model from: facebook/opt-6.7b, w_bit: 4, q_group_size: 128, zero_point: True, version: GEMM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b36119f253b34e4a830f41b3a1875c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d73c716af647c598fc3b0efbeee030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505d9f957c2247dca63747a8bbba1e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LICENSE.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b962377065c04f1e9e8d5557ea40d448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe36d4d45374c329b3d3ea5ad5115b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙️  Quantizing model with AWQ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "AWQ: 100%|██████████| 32/32 [40:54<00:00, 76.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saving quantized model to: models/opt-6.7b-awq\n",
      "💾 Saving quantized tokenizer to: models/opt-6.7b-awq\n",
      "Model change to eval mode.\n",
      "✅ Quantization and save complete.\n"
     ]
    }
   ],
   "source": [
    "# run this one time\n",
    "# update to the expected model name\n",
    "# model_name_or_path = \"facebook/opt-125m\"\n",
    "# model_name_or_path = \"facebook/opt-2.7b\"\n",
    "model_name_or_path = \"facebook/opt-6.7b\"\n",
    "\n",
    "model_name = model_name_or_path.split(\"/\")[-1]  # e.g., \"opt-2.7b\"\n",
    "quant_model_dir = f\"models/{model_name}-awq\"\n",
    "print(f\"using quant_model_dir: {quant_model_dir}\")\n",
    "\n",
    "# Call the function\n",
    "quant_model, quant_tokenizer = quantize_and_save_awq_model(\n",
    "    model_name_or_path=model_name_or_path,\n",
    "    quant_model_dir=quant_model_dir,\n",
    "    w_bit=4,\n",
    "    q_group_size=128,\n",
    "    zero_point=True,\n",
    "    version=\"GEMM\",\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating text for: Merry Christmas! I'm glad to\n",
      "Time taken 3.40 seconds\n",
      "Generated text: Merry Christmas! I'm glad to, Merry Christmas\n",
      " I'm glad to, Merry Christmas.\n",
      "That's all right all\n",
      "Generating text for: The woman worked as a\n",
      "Time taken 10.56 seconds\n",
      "Generated text: The woman worked as a nursing assistant at a hospital and the the\n",
      " the woman worked as a nursing assistant at a hospital and the the\n",
      " the woman worked as a nursing assistant at a hospital and the the\n",
      " the woman worked as a nursing assistant at a hospital and the the\n",
      "\n",
      "The woman worked as a nursing assistant at a hospital and the\n"
     ]
    }
   ],
   "source": [
    "# run this as many times as you want\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import time\n",
    "\n",
    "# update to the expected model name\n",
    "# model_name_or_path = \"facebook/opt-125m\"\n",
    "# model_name_or_path = \"facebook/opt-2.7b\"\n",
    "# model_name_or_path = \"facebook/opt-6.7b\"\n",
    "\n",
    "model_name = model_name_or_path.split(\"/\")[-1]  # e.g., \"opt-2.7b\"\n",
    "quant_model_dir = f\"models/{model_name}-awq\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(quant_model_dir)\n",
    "model = AutoModelForCausalLM.from_pretrained(quant_model_dir, device_map=\"cuda\").to(0)\n",
    "\n",
    "def generate_text(text):\n",
    "    print(f\"Generating text for: {text}\")\n",
    "    start_time = time.time()\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(0)\n",
    "    out = model.generate(**inputs, max_new_tokens=64)\n",
    "    result = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken {end_time - start_time:.2f} seconds\")\n",
    "    print(f\"Generated text: {result}\")\n",
    "    return result\n",
    "\n",
    "# testing\n",
    "result = generate_text(\"Merry Christmas! I'm glad to\")\n",
    "result = generate_text(\"The woman worked as a\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
