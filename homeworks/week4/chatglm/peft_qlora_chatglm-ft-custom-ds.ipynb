{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb393a61",
   "metadata": {},
   "source": [
    "# peft qlora chatglm finetune and inference with custom dataset\n",
    "\n",
    "```\n",
    "ç¬¬å››å‘¨ä½œä¸šï¼š\n",
    "1ã€åŸºäº data ç›®å½•ä¸‹çš„æ•°æ®è®­ç»ƒ ChatGLM3 æ¨¡å‹ï¼Œä½¿ç”¨ inference Notebook å¯¹æ¯”å¾®è°ƒå‰åçš„æ•ˆæœã€‚------> this notebook is for this task.\n",
    "2ã€ï¼ˆå¯é€‰ï¼‰ï¼šå°† gen_dataset Notebook æ”¹å†™ä¸º py æ–‡ä»¶ã€‚\n",
    "ä½œä¸šä»£ç ï¼š\n",
    "å¾®è°ƒçš„ä»£ç ï¼šhttps://github.com/DjangoPeng/LLM-quickstart/blob/main/chatglm/qlora_chatglm3_timestamp.ipynb\n",
    "ä½¿ç”¨å¾®è°ƒåæ¨¡å‹è¿›è¡Œæ¨ç†çš„ä»£ç ï¼šhttps://github.com/DjangoPeng/LLM-quickstart/blob/main/chatglm/chatglm_inference.ipynb\n",
    "ç”Ÿæˆæ•°æ®é›†çš„ä»£ç ï¼šhttps://github.com/RorschachWwww/LLM-quickstart/blob/main/chatglm/gen_dataset.ipynb\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fa8105c-6dda-426b-9180-ab9abbc9ce9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 12.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.9.2\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
      " _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15095MB, multi_processor_count=40)\n",
      "\n",
      "================================================================================\n",
      "ğŸ” Train/Eval with dataset: data/zhouyi_dataset_20240118_152413.csv\n",
      "================================================================================\n",
      "\n",
      "ğŸ”§ Releasing GPU ...\n",
      "loading dataset_name:data/zhouyi_dataset_20240118_152413.csv\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['content', 'summary'],\n",
      "        num_rows: 160\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>éœ€å¦åœ¨å‘¨æ˜“ä¸­æ˜¯ä»€ä¹ˆè±¡å¾ï¼Ÿ</td>\n",
       "      <td>éœ€å¦\"ç”±ä¸Šå¦åï¼ˆæ°´ï¼‰å’Œä¸‹å¦ä¹¾ï¼ˆå¤©ï¼‰ç»„æˆï¼Œä¸Šå¦ä¸ºäº‘ï¼Œä¸‹å¦ä¸ºå¤©ã€‚ä¸Šå¦åä¸ºé™©ï¼Œä¸‹å¦ä¹¾ä¸ºåˆšï¼Œè±¡å¾ç€äº‘æµ®èšäºå¤©ä¸Šï¼Œå¾…æ—¶é™é›¨ä¹‹è±¡ã€‚é¢„ç¤ºæŠ“åˆ°ä¿˜è™ï¼Œå¤§å‰å¤§åˆ©ï¼Œæœ‰åˆ©äºæ¶‰æ°´æ¸¡æ²³ã€‚å›å­è§‚æ­¤å¦è±¡ï¼Œå¯ä»¥å®´é¥®å®‰ä¹ï¼Œå¾…æ—¶è€ŒåŠ¨ã€‚\\n\\nè¿™ä¸ªå¦è±¡è¡¨ç¤ºè¸Œèº‡æœŸå¾…ï¼Œè™½ç„¶åˆšå¼ºï¼Œä½†å‰é¢æœ‰é™©é˜»ï¼Œåº”å½“ç­‰å¾…ï¼Œæ¶‰å¤§å·åˆ™åˆ©ã€‚æ—¶æœºå°šæœªæˆç†Ÿï¼Œéœ€è¦è€å¿ƒç­‰å¾…ï¼Œä¸å®œå†’è¿›ã€‚è°‹äº‹åº”å®¡æ—¶åº¦åŠ¿ï¼Œè€å¿ƒç­‰å¾…ï¼Œåˆ‡å‹¿å†’é™©ï¼Œæ¬²é€Ÿä¸è¾¾ã€‚è‡ªä¿¡ã€åšå®ˆä¸­æ­£ï¼Œå¯åŒ–é™©ä¸ºå¤·ã€‚æƒ…å†µæœ‰åˆ©æ—¶ï¼Œä»å¾—å±…å®‰æ€å±ã€‚\\n\\néœ€å¦çš„æ ¸å¿ƒå“²å­¦æ˜¯è°‹äº‹åº”å®¡æ—¶åº¦åŠ¿ï¼Œè€å¿ƒç­‰å¾…ï¼Œåˆ‡å‹¿å†’é™©ï¼Œæ¬²é€Ÿä¸è¾¾ã€‚è‡ªä¿¡ã€åšå®ˆä¸­æ­£ï¼Œå¯ä»¥åŒ–é™©ä¸ºå¤·ã€‚éœ€è¦æ§åˆ¶é¥®é£Ÿï¼Œä¿æŒå¥åº·çš„ç”Ÿæ´»æ–¹å¼ã€‚åœ¨æ„Ÿæƒ…å’Œå©šå§»æ–¹é¢ï¼Œéœ€è¦æ…é‡ã€è¯šå®ã€å’ŒæŸ”å…‹åˆšã€‚\\n\\nåœ¨è¡ŒåŠ¨ä¹‹åˆï¼Œéœ€è¦æå¤§çš„è€å¿ƒï¼Œè§‚æ—¶å¾…å˜ï¼Œåˆ›é€ æ¡ä»¶å’Œæœºä¼šã€‚ç­‰å¾…æ—¶æœºæˆç†Ÿåï¼Œå¤§å™¨å¿…å®šæ™šæˆã€‚åœ¨äº‹ä¸šå‘å±•ä¸­ï¼Œé‡åˆ°å›°éš¾å’Œé™©é˜»æ—¶ï¼Œå¿…é¡»ååˆ†è°¨æ…ï¼Œå¦ç„¶å¯¹å¾…å°äººçš„ä¸­ä¼¤ã€‚ä¸ºäººå¤„äº‹åº”è°¦å’Œã€å¦ç‡ï¼Œå¤šæœ‰ä»–äººç›¸åŠ©ï¼Œä¿ƒä½¿äº‹ä¸šæˆåŠŸã€‚å½“æ—¶æœºæˆç†Ÿåï¼Œåˆ™å¿…ç„¶ä¸€å¸†é£é¡ºã€‚\"\\n\\nsource:\"ã€Šæ˜“ç»ã€‹</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>è¯·è§£é‡Šä¸€ä¸‹æ¯”å¦ã€‚</td>\n",
       "      <td>æ¯”å¦\"æ˜¯å‘¨æ˜“å¦è±¡ä¸­çš„ä¸€æšå¦ï¼Œç”±ä¸‹å¦å¤ï¼ˆåœ°ï¼‰ä¸Šå¦åï¼ˆæ°´ï¼‰ç»„æˆï¼Œé¢„ç¤ºç€å‰åˆ©çš„å˜åŒ–ã€‚åœ¨åœç­®æ—¶ï¼Œå†æ¬¡å åœä¾ç„¶å‰åˆ©ï¼Œé¢„ç¤ºé•¿æœŸç¨³å®šæ— ç¾ç¥¸ã€‚ç„¶è€Œï¼Œå½“ä¸æ„¿è‡£æœçš„é‚¦å›½æœªèƒ½å‰æ¥æœè´ºæ—¶ï¼Œå°†ä¼šå¸¦æ¥å±é™©ã€‚\\n\\nåœ¨ã€Šè±¡è¾ã€‹ä¸­ï¼Œæ¯”å¦è¢«æè¿°ä¸ºåœ°ä¸Šæœ‰æ°´çš„æƒ…æ™¯ï¼Œåæ˜ äº†ç›¸äº²ç›¸ä¾ç›¸äº’ä¾èµ–çš„æ„ä¹‰ã€‚å…ˆç‹è§‚æ­¤å¦è±¡ï¼Œå–æ³•äºæ°´é™„å¤§åœ°ï¼Œåœ°çº³æ±Ÿæ²³ä¹‹è±¡ï¼Œå› æ­¤æ­¤å¦è¢«è§£é‡Šä¸ºå»ºç«‹ä¸‡å›½ï¼Œäº²è¿‘è¯¸ä¾¯ã€‚\\n\\nåŒ—å®‹æ˜“å­¦å®¶é‚µé›è§£é‡Šè®¤ä¸ºï¼Œæ¯”å¦ä»£è¡¨æ°´åœ¨åœ°é¢ä¸ŠæµåŠ¨ï¼Œäººé™…å…³ç³»äº²å¯†å’Œç¦ï¼Œå„ç§äº‹æƒ…æ— å¿§æ— è™‘ã€‚\\n\\nå°æ¹¾å›½å­¦å¤§å„’å‚…ä½©è£è§£é‡Šè®¤ä¸ºï¼Œæ¯”å¦çš„æ—¶è¿æ˜¯ä¼—äººç›¸è´ºï¼Œè´¢è¿æ˜¯å–„äººç›¸æ‰¶ï¼Œå®¶å®…æ–¹é¢æ˜¯é•¿ä¹…ç¾æ»¡ï¼Œèº«ä½“æ–¹é¢åˆ™éœ€æ—©æ±‚æ²»å¿ƒè…¹æ°´è‚¿ã€‚\\n\\nä¼ ç»Ÿè§£å¦è®¤ä¸ºï¼Œæ¯”å¦é¢„ç¤ºç€ç›¸äº²ç›¸è¾…ï¼Œå®½å®æ— ç§ï¼Œç²¾è¯šå›¢ç»“çš„é“ç†ã€‚åœ¨è¿åŠ¿ä¸Šï¼Œè¡¨ç¤ºå¹³é¡ºï¼Œèƒ½å¾—è´µäººææ‹”ï¼Œäº‹ä¸šå®œé€Ÿæˆ˜é€Ÿå†³ï¼Œä¸å®œè¿‡åº¦è¿Ÿç–‘ã€‚å¯¹äºäº‹ä¸šã€ç»å•†ã€æ±‚åã€å©šæ‹ç­‰æ–¹é¢éƒ½æœ‰ç§¯æçš„å½±å“ï¼Œæé†’äººä»¬å¾…äººå®½åšã€æ­£ç›´ï¼Œä¸»åŠ¨çƒ­æƒ…ï¼Œå¹¶è°¨æ…é€‰æ‹©æœ‹å‹ã€‚\\n\\næ€»ä¹‹ï¼Œ\"æ¯”å¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"è®¼å¦åœ¨å‘¨æ˜“ä¸­æ€æ ·è¡¨è¾¾æ•™è‚²çš„æ¦‚å¿µï¼Ÿ</td>\n",
       "      <td>åœ¨å‘¨æ˜“ä¸­ï¼Œè®¼å¦æ˜¯ä¸€ä¸ªæå…·æ·±æ„çš„å¦è±¡ã€‚ä¸Šå¦ä¸ºä¹¾ï¼ˆå¤©ï¼‰ï¼Œä¸‹å¦ä¸ºåï¼ˆæ°´ï¼‰ï¼Œä¸¤è€…ç›¸èƒŒè€Œè¡Œï¼Œä»£è¡¨å¤©ä¸æ°´è¿è¡Œçš„çŠ¶å†µï¼Œè±¡å¾ç€äº‹ç†ä¹–èˆ›å’Œäº‰è®¼ä¹‹è±¡ã€‚è®¼å¦ä¸­æœ‰åˆ©å¯å›¾ï¼Œä½†å¿…é¡»è­¦æƒ•æˆ’æƒ§ï¼Œäº‹æƒ…ä¸­é—´å‰åˆ©ï¼Œä½†æœ€ç»ˆä¼šæœ‰å‡¶é™©ã€‚åœ¨åœå¦æ—¶ï¼Œåˆ©äºä¼šè§è´µæ—ç‹å…¬ï¼Œä½†ä¸åˆ©äºæ¶‰æ°´æ¸¡æ²³ã€‚\\n\\nè®¼å¦çš„æ ¸å¿ƒå“²å­¦æ˜¯ï¼šå¼€å§‹å¯èƒ½é¡ºåˆ©ï¼Œæœ‰æ‰€æ”¶è·ï¼Œä½†éšåä¼šé‡åˆ°å›°éš¾å’ŒæŒ«æŠ˜ã€‚å› æ­¤ï¼ŒåŠ¡å¿…æ…ä¹‹åˆæ…ï¼Œä¸å¾—å›ºæ‰§å·²è§ï¼Œé¿å…ä»‹å…¥è¯‰è®¼çº çº·çš„äº‰æ‰§ä¹‹ä¸­ã€‚é€€è®©è€Œä¸å›ºæ‰§ï¼Œæ±‚å¾—åŒ–è§£ï¼Œå®‰äºæ­£ç†ï¼Œå¯å…é™¤æ„å¤–ä¹‹ç¾ã€‚é™·å…¥äº‰è®¼ï¼Œå³ä½¿è·èƒœï¼Œæœ€åè¿˜å¾—å¤±å»ï¼Œå¾—ä¸å¿å¤±ã€‚\\n\\nè®¼å¦çš„ç»å•†æŒ‡å¼•æ˜¯ï¼šå’Œæ°”ç”Ÿè´¢ï¼Œåƒäºæ˜¯ç¦ï¼Œåˆ‡å‹¿è¿½æ±‚ä¸ä¹‰ä¹‹è´¢ã€‚åœ¨å•†ä¸šè°ˆåˆ¤ä¸­è¦åšæŒå…¬æ­£ã€å…¬å¹³ã€äº’åˆ©çš„åŸåˆ™ï¼Œå°½é‡é¿å…å‘ç”Ÿå†²çªã€‚\\n\\nå¯¹äºå†³ç­–ï¼Œè®¼å¦æé†’æˆ‘ä»¬ï¼Œäº‰å¼ºå¥½èƒœï¼Œä¸å®‰äºç°çŠ¶ï¼Œä¸ºæ”¹å˜å‘½è¿å’Œè¶…è¶Šä»–äººè€Œå¥‹æ–—ã€‚ä½†ç¼ºä¹æŒä¹‹ä»¥æ’çš„æ¯…åŠ›ï¼Œå®¹æ˜“å¾—ç½ªä»–äººï¼Œå¸¦æ¥è¯‰è®¼ä¹‹ç¾ã€‚å› æ­¤ï¼Œæ¥å—æ•™è®­ï¼Œå¼•ä»¥ä¸ºæˆ’ï¼Œå¯åŠŸæˆåå°±ã€‚\\n\\nè®¼å¦æ‰€è•´å«çš„æ™ºæ…§æ˜¯ï¼šåœ¨é¢å¯¹äº‰ç«¯å’Œå¼‚è§æ—¶ï¼Œè¦å–„äºé€€è®©å’Œæ±‚å’Œï¼Œåšå®ˆæ­£é“ï¼Œè°¨æ…å¤„äº‹ï¼Œä»¥é¿å…ä¸å¿…è¦çš„å†²çªå’ŒæŸå¤±ã€‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>å‘¨æ˜“çš„\"ä¹¾å¦è®²è¿°äº†ä»€ä¹ˆï¼Ÿ</td>\n",
       "      <td>\"ä¹¾å¦\"\\nsummary: \"ã€Šæ˜“ç»ã€‹ä¸­çš„ä¹¾å¦æ˜¯å…­åå››å¦ä¸­çš„é¦–å¦ï¼Œè±¡å¾å¤©ï¼Œç”±å…­ä¸ªé˜³çˆ»ç»„æˆï¼Œä»£è¡¨ç€åˆšå¥å¼ºåŠ²çš„ç‰¹æ€§ã€‚å…¶å¦è¾ä¸ºâ€œå…ƒã€äº¨ã€åˆ©ã€è´â€ï¼Œé¢„ç¤ºç€å‰ç¥¥å¦‚æ„ï¼ŒåŒæ—¶ä¹Ÿæ•™å¯¼äººä»¬éµå®ˆå¤©é“çš„å¾·è¡Œã€‚ä¹¾å¦æ‰€è•´å«çš„æ ¸å¿ƒå“²å­¦æ˜¯ï¼šå¤©é“åˆšå¥ï¼Œè¿è¡Œä¸å·²ï¼Œå›å­è§‚æ­¤å¦è±¡ï¼Œä»è€Œä»¥å¤©ä¸ºæ³•ï¼Œè‡ªå¼ºä¸æ¯ã€‚\"\\n\\ncomment: \"åœ¨ä¼ ç»Ÿè§£å¦ä¸­ï¼Œä¹¾å¦é¢„ç¤ºç€å¤§å‰å¤§åˆ©ï¼Œäº‹ä¸šå¦‚æ—¥ä¸­å¤©ï¼Œä½†ä¹Ÿæé†’è¦è­¦æƒ•ç››æå¿…è¡°çš„é“ç†ã€‚ç»å•†æ–¹é¢é¡ºåˆ©å‘å±•ï¼Œä½†è¦å†·é™åˆ†æå½¢åŠ¿ï¼ŒåšæŒå•†ä¸šé“å¾·ã€‚å¯¹äºå©šæ‹ï¼Œå°½ç®¡é˜³ç››é˜´è¡°ï¼Œä½†åˆšæŸ”å¯ç›¸æµï¼Œæœ€ç»ˆå½¢æˆç¾æ»¡ç»“æœã€‚æ€»ä½“è€Œè¨€ï¼Œä¹¾å¦ä»£è¡¨ç€å……æ»¡æ´»åŠ›å’ŒåŠ›é‡çš„æ—¶æœºï¼Œä½†ä¹Ÿéœ€è¦ä¿æŒè°¦é€Šè°¨æ…çš„æ€åº¦ï¼Œä»¥åº”å¯¹å¯èƒ½å‡ºç°çš„å›°éš¾ã€‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"è®¼å¦æ¶‰åŠå“ªäº›å“²å­¦æ€æƒ³ï¼Ÿ</td>\n",
       "      <td>åœ¨å‘¨æ˜“ä¸­ï¼Œè®¼å¦æ˜¯ä¸€ä¸ªæå…·æ·±æ„çš„å¦è±¡ã€‚ä¸Šå¦ä¸ºä¹¾ï¼ˆå¤©ï¼‰ï¼Œä¸‹å¦ä¸ºåï¼ˆæ°´ï¼‰ï¼Œä¸¤è€…ç›¸èƒŒè€Œè¡Œï¼Œä»£è¡¨å¤©ä¸æ°´è¿è¡Œçš„çŠ¶å†µï¼Œè±¡å¾ç€äº‹ç†ä¹–èˆ›å’Œäº‰è®¼ä¹‹è±¡ã€‚è®¼å¦ä¸­æœ‰åˆ©å¯å›¾ï¼Œä½†å¿…é¡»è­¦æƒ•æˆ’æƒ§ï¼Œäº‹æƒ…ä¸­é—´å‰åˆ©ï¼Œä½†æœ€ç»ˆä¼šæœ‰å‡¶é™©ã€‚åœ¨åœå¦æ—¶ï¼Œåˆ©äºä¼šè§è´µæ—ç‹å…¬ï¼Œä½†ä¸åˆ©äºæ¶‰æ°´æ¸¡æ²³ã€‚\\n\\nè®¼å¦çš„æ ¸å¿ƒå“²å­¦æ˜¯ï¼šå¼€å§‹å¯èƒ½é¡ºåˆ©ï¼Œæœ‰æ‰€æ”¶è·ï¼Œä½†éšåä¼šé‡åˆ°å›°éš¾å’ŒæŒ«æŠ˜ã€‚å› æ­¤ï¼ŒåŠ¡å¿…æ…ä¹‹åˆæ…ï¼Œä¸å¾—å›ºæ‰§å·²è§ï¼Œé¿å…ä»‹å…¥è¯‰è®¼çº çº·çš„äº‰æ‰§ä¹‹ä¸­ã€‚é€€è®©è€Œä¸å›ºæ‰§ï¼Œæ±‚å¾—åŒ–è§£ï¼Œå®‰äºæ­£ç†ï¼Œå¯å…é™¤æ„å¤–ä¹‹ç¾ã€‚é™·å…¥äº‰è®¼ï¼Œå³ä½¿è·èƒœï¼Œæœ€åè¿˜å¾—å¤±å»ï¼Œå¾—ä¸å¿å¤±ã€‚\\n\\nè®¼å¦çš„ç»å•†æŒ‡å¼•æ˜¯ï¼šå’Œæ°”ç”Ÿè´¢ï¼Œåƒäºæ˜¯ç¦ï¼Œåˆ‡å‹¿è¿½æ±‚ä¸ä¹‰ä¹‹è´¢ã€‚åœ¨å•†ä¸šè°ˆåˆ¤ä¸­è¦åšæŒå…¬æ­£ã€å…¬å¹³ã€äº’åˆ©çš„åŸåˆ™ï¼Œå°½é‡é¿å…å‘ç”Ÿå†²çªã€‚\\n\\nå¯¹äºå†³ç­–ï¼Œè®¼å¦æé†’æˆ‘ä»¬ï¼Œäº‰å¼ºå¥½èƒœï¼Œä¸å®‰äºç°çŠ¶ï¼Œä¸ºæ”¹å˜å‘½è¿å’Œè¶…è¶Šä»–äººè€Œå¥‹æ–—ã€‚ä½†ç¼ºä¹æŒä¹‹ä»¥æ’çš„æ¯…åŠ›ï¼Œå®¹æ˜“å¾—ç½ªä»–äººï¼Œå¸¦æ¥è¯‰è®¼ä¹‹ç¾ã€‚å› æ­¤ï¼Œæ¥å—æ•™è®­ï¼Œå¼•ä»¥ä¸ºæˆ’ï¼Œå¯åŠŸæˆåå°±ã€‚\\n\\nè®¼å¦æ‰€è•´å«çš„æ™ºæ…§æ˜¯ï¼šåœ¨é¢å¯¹äº‰ç«¯å’Œå¼‚è§æ—¶ï¼Œè¦å–„äºé€€è®©å’Œæ±‚å’Œï¼Œåšå®ˆæ­£é“ï¼Œè°¨æ…å¤„äº‹ï¼Œä»¥é¿å…ä¸å¿…è¦çš„å†²çªå’ŒæŸå¤±ã€‚</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸  The dataset doesn't have 'validation' splitï¼Œ not evaluating.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df25d981f6994fa2a4e006440f1a3af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n",
      "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,899,392 || all params: 6,247,483,392 || trainable%: 0.06241540401681151\n",
      "dataset_name=data/zhouyi_dataset_20240118_152413.csv\n",
      "training_args num_train_epochs: 3, logging_steps: 1, eval_steps: 1, save_steps: 10, per_device_train_batch_size: 8, , gradient_accumulation_steps: 1\n",
      "start train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 13:31, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.594100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.049100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.089700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.375100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.539200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.601600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.654100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.163400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.274700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.291900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.855600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.891600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.555700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.994600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.001400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.532300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.624300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.567800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.511100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.279900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.255300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.199300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.128700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.130100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.085500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.054700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.044700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.022400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.024000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.023200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.027700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.017500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.012300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.010400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.012800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.013300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.015600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.010100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.007500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.005400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.006100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.007200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.005700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.004700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.004500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.005700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.005400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.005100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.004700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.004800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.003800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.004400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.004600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.004100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.003500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.003300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.002700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.003900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.003400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_152413/checkpoint-10 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_152413/checkpoint-20 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_152413/checkpoint-30 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_152413/checkpoint-40 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_152413/checkpoint-50 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_152413/checkpoint-60 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end train.\n",
      "âœ… fine tuned model saved to path: models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_152413\n",
      "\n",
      "================================================================================\n",
      "ğŸ” Train/Eval with dataset: data/zhouyi_dataset_20240118_163659.csv\n",
      "================================================================================\n",
      "\n",
      "ğŸ”§ Releasing GPU ...\n",
      "loading dataset_name:data/zhouyi_dataset_20240118_163659.csv\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['content', 'summary'],\n",
      "        num_rows: 160\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>å±¯å¦åœ¨å‘¨æ˜“ä¸­æ€æ ·è¡¨è¾¾æ•™è‚²çš„æ¦‚å¿µï¼Ÿ</td>\n",
       "      <td>åœ¨å‘¨æ˜“ä¸­ï¼Œå±¯å¦æ˜¯ä¸€ä¸ªå¤§å‰å¤§åˆ©çš„å¦è±¡ï¼Œé¢„ç¤ºç€å‰ç¥¥å’Œå¤§åˆ©ã€‚ç„¶è€Œï¼Œä¸åˆ©äºå‡ºé—¨ï¼Œä½†æœ‰åˆ©äºå»ºå›½å°ä¾¯ã€‚å±¯å¦ç”±ä¸Šå¦åï¼ˆæ°´ï¼‰ä¸‹å¦éœ‡ï¼ˆé›·ï¼‰ç»„æˆï¼Œåä¸ºäº‘ï¼Œéœ‡ä¸ºé›·ã€‚é¢„ç¤ºç€äº‘è¡Œé›·åŠ¨çš„å¦è±¡ã€‚å›å­è§‚æ­¤å¦è±¡ï¼Œå–æ³•äºäº‘é›·ï¼Œç”¨äº‘çš„æ©æ³½ï¼Œé›·çš„å¨ä¸¥æ¥æ²»ç†å›½äº‹ã€‚å±¯å¦è±¡å¾ç€å¼€å§‹å›°éš¾ï¼Œéœ€è¦æ¯…åŠ›å’Œæœæ•¢æ‰èƒ½è·å¾—å‰åˆ©ã€‚èº«å¤„å›°å¢ƒéœ€è¦å¤šåŠ è¾›è‹¦åŠªåŠ›ï¼Œæ’é™¤å›°éš¾ï¼Œæ–¹å¯é€šè¾¾ï¼Œæœ‰åˆéš¾åè§£ä¹‹è±¡ã€‚å› æ­¤ï¼Œå¯¹äºäº‹ä¸šåˆ›ä¸šè€Œè¨€ï¼Œåº”å½“å°å¿ƒç¿¼ç¿¼ï¼Œå‹‡å¾€ç›´å‰ï¼Œçµæ´»æœºåŠ¨ï¼Œå¯æœ›è·å¾—å¤§çš„æˆåŠŸã€‚ä½†ä¹Ÿéœ€æ³¨æ„åˆ°ä»æœ‰å›°éš¾å­˜åœ¨ï¼ŒåŠ¡å¿…æœ‰ä»–äººç›¸åŠ©ï¼Œå¹³æ—¶åº”å¤šæ–½æ©æƒ ã€‚å¯¹äºç»å•†ï¼Œèµ·åˆå¤šæœ‰æŒ«æŠ˜ï¼Œå¿…é¡»åšå®šä¿¡å¿µï¼Œç§¯æè¿›å–ï¼Œè¡ŒåŠ¨æœæ–­ï¼Œè‹¥ä»æ— æ³•æ‘†è„±å›°å¢ƒï¼Œåˆ™åº”é€€å®ˆä¿å…¨ï¼Œç­‰å¾…æœºä¼šï¼Œå†å±•å®å›¾ã€‚å¯¹äºå©šæ‹ï¼Œå¥½äº‹å¤šç£¨ï¼Œå¿ è´çº¯æ´ï¼Œå¤§èƒ†è¿½æ±‚ï¼Œèƒ½å¤ŸæˆåŠŸã€‚å±¯å¦çš„æ ¸å¿ƒå“²å­¦åœ¨äºï¼Œåˆéš¾åè§£ï¼Œéœ€è¦æ¯…åŠ›å’Œåšå¿ä¸æ‹”çš„æ¯…åŠ›å’Œé”²è€Œä¸èˆçš„å¥‹æ–—ç²¾ç¥ï¼Œä½†ä¹Ÿéœ€å¾—åˆ°è´¤å¾·ä¹‹äººçš„å¸®åŠ©æ‰èƒ½æ‘†è„±å›°å¢ƒã€‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>å‘¨æ˜“çš„è’™å¦è®²è¿°äº†ä»€ä¹ˆï¼Ÿ</td>\n",
       "      <td>è’™å¦æ˜¯ç”±è‰®å¦ï¼ˆå±±ï¼‰ä¸‹ï¼Œåå¦ï¼ˆæ°´ï¼‰ä¸Šç»„æˆçš„å¼‚å¦ç›¸å ã€‚å®ƒä»£è¡¨ç€é€šæ³°ï¼Œå¯è’™çš„æ„ä¹‰ã€‚åœ¨è¿™é‡Œï¼Œåœè€…å¹¶éæ˜¯åœ¨å‘å¹¼ç¨šæ„šæ˜§çš„äººå–æ±‚ï¼Œè€Œæ˜¯å¹¼ç¨šæ„šæ˜§çš„äººåœ¨å‘åœè€…æ±‚æ•™ã€‚ç¬¬ä¸€æ¬¡åœç­®å°±å¾—åˆ°äº†ç¥çµçš„æŒ‡ç¤ºã€‚ç„¶è€Œï¼Œå¦‚æœè½»æ…¢ä¸æ•¬åœ°å†ä¸‰åœç­®çš„è¯ï¼Œç¥çµä¾¿ä¸ä¼šå†ç¤ºè­¦ã€‚æ€»çš„æ¥è¯´ï¼Œè¿™æ˜¯ä¸€ä¸ªå‰åˆ©çš„åœé—®ã€‚\\n\\nè’™å¦çš„æ ¸å¿ƒåœ¨äºå±±ä¸‹æœ‰æ³‰çš„å½¢è±¡ï¼Œå¯“æ„ç€å¯è’™ã€‚å›å­è§‚æ­¤å¦è±¡ï¼Œåº”å½“ä»¥æœæ•¢åšæ¯…çš„è¡ŒåŠ¨æ¥åŸ¹å…»è‡ªèº«çš„å“å¾·ï¼Œåƒå±±æ³‰ä¸€æ ·æœæ–­è¡ŒåŠ¨ã€‚ç„¶è€Œï¼Œæ­¤å¦ä¹ƒæ˜¯ç¦»å®«å››ä¸–å¦ï¼Œå®ƒä»£è¡¨ç€å›è¿˜å¾€å¤ã€ç–‘æƒ‘ä¸å‰ã€å¤šå¿§æ„è¿‡å¤±ï¼Œå› è€Œå±äºå‡¶å¦ã€‚\\n\\nè’™å¦åœ¨ä¸ªäººå‘å±•ã€äº‹ä¸šç»å•†ã€æ±‚åå©šæ‹ç­‰æ–¹é¢çš„è§£é‡Šä¸ä¸€ã€‚åœ¨äº‹ä¸šæ–¹é¢ï¼Œè¡¨ç¤ºäº‹ä¸šåˆå»ºï¼Œå…·æœ‰å¯è’™å’Œé€šè¾¾ä¹‹è±¡ï¼Œéœ€è¦å‹‡æ•¢åšæ¯…çš„è¡ŒåŠ¨ï¼›è€Œåœ¨ç»å•†æ–¹é¢ï¼Œéœ€è¦åŠ¡å¿…å°å¿ƒè°¨æ…ï¼Œæ ‘ç«‹é«˜å°šçš„å•†ä¸šé“å¾·ï¼Œä¸å¯æ€¥åŠŸè¿‘åˆ©ï¼›æ±‚åæ–¹é¢ï¼Œéœ€è¦æ¥å—è‰¯å¥½çš„åŸºç¡€æ•™è‚²ï¼Œé™¶å†¶æƒ…æ“ã€‚æ•´ä½“è€Œè¨€ï¼Œæ­¤å¦æç¤ºé¡»å¿è€å¾…æœºè€ŒåŠ¨ï¼Œå¬å–åˆ«äººæ„è§ï¼Œæ–¹èƒ½é€šè¾¾è¿åŠ¿ã€‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>å‘¨æ˜“ä¸­è®¼å¦çš„è§£é‡Šæ˜¯ä»€ä¹ˆï¼Ÿ</td>\n",
       "      <td>åœ¨å‘¨æ˜“ä¸­ï¼Œè®¼å¦æ˜¯ä¸€ä¸ªå……æ»¡è­¦ç¤ºçš„å¦è±¡ã€‚å®ƒç”±ä¸Šå¦ä¹¾ï¼ˆå¤©ï¼‰å’Œä¸‹å¦åï¼ˆæ°´ï¼‰ç»„æˆï¼Œä»£è¡¨ç€å¤©ä¸æ°´èƒŒé“è€Œé©°ï¼Œå½¢æˆäº‰è®¼çš„å±€é¢ã€‚è™½ç„¶äº‹æƒ…å¼€å§‹æ—¶æœ‰åˆ©å¯å›¾ï¼Œä½†å¿…é¡»è­¦æƒ•æˆ’æƒ§ï¼Œå› ä¸ºä¸­é—´è™½ç„¶å‰åˆ©ï¼Œä½†æœ€ç»ˆä¼šå¸¦æ¥å‡¶é™©ã€‚å¯¹äºæ¶‰åŠå¤§å·ï¼Œæ¶‰æ°´æ¸¡æ²³çš„è¡ŒåŠ¨ä¸åˆ©ã€‚å› æ­¤ï¼Œå›å­è§‚æ­¤å¦è±¡ï¼Œåº”å½“æ…ä¹‹åˆæ…ï¼Œæœç»äº‰è®¼ä¹‹äº‹ï¼Œå¹¶åœ¨è°‹äº‹ä¹‹åˆè°¨æ…è¡Œäº‹ã€‚è®¼å¦çš„æ ¸å¿ƒå“²å­¦æ˜¯è¦é¿å…äº‰è®¼ï¼Œé€€è€Œè®©äººï¼Œæ±‚å¾—åŒ–è§£ï¼Œå®‰äºæ­£ç†ï¼Œæ–¹å¯é¿å…æ„å¤–ä¹‹ç¾ã€‚åœ¨äº‹ä¸šä¸Šï¼ŒåŠ¡å¿…é¿å…ä»‹å…¥è¯‰è®¼çº çº·çš„äº‰æ‰§ä¹‹ä¸­ï¼Œä¸å…¶è¿™æ ·ï¼Œä¸å¦‚é€€è€Œè®©äººã€‚å³ä½¿æœ€ç»ˆè·èƒœï¼Œä¹Ÿéš¾å…å¾—å¤±ä¸å‡ã€‚ç»å•†æ–¹é¢ï¼Œè¦åšæŒå…¬æ­£ã€å…¬å¹³ã€äº’åˆ©çš„åŸåˆ™ï¼Œé¿å…å†²çªï¼Œè¿™æ ·ä¼šæœ‰å¥½ç»“æœã€‚è€Œå¯¹äºæ±‚åã€å©šæ‹å’Œå†³ç­–ï¼Œä¹Ÿéƒ½éœ€è¦æ…é‡è¡Œäº‹ï¼Œé¿å…ç›²ç›®è¿½æ±‚ï¼Œé€€è®©è®©äººï¼Œå¯åŠ©äº‹ä¸šã€å©šå§»å’Œå†³ç­–çš„å‘å±•ã€‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>è¯·è§£é‡Šä¸€ä¸‹è®¼å¦ã€‚</td>\n",
       "      <td>åœ¨å‘¨æ˜“ä¸­ï¼Œè®¼å¦æ˜¯ä¸€ä¸ªå……æ»¡è­¦ç¤ºçš„å¦è±¡ã€‚å®ƒç”±ä¸Šå¦ä¹¾ï¼ˆå¤©ï¼‰å’Œä¸‹å¦åï¼ˆæ°´ï¼‰ç»„æˆï¼Œä»£è¡¨ç€å¤©ä¸æ°´èƒŒé“è€Œé©°ï¼Œå½¢æˆäº‰è®¼çš„å±€é¢ã€‚è™½ç„¶äº‹æƒ…å¼€å§‹æ—¶æœ‰åˆ©å¯å›¾ï¼Œä½†å¿…é¡»è­¦æƒ•æˆ’æƒ§ï¼Œå› ä¸ºä¸­é—´è™½ç„¶å‰åˆ©ï¼Œä½†æœ€ç»ˆä¼šå¸¦æ¥å‡¶é™©ã€‚å¯¹äºæ¶‰åŠå¤§å·ï¼Œæ¶‰æ°´æ¸¡æ²³çš„è¡ŒåŠ¨ä¸åˆ©ã€‚å› æ­¤ï¼Œå›å­è§‚æ­¤å¦è±¡ï¼Œåº”å½“æ…ä¹‹åˆæ…ï¼Œæœç»äº‰è®¼ä¹‹äº‹ï¼Œå¹¶åœ¨è°‹äº‹ä¹‹åˆè°¨æ…è¡Œäº‹ã€‚è®¼å¦çš„æ ¸å¿ƒå“²å­¦æ˜¯è¦é¿å…äº‰è®¼ï¼Œé€€è€Œè®©äººï¼Œæ±‚å¾—åŒ–è§£ï¼Œå®‰äºæ­£ç†ï¼Œæ–¹å¯é¿å…æ„å¤–ä¹‹ç¾ã€‚åœ¨äº‹ä¸šä¸Šï¼ŒåŠ¡å¿…é¿å…ä»‹å…¥è¯‰è®¼çº çº·çš„äº‰æ‰§ä¹‹ä¸­ï¼Œä¸å…¶è¿™æ ·ï¼Œä¸å¦‚é€€è€Œè®©äººã€‚å³ä½¿æœ€ç»ˆè·èƒœï¼Œä¹Ÿéš¾å…å¾—å¤±ä¸å‡ã€‚ç»å•†æ–¹é¢ï¼Œè¦åšæŒå…¬æ­£ã€å…¬å¹³ã€äº’åˆ©çš„åŸåˆ™ï¼Œé¿å…å†²çªï¼Œè¿™æ ·ä¼šæœ‰å¥½ç»“æœã€‚è€Œå¯¹äºæ±‚åã€å©šæ‹å’Œå†³ç­–ï¼Œä¹Ÿéƒ½éœ€è¦æ…é‡è¡Œäº‹ï¼Œé¿å…ç›²ç›®è¿½æ±‚ï¼Œé€€è®©è®©äººï¼Œå¯åŠ©äº‹ä¸šã€å©šå§»å’Œå†³ç­–çš„å‘å±•ã€‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>åœ¨å‘¨æ˜“ä¸­ï¼Œéœ€å¦è±¡å¾ç€ä»€ä¹ˆï¼Ÿ</td>\n",
       "      <td>éœ€å¦æ˜¯ä¸€ä¸ªå åœå¦è±¡ï¼Œåœ¨å‘¨æ˜“å¦è±¡ä¸­ï¼Œå®ƒç”±ä¸‹å¦ä¹¾å’Œä¸Šå¦åç»„æˆã€‚åè±¡å¾ç€äº‘ï¼Œä¹¾è±¡å¾ç€å¤©ï¼Œäº‘èšäºå¤©ï¼Œå½¢æˆäº†ç­‰å¾…æ—¶æœºçš„å¦è±¡ã€‚è¿™æ˜¯ä¸€ä¸ªå¤§å‰å¤§åˆ©çš„åœé—®ï¼Œç‰¹åˆ«é€‚åˆæ¶‰æ°´æ¸¡æ²³ã€‚æ ¹æ®ã€Šè±¡è¾ã€‹ï¼Œå›å­è§‚æ­¤å¦è±¡ï¼Œå¯ä»¥å®´é¥®å®‰ä¹ï¼Œå¾…æ—¶è€ŒåŠ¨ã€‚\\n\\néœ€å¦çš„æ ¸å¿ƒå“²å­¦æ˜¯ï¼šç¨³æ‰ç¨³æ‰“ï¼Œä¸å¯å†’å¤±è¡ŒåŠ¨ï¼Œè§‚æ—¶å¾…å˜ï¼Œè€å¿ƒç­‰å¾…ã€‚åœ¨äº‹ä¸šä¸Šï¼Œéœ€è¦å®¡æ—¶åº¦åŠ¿ï¼Œå®ˆä¸­æ­£ï¼Œä¸å¯æ€¥è¿›ï¼Œè‡ªä¿¡å……æ»¡ï¼Œå¯åŒ–é™©ä¸ºå¤·ã€‚åœ¨ç»å•†ä¸­ï¼Œå¿…é¡»å……æ»¡è€å¿ƒï¼Œåˆ›é€ æ¡ä»¶å’Œæœºä¼šï¼Œè¡Œäº‹å…‰æ˜ç£Šè½ï¼Œç­‰åˆ°æ—¶æœºæˆç†Ÿåå¿…ç„¶ä¸€å¸†é£é¡ºã€‚åœ¨æ„Ÿæƒ…æ–¹é¢ï¼Œäº¦éœ€æ…é‡ï¼ŒåŸ¹å…»æ„Ÿæƒ…ï¼Œä»¥è¯šå®ã€çƒ­æƒ…ç›¸å¾…ï¼Œæ—¶æœºæˆç†Ÿåå¯ä»¥æœ‰è‰¯å¥½çš„ç»“æœã€‚\\n\\néœ€å¦ç´§éšå¤å®«æ¸¸é­‚å¦ï¼Œé¢„ç¤ºç€è¸Œèº‡å’ŒæœŸå¾…ã€‚å¾—æ­¤å¦è€…ï¼Œéœ€è¦æ—¶æœºå°šæœªæˆç†Ÿï¼Œéœ€è¦è€å¿ƒç­‰å¾…ï¼Œæ€¥è¿›åä¼šè§å‡¶é™©ã€‚</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸  The dataset doesn't have 'validation' splitï¼Œ not evaluating.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "268d605db027490cad432e508014aa3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n",
      "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,899,392 || all params: 6,247,483,392 || trainable%: 0.06241540401681151\n",
      "dataset_name=data/zhouyi_dataset_20240118_163659.csv\n",
      "training_args num_train_epochs: 3, logging_steps: 1, eval_steps: 1, save_steps: 10, per_device_train_batch_size: 8, , gradient_accumulation_steps: 1\n",
      "start train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 07:07, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.672500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.701000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.272900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.395500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.951000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.685900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.522200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.138600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.022000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.764000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.532700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.224000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.752200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.841700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.484900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.488200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.091200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.764800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.816200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.590900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.435400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.285300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.262600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.190800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.123000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.084200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.055000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.066900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.031800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.049500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.027400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.021900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.018300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.019100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.013700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.013600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.011000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.009500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.008600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.007300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.006600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.006100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.005900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.006100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.005100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.004600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.004900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.004300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.004300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.004300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.004200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.004100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.003800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.004300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.004200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.004200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end train.\n",
      "âœ… fine tuned model saved to path: models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_163659\n",
      "\n",
      "================================================================================\n",
      "ğŸ” Train/Eval with dataset: data/zhouyi_dataset_handmade.csv\n",
      "================================================================================\n",
      "\n",
      "ğŸ”§ Releasing GPU ...\n",
      "loading dataset_name:data/zhouyi_dataset_handmade.csv\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['content', 'summary'],\n",
      "        num_rows: 8\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>å¤å¦</td>\n",
       "      <td>å¤å¦åŸæ–‡\\nå¤ã€‚å…ƒï¼Œäº¨ï¼Œåˆ©ç‰é©¬ä¹‹è´ã€‚å›å­æœ‰æ”¸å¾€ï¼Œå…ˆè¿·åå¾—ä¸»ã€‚åˆ©è¥¿å—å¾—æœ‹ï¼Œä¸œåŒ—ä¸§æœ‹ã€‚å®‰è´ï¼Œå‰ã€‚\\nè±¡æ›°ï¼šåœ°åŠ¿å¤ï¼Œå›å­ä»¥åšå¾·è½½ç‰©ã€‚\\nç™½è¯æ–‡è§£é‡Š\\nå¤å¦ï¼šå¤§å‰å¤§åˆ©ã€‚å é—®é›Œé©¬å¾—åˆ°å‰å…†ã€‚å›å­å‰å»æ—…è¡Œï¼Œå…ˆè¿·å¤±è·¯é€”ï¼Œåæ¥æ‰¾åˆ°ä¸»äººï¼Œå‰åˆ©ã€‚è¥¿å—è¡Œè·å¾—è´¢ç‰©ï¼Œä¸œåŒ—è¡Œä¸§å¤±è´¢ç‰©ã€‚å é—®å®šå±…ï¼Œå¾—åˆ°å‰å…†ã€‚\\nã€Šè±¡è¾ã€‹è¯´ï¼šå¤§åœ°çš„å½¢åŠ¿å¹³é“ºèˆ’å±•ï¼Œé¡ºæ‰¿å¤©é“ã€‚å›å­è§‚æ­¤å¦è±¡ï¼Œå–æ³•äºåœ°ï¼Œä»¥æ·±åšçš„å¾·è¡Œæ¥æ‰¿æ‹…é‡å¤§çš„è´£ä»»ã€‚\\nã€Šæ–­æ˜“å¤©æœºã€‹è§£\\nå¤å¦å¤ä¸Šå¤ä¸‹ï¼Œä¸ºå¤å®«æœ¬ä½å¦ã€‚å¤å¦ä¸ºæŸ”é¡ºï¼Œä¸ºåœ°æ°”èˆ’å±•ä¹‹è±¡ï¼Œå…·æœ‰çº¯é˜´ä¹‹æ€§ï¼Œå…ˆå¤±é“è€Œåå¾—ä¸»ï¼Œå®œå¾€è¥¿å—ï¼Œè¥¿å—å¯å¾—åˆ°æœ‹å‹ã€‚\\nåŒ—å®‹æ˜“å­¦å®¶é‚µé›è§£\\næŸ”é¡ºå’Œé™ï¼Œåšè½½ä¹‹åŠŸï¼›é™å®ˆå®‰é¡ºï¼Œå¦„åŠ¨æ‹›æŸã€‚\\nå¾—æ­¤å¦è€…ï¼Œå®œé¡ºä»è¿åŠ¿ï¼Œä»¥é™åˆ¶åŠ¨ï¼Œä¸å®œç‹¬ç«‹è°‹äº‹ï¼Œé¡ºä»ä»–äººï¼Œä¸€èµ·åˆä½œï¼Œå¯æˆå¤§äº‹ã€‚\\nå°æ¹¾å›½å­¦å¤§å„’å‚…ä½©è£è§£\\næ—¶è¿ï¼šä¸ºäººåšé“ï¼Œå£°åè¿œä¼ ã€‚\\nè´¢è¿ï¼šæ»¡è½½è€Œå½’ã€‚\\nå®¶å®…ï¼šå®¶åº­å®‰ç¨³ï¼›å©šå«å¤§å‰ã€‚\\nèº«ä½“ï¼šæŸ”è½¯è¿åŠ¨ã€‚\\nä¼ ç»Ÿè§£å¦\\nè¿™ä¸ªå¦æ˜¯åŒå¦ï¼ˆä¸‹å¤ä¸Šå¤ï¼‰ç›¸å ï¼Œé˜´æ€§ã€‚è±¡å¾åœ°ï¼ˆä¸ä¹¾å¦ç›¸åï¼‰ï¼Œé¡ºä»å¤©ï¼Œæ‰¿è½½ä¸‡ç‰©ï¼Œä¼¸å±•æ— ç©·æ— å°½ã€‚å¤å¦ä»¥é›Œé©¬ä¸ºè±¡å¾ï¼Œè¡¨æ˜åœ°é“ç”Ÿè‚²æŠšå…»ä¸‡ç‰©ï¼Œè€Œåˆä¾å¤©é¡ºæ—¶ï¼Œæ€§æƒ…æ¸©é¡ºã€‚å®ƒä»¥â€œå…ˆè¿·åå¾—â€è¯æ˜â€œå¤â€é¡ºä»â€œä¹¾â€ï¼Œä¾éšâ€œä¹¾â€ï¼Œæ‰èƒ½æŠŠæ¡æ­£ç¡®æ–¹å‘ï¼Œéµå¾ªæ­£é“ï¼Œè·å–å‰åˆ©ã€‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ä¹¾å¦</td>\n",
       "      <td>ä¹¾å¦åŸæ–‡\\nä¹¾ã€‚å…ƒï¼Œäº¨ï¼Œåˆ©ï¼Œè´ã€‚\\nè±¡æ›°ï¼šå¤©è¡Œå¥ï¼Œå›å­ä»¥è‡ªå¼ºä¸æ¯ã€‚\\n\\nç™½è¯æ–‡è§£é‡Š\\nä¹¾å¦ï¼šå¤§å‰å¤§åˆ©ï¼Œå‰åˆ©çš„è´åœã€‚\\nã€Šè±¡è¾ã€‹è¯´ï¼šå¤©é“åˆšå¥ï¼Œè¿è¡Œä¸å·²ã€‚å›å­è§‚æ­¤å¦è±¡ï¼Œä»è€Œä»¥å¤©ä¸ºæ³•ï¼Œè‡ªå¼ºä¸æ¯ã€‚\\n\\nã€Šæ–­æ˜“å¤©æœºã€‹è§£\\nä¹¾è±¡å¾å¤©ï¼Œå…­é˜³çˆ»æ„æˆä¹¾å¦ï¼Œä¸ºã€Šæ˜“ç»ã€‹å…­åå››å¦ä¹‹é¦–ã€‚çº¯é˜³åˆšå»ºï¼Œå…¶æ€§åˆšå¼ºï¼Œå…¶è¡ŒåŠ²å¥ï¼Œå¤§é€šè€Œè‡³æ­£ï¼Œå…†ç¤ºå¤§é€šè€Œæœ‰åˆ©ï¼Œä½†é¡»è¡Œæ­£é“ï¼Œæ–¹å¯æ°¸è¿œäº¨é€šã€‚\\n\\nåŒ—å®‹æ˜“å­¦å®¶é‚µé›è§£\\nåˆšå¥æ—ºç››ï¼Œå‘è‚²ä¹‹åŠŸï¼›å®Œäº‹é¡ºåˆ©ï¼Œè°¨é˜²å¤ªå¼ºã€‚\\nå¾—æ­¤å¦è€…ï¼Œå¤©è¡Œåˆšå¥ï¼Œè‡ªå¼ºä¸æ¯ï¼Œååˆ©åŒæ”¶ä¹‹è±¡ï¼Œå®œæŠŠæ¡æœºä¼šï¼Œäº‰å–æˆæœã€‚å¥³äººå¾—æ­¤å¦åˆ™æœ‰è¿‡äºåˆšç›´ä¹‹å«Œã€‚\\n\\nä¼ ç»Ÿè§£å¦\\nè¿™ä¸ªå¦æ˜¯åŒå¦ï¼ˆä¸‹ä¹¾ä¸Šä¹¾ï¼‰ç›¸å ã€‚è±¡å¾å¤©ï¼Œå–»é¾™ï¼ˆå¾·æ‰çš„å›å­ï¼‰ï¼Œåˆè±¡å¾çº¯ç²¹çš„é˜³å’Œå¥ï¼Œè¡¨æ˜å…´ç››å¼ºå¥ã€‚ä¹¾å¦æ˜¯æ ¹æ®ä¸‡ç‰©å˜é€šçš„é“ç†ï¼Œä»¥â€œå…ƒã€äº¨ã€åˆ©ã€è´â€ä¸ºå¦è¾ï¼Œè¡¨ç¤ºå‰ç¥¥å¦‚æ„ï¼Œæ•™å¯¼äººéµå®ˆå¤©é“çš„å¾·è¡Œã€‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>æ°´å¤©éœ€å¦</td>\n",
       "      <td>éœ€å¦åŸæ–‡ï¼šéœ€ã€‚æœ‰å­šï¼Œå…‰äº¨ï¼Œè´å‰ã€‚åˆ©æ¶‰å¤§å·ã€‚è±¡æ›°ï¼šäº‘ä¸Šäºå¤©ï¼Œéœ€ï¼›å›å­ä»¥é¥®é£Ÿå®´ä¹ã€‚ç™½è¯æ–‡è§£é‡Šï¼šéœ€å¦ä»£è¡¨ä¿˜è™ï¼Œå¤§å‰å¤§åˆ©ï¼Œé€‚å®œæ¶‰æ°´è¿‡æ²³ã€‚ã€Šè±¡è¾ã€‹è¯´ï¼šä¸Šå¦ä¸ºåï¼Œè±¡å¾äº‘ï¼›ä¸‹å¦ä¸ºä¹¾ï¼Œè±¡å¾å¤©ã€‚äº‘èšå¤©ä¸Šï¼Œå¾…é™é›¨ï¼Œå›å­è§‚æ­¤å¦ï¼Œå®œå®´é¥®å®‰ä¹ï¼Œå¾…æ—¶è€ŒåŠ¨ã€‚ã€Šæ–­æ˜“å¤©æœºã€‹è§£ï¼šéœ€å¦åä¸Šä¹¾ä¸‹ï¼Œè±¡å¾è¸Œèº‡æœŸå¾…ï¼Œåˆšå¼ºé¢å¯¹é™©é˜»ï¼Œå®œç­‰å¾…ï¼Œæ¶‰å¤§å·åˆ©ã€‚åŒ—å®‹æ˜“å­¦å®¶é‚µé›è§£ï¼šé‡é˜»ä¸è¿›ï¼Œå¤§å™¨æ™šæˆï¼Œéœ€è€å¿ƒç­‰å¾…ã€‚å°æ¹¾å›½å­¦å¤§å„’å‚…ä½©è£è§£ï¼šæ—¶è¿éœ€è€å¿ƒç­‰å¾…ï¼Œè´¢è¿èµ„æœ¬æœªé›†ï¼Œå®¶å®…å¹³å®‰ï¼Œèº«ä½“è°ƒé¥®é£Ÿä»¥å¥åº·ã€‚ä¼ ç»Ÿè§£å¦ï¼šå¼‚å¦ï¼ˆä¸‹ä¹¾ä¸Šåï¼‰ï¼Œåˆšé€¢é™©ï¼Œå®œç¨³å¥ï¼Œè§‚æ—¶å¾…å˜ï¼Œå¿…æˆåŠŸã€‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>å±±æ°´è’™å¦</td>\n",
       "      <td>è’™å¦åŸæ–‡ï¼šè’™ã€‚äº¨ã€‚åŒªæˆ‘æ±‚ç«¥è’™ï¼Œç«¥è’™æ±‚æˆ‘ã€‚åˆç­®å‘Šï¼Œå†ä¸‰æ¸ï¼Œæ¸åˆ™ä¸å‘Šã€‚åˆ©è´ã€‚è±¡æ›°ï¼šå±±ä¸‹å‡ºæ³‰ï¼Œè’™ã€‚å›å­ä»¥æœè¡Œè‚²å¾·ã€‚ç™½è¯æ–‡è§£é‡Šï¼šè’™å¦é€šæ³°ã€‚ä¸æ˜¯æˆ‘æ±‚å¹¼ç¨šä¹‹äººï¼Œè€Œæ˜¯å¹¼ç¨šä¹‹äººæ±‚æˆ‘ã€‚åˆæ¬¡å åœè¢«å‘ŠçŸ¥ï¼Œè½»æ…¢å åœåˆ™ä¸å†å‘ŠçŸ¥ã€‚å åœå‰åˆ©ã€‚ã€Šè±¡è¾ã€‹è¯´ï¼šå¦è±¡ä¸ºå±±ä¸‹æœ‰æ³‰ï¼Œå–æ³•äºå±±æ³‰æœæ•¢åšæ¯…ï¼ŒåŸ¹å…»å“å¾·ã€‚ã€Šæ–­æ˜“å¤©æœºã€‹è§£ï¼šè’™å¦è‰®ä¸Šåä¸‹ï¼Œè±¡å¾è’™æ˜§ï¼Œä¸»ç–‘æƒ‘ä¸å‰ï¼Œå¤šå¿§æ„ï¼Œå‡¶å…†ã€‚åŒ—å®‹æ˜“å­¦å®¶é‚µé›è§£ï¼šæ™ºæ…§æœªå¼€ï¼ŒçŠ¹è±«ä¸å†³ï¼Œéœ€é¡ºå¸ˆå‹æ•™å¯¼å¯æ™ºã€‚å°æ¹¾å›½å­¦å¤§å„’å‚…ä½©è£è§£ï¼šæ—¶è¿è“„å¾·å‡ºä¸–ï¼Œè´¢è¿çŸ¿ä¸šæœå†³å‰ï¼Œå®¶å®…å›å­å±…å‰ï¼Œå©šå§»ä¹‹å§‹ï¼Œèº«ä½“é©±é‚ªä¿å®‰ã€‚ä¼ ç»Ÿè§£å¦ï¼šå¼‚å¦ï¼ˆä¸‹åä¸Šè‰®ï¼‰ï¼Œå±±ä¸‹æœ‰é™©ä»å‰è¿›ï¼Œä¸ºè’™æ˜§ï¼ŒæŠŠæ¡æ—¶æœºè¡ŒåŠ¨æ°æ—¶ï¼Œå¯è’™é€šè¾¾ä¹‹è±¡ã€‚å¤§è±¡ï¼šè’™ä¸ºæ˜æ— æ‰€è§ï¼Œå®œå¯è’™ã€‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>æ°´é›·å±¯å¦</td>\n",
       "      <td>å±¯å¦åŸæ–‡ï¼šå±¯ã€‚å…ƒï¼Œäº¨ï¼Œåˆ©ï¼Œè´ã€‚å‹¿ç”¨ï¼Œæœ‰æ”¸å¾€ï¼Œåˆ©å»ºä¾¯ã€‚è±¡æ›°ï¼šäº‘ï¼Œé›·ï¼Œå±¯ï¼›å›å­ä»¥ç»çº¶ã€‚ç™½è¯æ–‡è§£é‡Šï¼šå±¯å¦å¤§å‰å¤§åˆ©ï¼Œå‰åˆ©çš„å åœã€‚ä¸åˆ©äºå‡ºé—¨ã€‚æœ‰åˆ©äºå»ºå›½å°ä¾¯ã€‚ã€Šè±¡è¾ã€‹è¯´ï¼šå±¯çš„ä¸Šå¦ä¸ºåï¼Œåä¸ºäº‘ï¼Œä¸‹å¦ä¸ºéœ‡ï¼Œéœ‡ä¸ºé›·ã€‚äº‘è¡Œäºä¸Šï¼Œé›·åŠ¨äºä¸‹ï¼Œæ˜¯å±¯å¦çš„å¦è±¡ã€‚å›å­è§‚æ­¤å¦è±¡ï¼Œå–æ³•äºäº‘é›·ï¼Œç”¨äº‘çš„æ©æ³½å’Œé›·çš„å¨ä¸¥æ²»ç†å›½äº‹ã€‚ã€Šæ–­æ˜“å¤©æœºã€‹è§£ï¼šå±¯å¦åä¸Šéœ‡ä¸‹ï¼Œä¸ºåå®«äºŒä¸–å¦ã€‚å±¯å¦æ˜¾ç¤ºå›°éš¾ï¼ŒåŠ¨è€Œé€¢é™©ï¼Œéœ€åˆšæ¯…æœæ•¢æ–¹ä¸ºå‰ã€‚åŒ—å®‹æ˜“å­¦å®¶é‚µé›è§£ï¼šä¸‡ç‰©å§‹ç”Ÿï¼Œå¼€å§‹å›°éš¾ï¼›å…ˆåŠ³åé€¸ï¼Œè‹¦å°½ç”˜æ¥ã€‚å¾—æ­¤å¦è€…ï¼Œèº«å¤„å›°å¢ƒï¼Œå®œå®ˆä¸å®œè¿›ï¼Œéœ€è¾›åŠ³å…‹éš¾ï¼Œåˆéš¾åè§£ã€‚å°æ¹¾å›½å­¦å¤§å„’å‚…ä½©è£è§£ï¼šæ—¶è¿å®œå®ˆï¼Œè´¢è¿åˆ›ä¸šè‰°éš¾ï¼Œå®¶å®…åˆå©šä¸å’Œï¼Œèº«ä½“éœ€ä¿å…ƒæ°”ã€‚ä¼ ç»Ÿè§£å¦ï¼šå¼‚å¦ï¼ˆä¸‹éœ‡ä¸Šåï¼‰ï¼Œéœ‡ä¸ºé›·åŠ¨ï¼Œåä¸ºé›¨é™©ã€‚é›·é›¨äº¤åŠ ï¼Œç¯å¢ƒé™©æ¶ã€‚â€œå±¯â€æŒ‡ä¸‡ç‰©å§‹ç”Ÿï¼Œè‰°éš¾é™©é˜»ä¸­é¡ºæ—¶åº”è¿ï¼Œç»ˆå°†æ¬£è£ã€‚</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸  The dataset doesn't have 'validation' splitï¼Œ not evaluating.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965a7cb70c9e48a08a0718abf249dd43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n",
      "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,899,392 || all params: 6,247,483,392 || trainable%: 0.06241540401681151\n",
      "dataset_name=data/zhouyi_dataset_handmade.csv\n",
      "training_args num_train_epochs: 3, logging_steps: 1, eval_steps: 1, save_steps: 10, per_device_train_batch_size: 8, , gradient_accumulation_steps: 1\n",
      "start train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:21, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.173000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.173000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.784700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end train.\n",
      "âœ… fine tuned model saved to path: models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_handmade\n"
     ]
    }
   ],
   "source": [
    "# this cell is to train the model with custom dataset from data/zhouyi_dataset_xxx\n",
    "from datasets import load_dataset, ClassLabel, Sequence\n",
    "from transformers import AutoTokenizer, TrainingArguments, Trainer\n",
    "import torch\n",
    "from peft import TaskType, LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from peft.utils import TRANSFORMERS_MODELS_TO_LORA_TARGET_MODULES_MAPPING\n",
    "from transformers import AutoModel, BitsAndBytesConfig\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "# print ptorch info\n",
    "print(torch.__config__.show(), torch.cuda.get_device_properties(0))\n",
    "\n",
    "# ======================\n",
    "# 1. parameneters setup\n",
    "# ======================\n",
    "\n",
    "model_name_or_path = 'THUDM/chatglm3-6b'\n",
    "#train_data_path = 'data/zhouyi_dataset_20240118_163659.csv'\n",
    "#eval_data_path = None\n",
    "seed = 8\n",
    "max_input_length = 512\n",
    "max_output_length = 1536\n",
    "lora_rank = 16\n",
    "lora_alpha = 32\n",
    "lora_dropout = 0.05\n",
    "#resume_from_checkpoint = None\n",
    "prompt_text = ''\n",
    "compute_dtype = 'bf16'  # fp32 / fp16 / bf16\n",
    "\n",
    "# support multiple dataset_names to be tested\n",
    "dataset_names = [\n",
    "    \"data/zhouyi_dataset_20240118_152413.csv\",\n",
    "    \"data/zhouyi_dataset_20240118_163659.csv\",\n",
    "    \"data/zhouyi_dataset_handmade.csv\",\n",
    "    #\"shibing624/AdvertiseGen\",\n",
    "    #can add more dataset for test\n",
    "]\n",
    "\n",
    "# use small data for faster test...\n",
    "num_train_samples = 1000\n",
    "# use 0.1 of train data\n",
    "num_eval_samples = num_train_samples // 10\n",
    "\n",
    "# training paramenters setup\n",
    "per_device_train_batch_size = 8\n",
    "per_device_eval_batch_size = 8\n",
    "gradient_accumulation_steps = 1\n",
    "learning_rate = 1e-3\n",
    "num_train_epochs = 3\n",
    "#eval_steps = num_train_samples // (5 * per_device_train_batch_size * gradient_accumulation_steps)\n",
    "#save_steps = num_train_samples // (3 * per_device_train_batch_size * gradient_accumulation_steps)\n",
    "#logging_steps = num_train_samples // (15 * per_device_train_batch_size * gradient_accumulation_steps)\n",
    "logging_steps = 1\n",
    "eval_steps = 1\n",
    "save_steps = 10\n",
    "\n",
    "# dtype mapping\n",
    "_compute_dtype_map = {\n",
    "    'fp32': torch.float32,\n",
    "    'fp16': torch.float16,\n",
    "    'bf16': torch.bfloat16\n",
    "}\n",
    "\n",
    "# the tokenize function\n",
    "def tokenize_func(example, tokenizer, ignore_label_id=-100):\n",
    "    question = prompt_text + example['content']\n",
    "    if example.get('input', None) and example['input'].strip():\n",
    "        question += f'\\n{example[\"input\"]}'\n",
    "    answer = example['summary']\n",
    "    q_ids = tokenizer.encode(text=question, add_special_tokens=False)\n",
    "    a_ids = tokenizer.encode(text=answer, add_special_tokens=False)\n",
    "    if len(q_ids) > max_input_length - 2:\n",
    "        q_ids = q_ids[:max_input_length - 2]\n",
    "    if len(a_ids) > max_output_length - 1:\n",
    "        a_ids = a_ids[:max_output_length - 1]\n",
    "    input_ids = tokenizer.build_inputs_with_special_tokens(q_ids, a_ids)\n",
    "    question_length = len(q_ids) + 2\n",
    "    labels = [ignore_label_id] * question_length + input_ids[question_length:]\n",
    "    return {'input_ids': input_ids, 'labels': labels}\n",
    "\n",
    "# the DataCollator class\n",
    "class DataCollatorForChatGLM:\n",
    "    def __init__(self, pad_token_id: int, max_length: int = 2048, ignore_label_id: int = -100):\n",
    "        self.pad_token_id = pad_token_id\n",
    "        self.ignore_label_id = ignore_label_id\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __call__(self, batch: List[Dict[str, List]]) -> Dict[str, torch.Tensor]:\n",
    "        len_list = [len(d['input_ids']) for d in batch]\n",
    "        batch_max_len = max(len_list)\n",
    "\n",
    "        input_ids, labels = [], []\n",
    "        for len_of_d, d in sorted(zip(len_list, batch), key=lambda x: -x[0]):\n",
    "            pad_len = batch_max_len - len_of_d\n",
    "            ids = d['input_ids'] + [self.pad_token_id] * pad_len\n",
    "            label = d['labels'] + [self.ignore_label_id] * pad_len\n",
    "            if batch_max_len > self.max_length:\n",
    "                ids = ids[:self.max_length]\n",
    "                label = label[:self.max_length]\n",
    "            input_ids.append(torch.LongTensor(ids))\n",
    "            labels.append(torch.LongTensor(label))\n",
    "        return {\n",
    "            'input_ids': torch.stack(input_ids),\n",
    "            'labels': torch.stack(labels)\n",
    "        }\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
    "    display(HTML(df.to_html()))\n",
    "\n",
    "# function to free up mem    \n",
    "def freeup_mem():\n",
    "    print(\"\\nğŸ”§ Releasing GPU ...\")\n",
    "    import torch, gc\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    #%reset -f\n",
    "    \n",
    "# tain/eval for the datasets\n",
    "for dataset_name in dataset_names:\n",
    "    print(f\"\\n\" + \"=\"*80)\n",
    "    print(f\"ğŸ” Train/Eval with dataset: {dataset_name}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # call to freeup mem    \n",
    "    freeup_mem()\n",
    "\n",
    "    # ======================\n",
    "    # 1. load dataset\n",
    "    # ======================\n",
    "    print(f\"loading dataset_name:{dataset_name}\")\n",
    "    dataset = load_dataset(\"csv\", data_files=dataset_name)\n",
    "    # print out dataset\n",
    "    print(dataset)\n",
    "\n",
    "    # show random elements\n",
    "    show_random_elements(dataset[\"train\"], num_examples=5)\n",
    "\n",
    "    eval_dataset_loaded = None\n",
    "    if 'validation' in dataset:\n",
    "        eval_dataset_loaded = dataset['validation']\n",
    "    else:\n",
    "        print(\"âš ï¸  The dataset doesn't have 'validation' splitï¼Œ not evaluating.\")\n",
    "\n",
    "    # ======================\n",
    "    # 2. set the used train/eval samples\n",
    "    # ======================\n",
    "    if num_train_samples is not None and num_train_samples > 0 \\\n",
    "    and len(dataset['train']) >= num_train_samples:\n",
    "        print(f\"num_train_samples: {num_train_samples}\")\n",
    "        dataset['train'] = dataset['train'].select(range(num_train_samples))\n",
    "    if eval_dataset_loaded is not None and num_eval_samples is not None \\\n",
    "and num_eval_samples > 0 and len(eval_dataset_loaded) >= num_eval_samples:\n",
    "        print(f\"num_eval_samples: {num_eval_samples}\")\n",
    "        eval_dataset_loaded = eval_dataset_loaded.select(range(num_eval_samples))\n",
    "\n",
    "    # ======================\n",
    "    # 3. Tokenize\n",
    "    # ======================\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True, revision='b098244')\n",
    "\n",
    "    column_names = dataset['train'].column_names\n",
    "    tokenized_train = dataset['train'].map(\n",
    "        lambda x: tokenize_func(x, tokenizer), \n",
    "        batched=False, \n",
    "        remove_columns=column_names\n",
    "    )\n",
    "    tokenized_train = tokenized_train.shuffle(seed=seed)\n",
    "    tokenized_train = tokenized_train.flatten_indices()\n",
    "\n",
    "\n",
    "    tokenized_eval = None\n",
    "    if eval_dataset_loaded is not None:\n",
    "        column_names_eval = eval_dataset_loaded.column_names\n",
    "        tokenized_eval = eval_dataset_loaded.map(\n",
    "            lambda x: tokenize_func(x, tokenizer), \n",
    "            batched=False, \n",
    "            remove_columns=column_names_eval\n",
    "        )\n",
    "\n",
    "        tokenized_eval = tokenized_eval.shuffle(seed=seed)\n",
    "        tokenized_eval = tokenized_eval.flatten_indices()\n",
    "    \n",
    "    # ======================\n",
    "    # 4. init the model, LoRAã€QLoRA\n",
    "    # ======================\n",
    "    model = AutoModel.from_pretrained(\n",
    "        model_name_or_path,\n",
    "        quantization_config=BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type='nf4',\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_compute_dtype=_compute_dtype_map[compute_dtype]\n",
    "        ),\n",
    "        device_map='auto',\n",
    "        trust_remote_code=True,\n",
    "        revision='b098244'\n",
    "    )\n",
    "\n",
    "    model.supports_gradient_checkpointing = True  \n",
    "    model.gradient_checkpointing_enable()\n",
    "    model.enable_input_require_grads()\n",
    "\n",
    "    model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "\n",
    "    kbit_model = prepare_model_for_kbit_training(model)\n",
    "    target_modules = TRANSFORMERS_MODELS_TO_LORA_TARGET_MODULES_MAPPING['chatglm']\n",
    "    lora_config = LoraConfig(\n",
    "        target_modules=target_modules,\n",
    "        r=lora_rank,\n",
    "        lora_alpha=lora_alpha,\n",
    "        lora_dropout=lora_dropout,\n",
    "        bias='none',\n",
    "        inference_mode=False,\n",
    "        task_type=TaskType.CAUSAL_LM\n",
    "    )\n",
    "    qlora_model = get_peft_model(kbit_model, lora_config)\n",
    "    qlora_model.print_trainable_parameters()\n",
    "\n",
    "    # ======================\n",
    "    # 5. TrainingArguments & Trainer\n",
    "    # ======================\n",
    "\n",
    "    # Split the string by '/' and take the last part (the filename)\n",
    "    # \"data/zhouyi_dataset_20240118_163659.csv\"\n",
    "    print(f\"dataset_name={dataset_name}\")\n",
    "    filename = dataset_name.split('/')[-1]  # 'zhouyi_dataset_20240118_163659.csv'\n",
    "\n",
    "    # Split by '_' and take the parts after 'dataset'\n",
    "    # parts = filename.split('_')\n",
    "    # Assuming structure: ... dataset YYYYMMDD HHMMSS .csv\n",
    "    # date_part = parts[-2]  # '20240118'\n",
    "    # time_part = parts[-1].split('.')[0]  # '163659'\n",
    "    # timestamp = f\"{date_part}_{time_part}\"\n",
    "    # zhouyi_dataset_20240118_163659\n",
    "    part1 = filename.split('.')[-2]\n",
    "    saved_dir = f\"models/{model_name_or_path}-epoch{num_train_epochs}-{part1}\"\n",
    "    print(f\"training_args num_train_epochs: {num_train_epochs}, \\\n",
    "logging_steps: {logging_steps}, eval_steps: {eval_steps}, save_steps: {save_steps}\\\n",
    ", per_device_train_batch_size: {per_device_train_batch_size}, , gradient_accumulation_steps: {gradient_accumulation_steps}\")\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=saved_dir,\n",
    "        per_device_train_batch_size=per_device_train_batch_size,\n",
    "        per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        learning_rate=learning_rate,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        warmup_ratio=0.1,\n",
    "        evaluation_strategy=\"steps\" if eval_dataset_loaded is not None else \"no\",\n",
    "        eval_steps=eval_steps,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=save_steps,\n",
    "        logging_steps=logging_steps,\n",
    "        optim=\"adamw_torch\",\n",
    "        fp16=True,\n",
    "    )\n",
    "\n",
    "    data_collator = DataCollatorForChatGLM(pad_token_id=tokenizer.pad_token_id)\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=qlora_model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_eval,\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "\n",
    "    # ======================\n",
    "    # 6. train & auto print the train/validation loss\n",
    "    # ======================\n",
    "    print(f\"start train...\")\n",
    "    trainer.train()\n",
    "    print(f\"end train.\")\n",
    "\n",
    "    # ======================\n",
    "    # 7. saved the tuned model\n",
    "    # ======================\n",
    "    trainer.model.save_pretrained(saved_dir)\n",
    "    print(f\"âœ… fine tuned model saved to path: {saved_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6409c3d9-8f9a-45cd-9390-bd1aefb41a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”§ Releasing GPU ...\n",
      "ğŸ” Loading the base model: THUDM/chatglm3-6b (not fine tuned)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ede20c088f89468d99eb22ba12efd7d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ” Loading PEFT model from: models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_152413\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Comparing result for query: è§£é‡Šä¸‹ä¹¾å¦æ˜¯ä»€ä¹ˆï¼Ÿ\n",
      "================================================================================\n",
      "ğŸ“Base model response:\n",
      "ä¹¾å¦æ˜¯å‘¨æ˜“ä¸­çš„ä¸€å¦ï¼Œä»£è¡¨å¤©ï¼Œè±¡å¾ç€åˆšå¥å¼ºåŠ²çš„ç‰¹æ€§ã€‚å®ƒç”±ä¸¤ä¸ªé˜³çˆ»å¤¹ä¸€ä¸ªé˜´çˆ»æ„æˆï¼Œè±¡å¾ç€é˜³åˆšä¹‹æ°”çš„èšé›†ã€‚ä¹¾å¦è±¡å¾ç€åˆšå¥ã€å¼ºç››ã€ç‹¬ç«‹è‡ªä¸»çš„ç‰¹æ€§ï¼Œä»£è¡¨ç€é”åˆ©ã€ç›´ç‡ã€æœæ•¢çš„æ€§æ ¼ã€‚åœ¨ã€Šæ˜“ç»ã€‹ä¸­ï¼Œä¹¾å¦é¢„ç¤ºç€å¥æ—ºã€å¼ºç››ã€ç‹¬ç«‹è‡ªä¸»çš„æƒ…å†µï¼Œå¹¶å¸¦æ¥å‰å…†ã€‚\n",
      "\n",
      "ä¹¾å¦çš„å¦è¾æè¿°äº†é˜³çˆ»åœ¨å‰çš„ç‰¹æ€§ï¼Œå¼ºè°ƒåˆšå¥ã€é”åˆ©å’Œæœæ•¢ï¼Œå¹¶é¢„ç¤ºç€å¯èƒ½å¸¦æ¥æˆåŠŸã€‚åŒæ—¶ï¼Œéœ€è¦æ³¨æ„å‡†å¤‡å¥½äº†ç‡ƒæ–™ï¼ˆå‰è¿›ï¼‰æ‰èƒ½å‰è¿›ï¼Œè€Œé˜´çˆ»æç¤ºéœ€è¦è°¨æ…è¡Œäº‹ï¼Œä»¥å…å¸¦æ¥ç¾éš¾ã€‚åœ¨å†³ç­–æ—¶ï¼Œåº”å½“ç§¯æåˆšå¥ï¼Œè€Œè°¨æ…æŸ”å¼±ï¼Œä»¥äº‹ä¸šæˆåŠŸä¸ºå‰ï¼Œå¦äº‹ä¸šå¤±è´¥ä¸ºå‡¶ã€‚\n",
      "\n",
      "åœ¨å¤ä»£ï¼Œäººä»¬è®¤ä¸ºä¹¾å¦ä»£è¡¨å¤©ï¼Œè±¡å¾åˆšå¥ã€å¼ºç››ã€ç‹¬ç«‹è‡ªä¸»çš„ç‰¹æ€§ã€‚åœ¨å†³ç­–æ—¶ï¼Œåº”è¯¥ç§¯æåˆšå¥ï¼Œè€Œè°¨æ…æŸ”å¼±ï¼Œä»¥äº‹ä¸šæˆåŠŸä¸ºå‰ï¼Œå¦äº‹ä¸šå¤±è´¥ä¸ºå‡¶ã€‚åŒæ—¶ï¼Œç»å•†æ±‚è°‹é¡»è°¨æ…é€‰æ‹©æ–¹å‘ï¼ŒåŒæ—¶æ³¨æ„åˆä½œï¼Œä»¥åˆ©ç›Šæœ€å¤§åŒ–ä¸ºç›®æ ‡ã€‚ç»å•†æ±‚è°‹æ–¹é¢ï¼Œé¡»å¾—é‡è´¤äººï¼Œæ ¹æ®æ—¶åŠ¿å˜åŒ–ï¼ŒæŠ“ä½æœºé‡ã€‚åœ¨äº‹ä¸šä¸­ï¼Œéœ€è¦ç§¯æåˆšå¥ï¼ŒåŒæ—¶è°¨æ…æŸ”å¼±ï¼Œä»¥äº‹ä¸šæˆåŠŸä¸ºå‰ï¼Œå¦äº‹ä¸šå¤±è´¥ä¸ºå‡¶ã€‚\n",
      "\n",
      "ä¹¾å¦çš„æ ¸å¿ƒå“²å­¦æ˜¯ï¼šåˆšå¥å¼ºåŠ²ï¼Œé˜³åˆšä¹‹æ°”çš„èšé›†ï¼Œä»£è¡¨ç€é”åˆ©ã€ç›´ç‡ã€æœæ•¢çš„æ€§æ ¼ã€‚åœ¨å†³ç­–æ—¶ï¼Œåº”è¯¥ç§¯æåˆšå¥ï¼Œè€Œè°¨æ…æŸ”å¼±ï¼Œä»¥äº‹ä¸šæˆåŠŸä¸ºå‰ï¼Œå¦äº‹ä¸šå¤±è´¥ä¸ºå‡¶ã€‚     \n",
      "ğŸ‘‰Fine tuned model (models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_152413) response: \n",
      "[gMASK]sop è§£é‡Šä¸‹ä¹¾å¦æ˜¯ä»€ä¹ˆï¼Ÿ ä¹¾å¦æ˜¯å‘¨æ˜“ä¸­çš„ä¸€å¦ï¼Œä»£è¡¨å¤©ï¼Œè±¡å¾åˆšå¥å¼ºåŠ²çš„ç‰¹æ€§ã€‚å®ƒç”±ä¸¤ä¸ªä¹¾å¦å åŠ è€Œæˆï¼Œä»£è¡¨ç€åˆšå¥å¼ºåŠ²çš„ç‰¹æ€§ã€‚åœ¨åœé—®ä¸­ï¼Œä¹¾å¦é¢„ç¤ºç€å‰ç¥¥å¦‚æ„ï¼ŒåŒæ—¶ä¹Ÿæé†’é¢ä¸´ç€ä¿®å…»å’Œæˆé•¿çš„è¿‡ç¨‹ã€‚åœ¨å†³ç­–ä¸­ï¼Œæ„å‘³ç€åˆšå¥å¼ºåŠ²çš„ç‰¹æ€§ä¼šå¸¦æ¥å‰ç¥¥å¦‚æ„ï¼Œä½†éœ€è¦è­¦æƒ•å¯èƒ½ä¼šå¸¦æ¥å›°éš¾ã€‚\n",
      "\n",
      "ä¹¾å¦çš„ç‰¹æ€§åŒ…æ‹¬ï¼š\n",
      "\n",
      "1. å‰ç¥¥ï¼šä¹¾å¦é¢„ç¤ºç€äº‹æƒ…é¡ºåˆ©ï¼Œå¸¦æ¥å‰ç¥¥å¦‚æ„ã€‚\n",
      "2. åˆšå¥ï¼šä¹¾å¦ä»£è¡¨åˆšå¥å¼ºåŠ²çš„ç‰¹æ€§ï¼Œè¡¨ç¤ºäº‹æƒ…çš„å‘å±•éœ€è¦åˆšå¥å¼ºåŠ²çš„æ¯…åŠ›ã€‚\n",
      "3. çªå‡ºï¼šä¹¾å¦å¼ºè°ƒåˆšå¥å¼ºåŠ²çš„ç‰¹æ€§ï¼Œå…·æœ‰çªå‡ºå’Œé¢†å¯¼èƒ½åŠ›ã€‚\n",
      "4. å…»ï¼šä¹¾å¦æ„å‘³ç€å…»æˆäº†åˆšå¥å¼ºåŠ²çš„ç‰¹æ€§ï¼Œèƒ½å¤Ÿå…»æˆäº†åšå®šçš„å“å¾·ã€‚\n",
      "\n",
      " summary:\n",
      "\n",
      "ä¹¾å¦ is a message from the I Ching, representing theå¤©, and it symbolizes the strong and powerful nature. It is composed of two dragons, each representing strength and power, and it represents the need for determination and perseverance in the face of adversity. The message is that of success and prosperity, and it highlights the importance of being strong and resolute in the face of challenges.\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Comparing result for query: å‘¨æ˜“ä¸­çš„è®¼å¦æ˜¯ä»€ä¹ˆ\n",
      "================================================================================\n",
      "ğŸ“Base model response:\n",
      "è®¼å¦æ˜¯å‘¨æ˜“å¦è±¡ä¸­çš„ä¸€æšå¦ï¼Œç”±ä¸Šå¦åï¼ˆæ°´ï¼‰å’Œä¸‹å¦ä¹¾ï¼ˆå¤©ï¼‰ç»„æˆï¼Œä»£è¡¨å¤©ä¸Šæœ‰æ°´ï¼Œè±¡å¾åˆšå¥å…¬æ­£ã€‚è®¼å¦çš„å¦ä¹‰æ˜¯ï¼šå¤©ä¸Šæœ‰æ°´ï¼Œäººæœ‰å¿—ã€‚ both parties are willing to fight for what they believe is right.\n",
      "\n",
      "è®¼å¦çš„æ—¶è¿æ˜¯ï¼š\n",
      "\n",
      "åˆçˆ»ï¼šé˜³åˆšä¹‹å¦ï¼Œåˆšä¸­æœ‰å¥ï¼Œå®œåˆå…¥ç¤¾ä¼šï¼Œåˆšå¼ºcraftsman\n",
      "\n",
      "äºŒçˆ»ï¼šé˜³åˆšä¹‹å¦ï¼Œåˆšä¸­æœ‰å¥ï¼Œå®œæ±‚åé€åˆ©ï¼Œåˆ©è§ancestors\n",
      "\n",
      "ä¸‰çˆ»ï¼šé˜³åˆšä¹‹å¦ï¼Œåˆšä¸­æœ‰å¥ï¼Œå®œå©šå«ä¹‹å‰ï¼Œå®œåˆ©è§å¤«\n",
      "\n",
      "å››çˆ»ï¼šé˜³åˆšä¹‹å¦ï¼Œåˆšä¸­æœ‰å¥ï¼Œå®œçˆ¶å–œå­ï¼Œçˆ¶åˆ©å­äº¦åˆ©\n",
      "\n",
      "è®¼å¦çš„è¿åŠ¿æŒ‡æ•°ä¸ºï¼šåˆ©ï¼Œåˆ©è§è´¢ç‘\n",
      "\n",
      "è®¼å¦çš„è¿åŠ¿æç¤ºï¼š\n",
      "\n",
      "åˆå…¥ç¤¾æœƒï¼Œåˆšå¼·craftsmanï¼Œå®œæ±‚åé€åˆ©ï¼Œå®œå©šå«ä¹‹å‰ï¼Œå®œåˆ©è§å¤«ï¼Œåˆšå¼·ä¸­æœ‰åˆ©ï¼Œå®œçˆ¶å–œå­ï¼Œçˆ¶åˆ©å­äº¦åˆ©ã€‚\n",
      "\n",
      "è®¼å¦çš„å®œè§£å®œå†³ï¼š\n",
      "\n",
      "è®¼å¦è§£å¦ä¸ºï¼šå†³å‰ï¼Œåˆå‡¶ååˆ©ã€‚decision will be made after the initial adversity.\n",
      "\n",
      "è®¼å¦çš„å åœæ–¹æ³•ï¼š\n",
      "\n",
      "è®¼å¦ä¹‹è±¡ä¸ºå¤©ä¸Šæœ‰æ°´ï¼Œäººæœ‰å¿—ã€‚æ•´ä½“è€Œè¨€ï¼Œåˆšå¥å…¬æ­£ï¼Œè¯´æ˜æœ‰åšæ¯…ä¸å±ˆçš„å“è´¨ã€‚ç„¶è€Œï¼Œåˆå…¥ç¤¾ä¼šï¼Œåˆšå¼ºcraftsmanï¼Œéœ€è¦æ±‚å©šè§ç‘ï¼Œåˆ©è§è´¢ç‘ã€‚\n",
      "\n",
      "è®¼å¦çš„æ•°å­—å¦è±¡ä¸ºï¼šè®¼å¦ï¼ˆ6å¦ï¼‰ï¼Œè±¡å¾åˆšå¥å…¬æ­£ï¼Œ both parties are willing to fight for what they believe is right.\n",
      "\n",
      "è®¼å¦çš„å“²å­¦åŸç†ï¼š\n",
      "\n",
      "è®¼å¦è¡¨ç¤ºåˆšå¥å…¬æ­£ï¼Œä½†æ˜¯éœ€è¦ pause ä¸€ä¸‹ï¼Œå› ä¸ºåˆå…¥ç¤¾ä¼šï¼Œåˆšå¼ºcraftsmanã€‚ overallè€Œè¨€ï¼Œåˆšå¼ºä¸­æœ‰åˆ©ï¼Œå®œçˆ¶å–œå­ï¼Œçˆ¶åˆ©å­äº¦åˆ©ã€‚å› æ­¤ï¼Œè®¼å¦çš„æ€»ä½“è¿æ°”çš„å®œè§£å®œå†³ä¸ºï¼šå†³å‰ï¼Œåˆå‡¶ååˆ©ã€‚     \n",
      "ğŸ‘‰Fine tuned model (models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_152413) response: \n",
      "[gMASK]sop å‘¨æ˜“ä¸­çš„è®¼å¦æ˜¯ä»€ä¹ˆå¦è±¡\n",
      "\n",
      " åœ¨å‘¨æ˜“ä¸­ï¼Œè®¼å¦æ˜¯ä¸€ä¸ªæå…·æ·±æ„çš„å¦è±¡ã€‚ä¸Šå¦ä¸ºä¹¾ï¼ˆå¤©ï¼‰ï¼Œä¸‹å¦ä¸ºåï¼ˆæ°´ï¼‰ï¼Œä¸¤è€…ç›¸èƒŒè€Œè¡Œï¼Œä»£è¡¨å¤©ä¸æ°´è¿è¡Œçš„çŠ¶å†µï¼Œè±¡å¾ç€äº‹ç†ä¹–èˆ›å’Œäº‰è®¼ä¹‹è±¡ã€‚è®¼å¦ä¸­æœ‰åˆ©å¯å›¾ï¼Œä½†å¿…é¡»è­¦æƒ•æˆ’æƒ§ï¼Œäº‹æƒ…ä¸­é—´å‰åˆ©ï¼Œä½†æœ€ç»ˆä¼šæœ‰å‡¶é™©ã€‚åœ¨åœå¦æ—¶ï¼Œåˆ©äºä¼šè§è´µæ—ç‹å…¬ï¼Œä½†ä¸åˆ©äºæ¶‰æ°´æ¸¡æ²³ã€‚\n",
      "\n",
      "è®¼å¦çš„æ ¸å¿ƒå“²å­¦æ˜¯ï¼šå¼€å§‹å¯èƒ½é¡ºåˆ©ï¼Œæœ‰æ‰€æ”¶è·ï¼Œä½†éšåä¼šé‡åˆ°å›°éš¾å’ŒæŒ«æŠ˜ã€‚å› æ­¤ï¼ŒåŠ¡å¿…æ…ä¹‹åˆæ…ï¼Œä¸å¾—å›ºæ‰§å·²è§ï¼Œé¿å…ä»‹å…¥è¯‰è®¼çº çº·çš„äº‰æ‰§ä¹‹ä¸­ã€‚é€€è®©è€Œä¸å›ºæ‰§ï¼Œæ±‚å¾—åŒ–è§£ï¼Œå®‰äºæ­£ç†ï¼Œå¯å…é™¤æ„å¤–ä¹‹ç¾ã€‚é™·å…¥äº‰è®¼ï¼Œå³ä½¿è·èƒœï¼Œæœ€åè¿˜å¾—å¤±å»ï¼Œå¾—ä¸å¿å¤±ã€‚\n",
      "\n",
      "è®¼å¦çš„ç»å•†æŒ‡å¼•æ˜¯ï¼šå’Œæ°”ç”Ÿè´¢ï¼Œåƒäºæ˜¯ç¦ï¼Œåˆ‡å‹¿è¿½æ±‚ä¸ä¹‰ä¹‹è´¢ã€‚åœ¨å•†ä¸šè°ˆåˆ¤ä¸­è¦åšæŒå…¬æ­£ã€å…¬å¹³ã€äº’åˆ©çš„åŸåˆ™ï¼Œå°½é‡é¿å…å‘ç”Ÿå†²çªã€‚\n",
      "\n",
      "å¯¹äºå†³ç­–ï¼Œè®¼å¦æé†’æˆ‘ä»¬ï¼Œäº‰å¼ºå¥½èƒœï¼Œä¸å®‰äºç°çŠ¶ï¼Œä¸ºæ”¹å˜å‘½è¿å’Œè¶…è¶Šä»–äººè€Œå¥‹æ–—ã€‚ä½†ç¼ºä¹æŒä¹‹ä»¥æ’çš„æ¯…åŠ›ï¼Œå®¹æ˜“å¾—ç½ªä»–äººï¼Œå¸¦æ¥è¯‰è®¼ä¹‹ç¾ã€‚å› æ­¤ï¼Œæ¥å—æ•™è®­ï¼Œå¼•ä»¥ä¸ºæˆ’ï¼Œå¯åŠŸæˆåå°±ã€‚\n",
      "\n",
      "è®¼å¦æ‰€è•´å«çš„æ™ºæ…§æ˜¯ï¼šåœ¨é¢å¯¹äº‰ç«¯å’Œå¼‚è§æ—¶ï¼Œè¦å–„äºé€€è®©å’Œæ±‚å’Œï¼Œåšå®ˆæ­£é“ï¼Œè°¨æ…å¤„äº‹ï¼Œä»¥é¿å…ä¸å¿…è¦çš„å†²çªå’ŒæŸå¤±ã€‚\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Comparing result for query: å¸ˆå¦æ˜¯ä»€ä¹ˆï¼Ÿ\n",
      "================================================================================\n",
      "ğŸ“Base model response:\n",
      "å¸ˆå¦æ˜¯ä¸€ä¸ªç”±åå¦ï¼ˆæ°´ï¼‰ä¸Šæ‰¿å¤å¦ï¼ˆåœ°ï¼‰ç»„æˆçš„å¦è±¡ï¼Œä»£è¡¨å†›é˜Ÿå’ŒæŒ‡æŒ¥å†›æƒ…çš„å¦è±¡ã€‚æ ¹æ®ã€Šè±¡è¾ã€‹ï¼Œè¿™ä¸€å¦è±¡è¢«è§£é‡Šä¸ºâ€œåœ°ä¸­æœ‰æ°´â€ï¼Œè±¡å¾ç€åƒå¤§åœ°ä¸€æ ·åŒ…å®¹å’Œå…»è‚²ä¼—äººã€‚æ ¹æ®ã€Šæ–­æ˜“å¤©æœºã€‹ï¼Œåªæœ‰å¾·é«˜æœ›é‡çš„é•¿è€…æ¥ç»Ÿç‡å†›é˜Ÿï¼Œæ‰èƒ½è·å¾—å‰ç¥¥æ— å’ã€‚\n",
      "\n",
      "æ®åŒ—å®‹æ˜“å­¦å®¶é‚µé›è§£ï¼Œå¾—å¸ˆå¦è€…å°†é¢ä¸´å›°éš¾é‡é‡ï¼Œå¿§å¿ƒåŠ³ä¼—ï¼Œå®œåŒ…å®¹åˆ«äººï¼Œè‰°è‹¦åŠªåŠ›ï¼Œæ‘’é™¤ä¸€åˆ‡å›°éš¾ã€‚å°æ¹¾å›½å­¦å¤§å„’å‚…ä½©è£è§£åˆ™æåˆ°ï¼Œå¯¹äºæ—¶è¿ã€è´¢è¿ã€å®¶å®…å’Œèº«ä½“ç­‰æ–¹é¢ä¼šæœ‰ç›¸åº”å½±å“ã€‚\n",
      "\n",
      "ä¼ ç»Ÿè§£å¦è®¤ä¸ºï¼Œå¸ˆå¦å…·æœ‰å…»å…µèšä¼—ã€å‡ºå¸ˆæ”»ä¼ä¹‹è±¡ï¼Œå½¼æ­¤æœ‰ä¼¤ï¼Œéš¾å¾—å®‰å®çš„å¤§è±¡ã€‚åœ¨è¿åŠ¿æ–¹é¢ï¼Œé¢„ç¤ºç€å›°éš¾é‡é‡ï¼Œéœ€è¦ä»¥æ­£è§„è¡Œäº‹ï¼Œè°¨å°æ…å¾®ï¼Œä¸¥äºå¾‹å·²ã€‚åœ¨äº‹ä¸šã€ç»å•†ã€æ±‚åã€å©šæ‹å’Œå†³ç­–ç­‰æ–¹é¢ï¼Œéƒ½éœ€è¦ä¿æŒå†·é™ã€è°¨æ…ï¼Œæ³¨æ„é¿å…æ•Œäººå’Œå›°éš¾å¸¦æ¥çš„ä¸åˆ©å½±å“ï¼Œå¿…èƒ½æˆåŠŸã€‚     \n",
      "ğŸ‘‰Fine tuned model (models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_152413) response: \n",
      "[gMASK]sop å¸ˆå¦æ˜¯ä»€ä¹ˆï¼Ÿ å¸ˆå¦æ˜¯ä¸€ä¸ªç”±åå¦ï¼ˆæ°´ï¼‰ä¸Šæ‰¿å¤å¦ï¼ˆåœ°ï¼‰ç»„æˆçš„å¦è±¡ï¼Œä»£è¡¨å†›é˜Ÿå’ŒæŒ‡æŒ¥å†›æƒ…çš„å¦è±¡ã€‚æ ¹æ®ã€Šè±¡è¾ã€‹ï¼Œè¿™ä¸€å¦è±¡è¢«è§£é‡Šä¸ºâ€œåœ°ä¸­æœ‰æ°´â€ï¼Œè±¡å¾ç€åƒå¤§åœ°ä¸€æ ·åŒ…å®¹å’Œå…»è‚²ä¼—äººã€‚æ ¹æ®ã€Šæ–­æ˜“å¤©æœºã€‹ï¼Œåªæœ‰å¾·é«˜æœ›é‡çš„é•¿è€…æ¥ç»Ÿç‡å†›é˜Ÿï¼Œæ‰èƒ½è·å¾—å‰ç¥¥æ— å’ã€‚\n",
      "\n",
      "\n",
      "æ®åŒ—å®‹æ˜“å­¦å®¶é‚µé›è§£ï¼Œå¾—å¸ˆå¦è€…å°†é¢ä¸´å›°éš¾é‡é‡ï¼Œå¿§å¿ƒåŠ³ä¼—ï¼Œå®œåŒ…å®¹åˆ«äººï¼Œè‰°è‹¦åŠªåŠ›ï¼Œæ‘’é™¤ä¸€åˆ‡å›°éš¾ã€‚å°æ¹¾å›½å­¦å¤§å„’å‚…ä½©è£è§£åˆ™æåˆ°ï¼Œå¯¹äºæ—¶è¿ã€è´¢è¿ã€å®¶å®…å’Œèº«ä½“ç­‰æ–¹é¢ä¼šæœ‰ç›¸åº”å½±å“ã€‚\n",
      "\n",
      "\n",
      "ä¼ ç»Ÿè§£å¦è®¤ä¸ºï¼Œå¸ˆå¦å…·æœ‰å…»å…µèšä¼—ã€å‡ºå¸ˆæ”»ä¼ä¹‹è±¡ï¼Œå½¼æ­¤æœ‰ä¼¤ï¼Œéš¾å¾—å®‰å®çš„å¤§è±¡ã€‚åœ¨è¿åŠ¿æ–¹é¢ï¼Œé¢„ç¤ºç€å›°éš¾é‡é‡ï¼Œéœ€è¦ä»¥æ­£è§„è¡Œäº‹ï¼Œè°¨å°æ…å¾®ï¼Œä¸¥äºå¾‹å·²ã€‚åœ¨äº‹ä¸šã€ç»å•†ã€æ±‚åã€å©šæ‹å’Œå†³ç­–ç­‰æ–¹é¢ï¼Œéƒ½éœ€è¦ä¿æŒå†·é™ã€è°¨æ…ï¼Œæ³¨æ„é¿å…æ•Œäººå’Œå›°éš¾å¸¦æ¥çš„ä¸åˆ©å½±å“ï¼Œå¿…èƒ½æˆåŠŸã€‚\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Comparing result for query: åœ°æ°´å¸ˆå¦æ˜¯ä»€ä¹ˆï¼Ÿ\n",
      "================================================================================\n",
      "ğŸ“Base model response:\n",
      "åœ°æ°´å¸ˆå¦æ˜¯å‘¨æ˜“ä¸­çš„ä¸€å¦ï¼Œå¯¹åº”ç€ã€Šæ˜“ç»ã€‹ä¸­çš„å¦è¾ï¼Œå¦è±¡æ˜¯åå¦ï¼Œä»£è¡¨æ°´ï¼Œè±¡å¾æ¶¦æ³½ä¸‡ç‰©ï¼Œå…·æœ‰æ»‹æ¶¦æ»‹å…»çš„ç‰¹ç‚¹ã€‚åœ¨åœé—®ä¸­ï¼Œè¡¨ç¤ºé¢ä¸´å›°å¢ƒï¼Œéœ€è¦åšéŸ§ä¸æ‹”çš„ç²¾ç¥æ¥åº”å¯¹ã€‚\n",
      "\n",
      "åœ¨è§£å¦ä¸­ï¼Œè®¤ä¸ºåœ°æ°´å¸ˆå¦é¢„ç¤ºç€SCOOPï¼ˆSpiritual Compass, Opportunity, Unity, Promiseï¼‰å¦è±¡ï¼Œå³ç²¾ç¥ compassæŒ‡ç¤ºæ–¹å‘ï¼Œæœºä¼šå¸¦æ¥å˜åŒ–ï¼Œå›¢ç»“å¸¦æ¥åŠ›é‡ï¼Œ promises å¸¦æ¥æˆåŠŸã€‚\n",
      "\n",
      "æ€»ç»“èµ·æ¥ï¼Œåœ°æ°´å¸ˆå¦æ„å‘³ç€å›°éš¾ä¸­éœ€è¦åšæŒï¼Œä¾é æ™ºæ…§å’Œå‹‡æ°”æ¥è§£å†³é—®é¢˜ã€‚     \n",
      "ğŸ‘‰Fine tuned model (models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_152413) response: \n",
      "[gMASK]sop åœ°æ°´å¸ˆå¦æ˜¯ä»€ä¹ˆï¼Ÿ åœ°æ°´å¸ˆå¦æ˜¯ä¸€ä¸ªç”±åå¦ï¼ˆæ°´ï¼‰ä¸Šæ‰¿å¤å¦ï¼ˆåœ°ï¼‰ç»„æˆçš„å¦è±¡ï¼Œä»£è¡¨çš„æ˜¯åœ°æ°´å¸ˆè¿™ä¸€å¦è±¡ã€‚æ ¹æ®ã€Šè±¡è¾ã€‹ï¼Œè¿™ä¸€å¦è±¡è¢«è§£é‡Šä¸ºâ€œåœ°ä¸­æœ‰æ°´â€ï¼Œè±¡å¾ç€åƒå¤§åœ°ä¸€æ ·åŒ…å®¹ç€æ°´ï¼Œä»¥åŠåƒå¤§åœ°ä¸€æ ·åŒ…å®¹ç€ä¼—äººå¿ƒçµçš„å¦è±¡ã€‚æ ¹æ®ã€Šæ–­æ˜“å¤©æœºã€‹ï¼Œåœ°æ°´å¸ˆå¦çš„åˆçˆ»ä¸ºé˜³ï¼Œä¸­çˆ»ä¸ºé˜³ï¼Œæœ«çˆ»ä¸ºé˜³ï¼Œè¡¨ç¤ºè¿™æ˜¯ä¸€ä¸ªå……æ»¡æ´»åŠ›å’Œå†³å¿ƒçš„å¦è±¡ã€‚\n",
      "\n",
      "æ ¹æ®ã€Šè±¡è¾ã€‹ï¼Œåœ°æ°´å¸ˆå¦è¢«è§£é‡Šä¸ºâ€œåœ°ä¸­æœ‰æ°´â€ï¼Œè±¡å¾ç€åƒå¤§åœ°ä¸€æ ·åŒ…å®¹ç€æ°´ï¼Œä»¥åŠåƒå¤§åœ°ä¸€æ ·åŒ…å®¹ç€ä¼—äººå¿ƒçµçš„å¦è±¡ã€‚æ ¹æ®ã€Šæ–­æ˜“å¤©æœºã€‹ï¼Œåœ°æ°´å¸ˆå¦çš„åˆçˆ»ä¸ºé˜³ï¼Œä¸­çˆ»ä¸ºé˜³ï¼Œæœ«çˆ»ä¸ºé˜³ï¼Œè¡¨ç¤ºè¿™æ˜¯ä¸€ä¸ªå……æ»¡æ´»åŠ›å’Œå†³å¿ƒçš„å¦è±¡ã€‚\n",
      "\n",
      "æ ¹æ®ã€Šè±¡è¾ã€‹ï¼Œåœ°æ°´å¸ˆå¦è¢«è§£é‡Šä¸ºâ€œåœ°ä¸­æœ‰æ°´â€ï¼Œè±¡å¾ç€åƒå¤§åœ°ä¸€æ ·åŒ…å®¹ç€æ°´ï¼Œä»¥åŠåƒå¤§åœ°ä¸€æ ·åŒ…å®¹ç€ä¼—äººå¿ƒçµçš„å¦è±¡ã€‚æ ¹æ®ã€Šæ–­æ˜“å¤©æœºã€‹ï¼Œåœ°æ°´å¸ˆå¦çš„åˆçˆ»ä¸ºé˜³ï¼Œä¸­çˆ»ä¸ºé˜³ï¼Œæœ«çˆ»ä¸ºé˜³ï¼Œè¡¨ç¤ºè¿™æ˜¯ä¸€ä¸ªå……æ»¡æ´»åŠ›å’Œå†³å¿ƒçš„å¦è±¡ã€‚\n",
      "\n",
      "åœ°æ°´å¸ˆå¦çš„æ ¸å¿ƒå“²å­¦æ˜¯ï¼šåƒå¤§åœ°ä¸€æ ·åŒ…å®¹ç€æ°´ï¼Œä»¥åŠåƒå¤§åœ°ä¸€æ ·åŒ…å®¹ç€ä¼—äººå¿ƒçµçš„å¦è±¡ã€‚æ ¹æ®ã€Šè±¡è¾ã€‹å’Œã€Šæ–­æ˜“å¤©æœºã€‹çš„è§£é‡Šï¼Œåœ°æ°´å¸ˆå¦çš„åˆçˆ»ã€ä¸­çˆ»å’Œæœ«çˆ»éƒ½ä¸ºé˜³ï¼Œè¡¨ç¤ºè¿™æ˜¯ä¸€ä¸ªå……æ»¡æ´»åŠ›å’Œå†³å¿ƒçš„å¦è±¡ã€‚\n",
      "\n",
      "æ ¹æ®ã€Šè±¡è¾ã€‹ï¼Œåœ°æ°´å¸ˆå¦é¢„ç¤ºç€å›°éš¾ä¸­æœ‰åˆ©ï¼Œé¡ºåˆ©ä¸­æœ‰é™©ï¼Œè¡¨ç¤ºå…ˆå¾—èƒœåå¾—ï¼Œå¾—èƒœå®¹æ˜“å¤±ï¼Œå›°éš¾ä¸­æœ‰åˆ©ï¼Œå¾—å¿—å®¹æ˜“è¿·å¤±ã€‚æ ¹æ®ã€Šæ–­æ˜“å¤©æœºã€‹ï¼Œåœ°æ°´å¸ˆå¦çš„åˆçˆ»ä¸ºé˜³ï¼Œä¸­çˆ»ä¸ºé˜³ï¼Œæœ«çˆ»ä¸ºé˜³ï¼Œè¡¨ç¤ºè¿™æ˜¯ä¸€ä¸ªå……æ»¡æ´»åŠ›å’Œå†³å¿ƒçš„å¦è±¡ã€‚\n",
      "\n",
      "åœ°æ°´å¸ˆå¦çš„æ ¸å¿ƒå“²å­¦æ˜¯ï¼šåƒå¤§åœ°ä¸€æ ·åŒ…å®¹ç€æ°´ï¼Œä»¥åŠåƒå¤§åœ°ä¸€æ ·åŒ…å®¹ç€ä¼—äººå¿ƒçµçš„å¦è±¡ã€‚æ ¹æ®ã€Šè±¡è¾ã€‹å’Œã€Šæ–­æ˜“å¤©æœºã€‹çš„è§£é‡Šï¼Œåœ°æ°´å¸ˆå¦çš„åˆçˆ»ã€ä¸­çˆ»å’Œæœ«çˆ»éƒ½ä¸ºé˜³ï¼Œè¡¨ç¤ºè¿™æ˜¯ä¸€ä¸ªå……æ»¡æ´»åŠ›å’Œå†³å¿ƒçš„å¦è±¡ã€‚\n",
      "\n",
      "æ ¹æ®ã€Šè±¡è¾ã€‹ï¼Œåœ°æ°´å¸ˆå¦é¢„ç¤ºç€å›°éš¾ä¸­æœ‰åˆ©ï¼Œé¡ºåˆ©ä¸­æœ‰é™©ï¼Œè¡¨ç¤ºå…ˆå¾—èƒœåå¾—ï¼Œå¾—èƒœå®¹æ˜“å¤±ï¼Œ\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Comparing result for query: å¤©æ°´è®¼å¦\n",
      "================================================================================\n",
      "ğŸ“Base model response:\n",
      "çš„å¤©æ°´è®¼å¦æ˜¯æŒ‡å¦è±¡ä¸ºä¹¾ä¸Šåä¸‹çš„ä¸€å¦ï¼Œä»£è¡¨çš„å¤©æ°´å¦è±¡å¾ç€å¤©åœ°ä¹‹é—´æµè¡Œç€å¤§çš„æ°´æµã€‚åœ¨åœå¦ä¸­ï¼Œè¿™ä¸ªå¦è±¡é€šå¸¸è¢«è§£é‡Šä¸ºå‰åˆ©ï¼Œå…·æœ‰äº«æœ‰çš„è¿æ ¼ã€‚ä½†æ˜¯éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå¤©çŒ«å¦è±¡å…·æœ‰åŒé‡å˜æ ¼ï¼Œéœ€è¦ç»¼åˆè€ƒè™‘å¦è±¡å’Œå˜æ ¼çš„æ„ä¹‰ï¼Œæ‰èƒ½å¾—å‡ºå‡†ç¡®çš„ç»“è®ºã€‚\n",
      "\n",
      "åœ¨ä¼ ç»Ÿæ–‡åŒ–ä¸­ï¼Œå¤©çŒ«å¦è±¡è¢«è®¤ä¸ºå…·æœ‰ä¼ è¾¾æ¶ˆæ¯çš„åŠŸèƒ½ï¼Œå¯ä»¥é¢„æµ‹å‰åˆ©æˆ–å‡¶é™©ã€‚ä½†æ˜¯ï¼Œåœ¨ç°ä»£ç¤¾ä¼šï¼Œé¢„æµ‹å¹¶ä¸ç§‘å­¦ï¼Œåªèƒ½é è‡ªå·±çš„åŠªåŠ›å’Œåˆ¤æ–­æ¥å†³å®šæœªæ¥çš„èµ°å‘ã€‚     \n",
      "ğŸ‘‰Fine tuned model (models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_152413) response: \n",
      "[gMASK]sop å¤©æ°´è®¼å¦\n",
      "\n",
      "å¤©çŒ«å›½é™…è¯‰ç§°ï¼Œåœ¨å¤©çŒ«å¹³å°ä¸Šï¼Œå› å•†å®¶æœªæŒ‰çº¦å®šå±¥è¡Œäº¤æ˜“ä¹‰åŠ¡ï¼Œé€ æˆæ¶ˆè´¹è€…æŸå¤±ï¼Œè¯·æ±‚åˆ¤ä»¤å•†å®¶èµ”å¿æ¶ˆè´¹è€…æŸå¤±åŠæ‰¿æ‹…ç›¸åº”è´£ä»»ã€‚\n",
      "\n",
      "å¤©çŒ«å›½é™…è®¤ä¸ºï¼Œæ ¹æ®ã€Šä¸­åäººæ°‘å…±å’Œå›½åˆåŒæ³•ã€‹ç¬¬107æ¡è§„å®šï¼Œå•†å®¶åº”æŒ‰ç…§çº¦å®šå±¥è¡Œäº¤æ˜“ä¹‰åŠ¡ã€‚ç„¶è€Œï¼Œå•†å®¶æœªèƒ½æŒ‰çº¦å®šå±¥è¡Œäº¤æ˜“ä¹‰åŠ¡ï¼Œé€ æˆæ¶ˆè´¹è€…æŸå¤±ã€‚å› æ­¤ï¼Œå¤©çŒ«å›½é™…è¯·æ±‚åˆ¤ä»¤å•†å®¶èµ”å¿æ¶ˆè´¹è€…æŸå¤±åŠæ‰¿æ‹…ç›¸åº”è´£ä»»ã€‚\n",
      "\n",
      "å¤©çŒ«å›½é™…è¯·æ±‚æ³•é™¢é‡‡å–çš„å®¡åˆ¤ç¨‹åºæ˜¯ï¼š\n",
      "\n",
      "1. æ³•é™¢åº”å½“ç»„æˆåˆè®®åº­ï¼Œç”±3åä»¥ä¸Šå®¡åˆ¤äººå‘˜å…±åŒå®¡ç†æœ¬æ¡ˆï¼›\n",
      "2. æ³•é™¢åº”å½“å¯¹å¤©çŒ«å›½é™…æä¾›çš„è¯æ®è¿›è¡Œå®¡æŸ¥ï¼Œçœ‹æ˜¯å¦èƒ½å¤Ÿè¯æ˜å…¶è¯‰è®¼è¯·æ±‚ï¼›\n",
      "3. æ³•é™¢åº”å½“ä¸€æ¡ˆä¸€æ–­ï¼Œå³é’ˆå¯¹æ¯ä¸€ä¸ªæ¡ˆä»¶ï¼Œéƒ½åº”å½“ä½œå‡ºç‹¬ç«‹çš„åˆ¤å†³ï¼›\n",
      "4. æ³•é™¢åº”å½“é€‚ç”¨æ³•å¾‹ï¼Œå¯¹æ¡ˆä»¶è¿›è¡Œå®¡ç†ã€‚\n",
      "\n",
      "å¤©çŒ«å›½é™…å°†ç§¯æé…åˆæ³•é™¢å®¡ç†ï¼Œå¸Œæœ›æ³•é™¢èƒ½å¤Ÿå…¬æ­£å®¡ç†æœ¬æ¡ˆã€‚\n",
      "\n",
      "================================================================================\n",
      "ğŸ” Loading PEFT model from: models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_163659\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Comparing result for query: è§£é‡Šä¸‹ä¹¾å¦æ˜¯ä»€ä¹ˆï¼Ÿ\n",
      "================================================================================\n",
      "ğŸ“Base model response:\n",
      "{'name': 'ä¹¾å¦æ˜¯å‘¨æ˜“ä¸­çš„ä¸€å¦ï¼Œç”±å…­ä¸ªé˜³çˆ»ç»„æˆï¼Œè±¡å¾ç€å¤©ã€‚å®ƒä»£è¡¨äº†ä¸€ç§åˆšå¥ã€å¥è¡Œã€åˆšå¥ä¸å±ˆçš„æ„å¢ƒã€‚åœ¨å‘¨æ˜“ä¸­ï¼Œé˜³çˆ»ä»£è¡¨é˜³åˆšï¼Œé˜´çˆ»ä»£è¡¨é˜´æŸ”ã€‚ä¹¾å¦çš„æ ¸å¿ƒå“²å­¦æ˜¯ï¼šå›å­è§‚æ­¤å¦è±¡ï¼Œä»è€Œç»“äº¤åˆ°å›å­ï¼Œæ±‚å¾—èµ°å»Šï¼ˆå¦è±¡ï¼‰çš„ç›¸åº”ã€‚', 'content': '\\nä¹¾å¦çš„å“²å­¦å«ä¹‰å¯ä»¥å¼•ç”³ä¸ºï¼šå¤©è¡Œå¥ï¼Œå›å­è§‚äºå¤©è¡Œï¼Œä»è€Œå¤§å‰ã€‚å›å­åº”å½“æ•ˆæ³•å¤©çš„è¡Œå¥ï¼Œå³è‡ªå¼ºä¸æ¯ï¼Œå¥è¡Œä¸æ­¢ï¼Œ Flexibility and adaptability, but with Determination and pride. ä¹¾å¦æ—¢è±¡å¾å›å­è‡ªå¼ºä¸æ¯çš„æ¯…åŠ›ï¼Œä¹Ÿæš—ç¤ºç€åœ¨å›°éš¾ä¸­åšå¿ä¸æ‹”çš„æ„å¿—ã€‚åœ¨äº‹ä¸šã€ç»å•†ã€æ±‚åã€å©šæ‹ç­‰æ–¹é¢çš„å†³ç­–ä¸­ï¼Œéƒ½éœ€è¦å€Ÿé‰´ä¹¾å¦çš„åˆšå¥ä¸ä¸å±ˆã€‚'}     \n",
      "ğŸ‘‰Fine tuned model (models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_163659) response: \n",
      "[gMASK]sop è§£é‡Šä¸‹ä¹¾å¦æ˜¯ä»€ä¹ˆï¼Ÿ åœ¨å‘¨æ˜“ä¸­ï¼Œä¹¾å¦æ˜¯å…­åå››å¦ä¹‹é¦–ï¼Œç”±å…­ä¸ªé˜³çˆ»ç»„æˆï¼Œè±¡å¾ç€å¤©ã€‚å®ƒæ‰€ä»£è¡¨çš„æ˜¯åˆšå¥ã€å¥è¡Œã€åˆšå¥ä¸å±ˆçš„æ„å¢ƒã€‚ä¹¾å¦çš„æ ¸å¿ƒå“²å­¦æ˜¯ï¼šå¤©é“åˆšå¥ï¼Œè¿è¡Œä¸å·²ï¼Œå›å­è§‚æ­¤å¦è±¡ï¼Œä»è€Œä»¥å¤©ä¸ºæ³•ï¼Œè‡ªå¼ºä¸æ¯ã€‚\n",
      "\n",
      "ä¹¾å¦è±¡å¾å¤©ï¼Œä¸ºå¤§é€šè€Œè‡³æ­£ã€‚å¾—æ­¤å¦è€…ï¼Œååˆ©åŒæ”¶ï¼Œåº”æŠŠæ¡æœºä¼šï¼Œäº‰å–æˆæœã€‚ç„¶è€Œï¼Œåˆ‡å‹¿è¿‡äºéª„å‚²è‡ªæ»¡ï¼Œè€Œåº”ä¿æŒè°¦é€Šã€å†·é™å’Œè­¦æƒ•ã€‚åœ¨äº‹ä¸šã€ç»å•†ã€æ±‚åç­‰æ–¹é¢ï¼Œä¹¾å¦çš†æš—ç¤ºç€å¤§å‰å¤§åˆ©ï¼Œä½†ä¹Ÿè­¦ç¤ºç€å¿…é¡»åšæŒæ­£é“ã€ä¿®å…»å¾·è¡Œï¼Œæ–¹èƒ½æ°¸è¿œäº¨é€šã€‚\n",
      "\n",
      "åœ¨å©šæ‹æ–¹é¢ï¼Œä¹¾å¦æç¤ºç€é˜³ç››é˜´è¡°ï¼Œä½†ä¹Ÿå¼ºè°ƒåˆšæŸ”ç›¸æµï¼Œç›¸äº’è¡¥è¶³ï¼Œå½¢æˆç¾æ»¡çš„ç»“æœã€‚åœ¨å†³ç­–æ–¹é¢ï¼Œåˆ™æ˜¯å¼ºè°ƒåˆšå¥ã€æ­£ç›´ã€å…¬å…ï¼Œè‡ªå¼ºä¸æ¯çš„å®è´¨ï¼Œéœ€è¦ä¿®å…»å¾·è¡Œã€åšå®šä¿¡å¿µï¼Œæ–¹èƒ½å…‹æœå›°éš¾ï¼Œæ¶ˆé™¤ç¾éš¾ã€‚\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Comparing result for query: å‘¨æ˜“ä¸­çš„è®¼å¦æ˜¯ä»€ä¹ˆ\n",
      "================================================================================\n",
      "ğŸ“Base model response:\n",
      "åœ¨å‘¨æ˜“ä¸­ï¼Œè®¼å¦æ˜¯ä¸€ä¸ªå……æ»¡è­¦ç¤ºçš„å¦è±¡ã€‚å®ƒç”±ä¸Šå¦ä¹¾ï¼ˆå¤©ï¼‰å’Œä¸‹å¦åï¼ˆæ°´ï¼‰ç»„æˆï¼Œä»£è¡¨ç€å¤©ä¸æ°´èƒŒé“è€Œé©°ï¼Œå½¢æˆäº‰è®¼çš„å±€é¢ã€‚è™½ç„¶äº‹æƒ…å¼€å§‹æ—¶æœ‰åˆ©å¯å›¾ï¼Œä½†å¿…é¡»è­¦æƒ•æˆ’æƒ§ï¼Œå› ä¸ºä¸­é—´è™½ç„¶å‰åˆ©ï¼Œä½†æœ€ç»ˆä¼šå¸¦æ¥å‡¶é™©ã€‚å¯¹äºæ¶‰åŠå¤§å·ï¼Œæ¶‰æ°´æ¸¡æ²³çš„è¡ŒåŠ¨ä¸åˆ©ã€‚å› æ­¤ï¼Œå›å­è§‚æ­¤å¦è±¡ï¼Œåº”å½“æ…ä¹‹åˆæ…ï¼Œæœç»äº‰è®¼ä¹‹äº‹ï¼Œå¹¶åœ¨è°‹äº‹ä¹‹åˆè°¨æ…è¡Œäº‹ã€‚è®¼å¦çš„æ ¸å¿ƒå“²å­¦æ˜¯è¦é¿å…äº‰è®¼ï¼Œé€€è€Œè®©äººï¼Œæ±‚å¾—åŒ–è§£ï¼Œå®‰äºæ­£ç†ï¼Œæ–¹å¯é¿å…æ„å¤–ä¹‹ç¾ã€‚åœ¨äº‹ä¸šä¸Šï¼ŒåŠ¡å¿…é¿å…ä»‹å…¥è¯‰è®¼çº çº·çš„äº‰æ‰§ä¹‹ä¸­ï¼Œä¸å…¶è¿™æ ·ï¼Œä¸å¦‚é€€è€Œè®©äººã€‚å³ä½¿æœ€ç»ˆè·èƒœï¼Œä¹Ÿéš¾å…å¾—å¤±ä¸å‡ã€‚ç»å•†æ–¹é¢ï¼Œè¦åšæŒå…¬æ­£ã€å…¬å¹³ã€äº’åˆ©çš„åŸåˆ™ï¼Œé¿å…å†²çªï¼Œè¿™æ ·ä¼šæœ‰å¥½ç»“æœã€‚è€Œå¯¹äºæ±‚åã€å©šæ‹å’Œå†³ç­–ï¼Œä¹Ÿéƒ½éœ€è¦æ…é‡è¡Œäº‹ï¼Œé¿å…ç›²ç›®è¿½æ±‚ï¼Œé€€è®©è®©äººï¼Œå¯åŠ©äº‹ä¸šã€å©šå§»å’Œå†³ç­–çš„å‘å±•ã€‚     \n",
      "ğŸ‘‰Fine tuned model (models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_163659) response: \n",
      "[gMASK]sop å‘¨æ˜“ä¸­çš„è®¼å¦æ˜¯ä»€ä¹ˆæ¦‚å¿µ åœ¨å‘¨æ˜“ä¸­ï¼Œè®¼å¦æ˜¯ä¸€ä¸ªå……æ»¡è­¦ç¤ºçš„å¦è±¡ã€‚å®ƒç”±ä¸Šå¦ä¹¾ï¼ˆå¤©ï¼‰å’Œä¸‹å¦åï¼ˆæ°´ï¼‰ç»„æˆï¼Œä»£è¡¨ç€å¤©ä¸æ°´èƒŒé“è€Œé©°ï¼Œå½¢æˆäº‰è®¼çš„å±€é¢ã€‚è™½ç„¶äº‹æƒ…å¼€å§‹æ—¶æœ‰åˆ©å¯å›¾ï¼Œä½†å¿…é¡»è­¦æƒ•æˆ’æƒ§ï¼Œå› ä¸ºä¸­é—´è™½ç„¶å‰åˆ©ï¼Œä½†æœ€ç»ˆä¼šå¸¦æ¥å‡¶é™©ã€‚å¯¹äºæ¶‰åŠå¤§å·ï¼Œæ¶‰æ°´æ¸¡æ²³çš„è¡ŒåŠ¨ä¸åˆ©ã€‚å› æ­¤ï¼Œå›å­è§‚æ­¤å¦è±¡ï¼Œåº”å½“æ…ä¹‹åˆæ…ï¼Œæœç»äº‰è®¼ä¹‹äº‹ï¼Œå¹¶åœ¨è°‹äº‹ä¹‹åˆè°¨æ…è¡Œäº‹ã€‚è®¼å¦çš„æ ¸å¿ƒå“²å­¦æ˜¯è¦é¿å…äº‰è®¼ï¼Œé€€è€Œè®©äººï¼Œæ±‚å¾—åŒ–è§£ï¼Œå®‰äºæ­£ç†ï¼Œæ–¹å¯é¿å…æ„å¤–ä¹‹ç¾ã€‚åœ¨äº‹ä¸šä¸Šï¼ŒåŠ¡å¿…é¿å…ä»‹å…¥è¯‰è®¼çº çº·çš„äº‰æ‰§ä¹‹ä¸­ï¼Œä¸å…¶è¿™æ ·ï¼Œä¸å¦‚é€€è€Œè®©äººã€‚å³ä½¿æœ€ç»ˆè·èƒœï¼Œä¹Ÿéš¾å…å¾—å¤±ä¸å‡ã€‚ç»å•†æ–¹é¢ï¼Œè¦åšæŒå…¬æ­£ã€å…¬å¹³ã€äº’åˆ©çš„åŸåˆ™ï¼Œé¿å…å†²çªï¼Œè¿™æ ·ä¼šæœ‰å¥½ç»“æœã€‚è€Œå¯¹äºæ±‚åã€å©šæ‹å’Œå†³ç­–ï¼Œä¹Ÿéƒ½éœ€è¦æ…é‡è¡Œäº‹ï¼Œé¿å…ç›²ç›®è¿½æ±‚ï¼Œé€€è®©è®©äººï¼Œå¯åŠ©äº‹ä¸šã€å©šå§»å’Œå†³ç­–çš„å‘å±•ã€‚\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Comparing result for query: å¸ˆå¦æ˜¯ä»€ä¹ˆï¼Ÿ\n",
      "================================================================================\n",
      "ğŸ“Base model response:\n",
      "å¸ˆå¦ï¼Œæ˜¯å‘¨æ˜“ä¸­çš„ä¸€å¦ï¼Œç”±ä¸¤ä¸ªå¦ç›¸åˆè€Œæˆï¼Œä»£è¡¨å°”æ–¯å¦ã€‚åœ¨å‘¨æ˜“ä¸­ï¼Œorsaï¼ˆulbï¼‰å¦ä¸ºåˆçˆ»ï¼Œä»£è¡¨å¼€å§‹ï¼›ä¸­é—´çˆ»ä¸ºä¹é˜³ï¼Œä»£è¡¨å……æ»¡é˜³å…‰ï¼›ä¸Šå¦ä¸ºä¹é˜´ï¼Œä»£è¡¨å¹½æš—ã€‚è¿™ä¸€å¦çš„ä¸»è¦ç‰¹ç‚¹æ˜¯åˆšä¸­æœ‰æŸ”ï¼Œåˆšä¸­æœ‰åˆšï¼Œåˆšä¸­æœ‰æŸ”ï¼Œåˆšä¸­æœ‰åˆšï¼Œä¸Šå¦ä¸ºå¤ï¼Œä¸‹å¦ä¸ºéœ‡ã€‚\n",
      "\n",
      "å¸ˆå¦çš„æ ¸å¿ƒå“²å­¦æ˜¯ï¼šå¤©æ—¶ä¸å¦‚åœ°åˆ©ï¼Œåœ°åˆ©ä¸å¦‚äººæ—¶ï¼Œæ—¶åŠ¿é€ äººï¼Œå›å­ä¿®å…»è‡ªèº«ï¼Œç­‰å¾…æ—¶æœºï¼ŒæŒæ¡å…µæ³•ï¼Œåˆ›é€ èƒœåˆ©çš„æ¡ä»¶ã€‚åœ¨äº‹ä¸šä¸Šï¼Œè¿™ä¸€å¦æç¤ºç€å¿…é¡»æŒæ¡æ—¶æœºï¼Œç§¯æè¡ŒåŠ¨ï¼Œå……åˆ†å‡†å¤‡ï¼Œå–„äºå˜é€šï¼Œå‹‡äºæ‹…å½“ã€‚åœ¨ç»å•†ä¸­ï¼Œè¡¨ç°ä¸ºæŒæ¡æ—¶æœºï¼Œå‹‡æ•¢è¡ŒåŠ¨ï¼Œå–„äºå˜é€šï¼Œå……æ»¡è‡ªä¿¡ï¼Œå†·é™åˆ†æï¼Œæ•¢ä½œæ•¢ä¸ºã€‚\n",
      "\n",
      "å¸ˆå¦çš„å‰å‡¶æŒ‡æ ‡ä¸ºï¼šåˆçˆ»ä¸ºå‰ï¼Œä¸­é—´çˆ»ä¸ºå‡¶ï¼Œä¸Šå¦ä¸ºå‰ï¼Œä¸‹å¦ä¸ºå‡¶ã€‚å‰å‡¶å–å†³äºçˆ»è¾çš„ç»„åˆå’Œå¦è±¡çš„æ­é…ã€‚åœ¨ç»å•†ä¸­ï¼Œè‹¥å‡¶çˆ»å¾—ä½ï¼Œåˆ™å¿…é¡»è°¨æ…è¡Œäº‹ï¼Œè‹¥å‰çˆ»å¾—ä½ï¼Œåˆ™å¯æ”¾å¿ƒè¡ŒåŠ¨ï¼Œè‹¥é€¢æœ‰åˆ©å¯ä¸ºçš„æ—¶æœºåˆ™åº”ç§¯æè¡ŒåŠ¨ã€‚åœ¨äº‹ä¸šå’Œç»å•†ä¸­ï¼Œå¿…é¡»æ³¨æ„æŒæ¡æ—¶æœºï¼Œå……åˆ†å‡†å¤‡ï¼Œå–„äºå˜é€šï¼Œå‹‡æ•¢æ‹…å½“ã€‚     \n",
      "ğŸ‘‰Fine tuned model (models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_163659) response: \n",
      "[gMASK]sop å¸ˆå¦æ˜¯ä»€ä¹ˆï¼Ÿ åœ¨å‘¨æ˜“ä¸­ï¼Œå¸ˆå¦æ˜¯ä¸€ä¸ªç”±åå¦ï¼ˆæ°´ï¼‰å’Œå¤å¦ï¼ˆåœ°ï¼‰ç›¸å è€Œæˆçš„å¼‚å¦ã€‚è¿™ä¸€å¦è±¡ä»£è¡¨ç€å†›é˜Ÿçš„åŠ›é‡å’Œå†›æƒ…çš„æ€»æŒ‡æŒ¥ï¼Œé¢„ç¤ºç€å‰ç¥¥æ— ç¾ã€‚è±¡è¾ä¸­æè¿°äº†åœ°ä¸­æœ‰æ°´çš„æƒ…æ™¯ï¼Œå¯“æ„ç€å›å­åº”å½“åƒå¤§åœ°ä¸€æ ·å®¹çº³å’Œç•œå…»å¤§ä¼—ã€‚å¸ˆå¦çš„è§£é‡Šå¼ºè°ƒé€‰æ‹©å¾·é«˜æœ›é‡çš„é•¿è€…æ¥ç»Ÿç‡å†›é˜Ÿï¼Œæ‰èƒ½è·å¾—å‰ç¥¥æ— å’ã€‚å¦å¤–ï¼Œå¸ˆå¦ä¹Ÿè±¡å¾ç€å›°éš¾é‡é‡ï¼Œéœ€è¦åŒ…å®¹åˆ«äººã€è‰°è‹¦åŠªåŠ›ï¼ŒåŠæ—¶è¡Œäº‹ï¼Œä¸¥äºå¾‹å·²ã€‚åœ¨äº‹ä¸šã€ç»å•†ã€æ±‚åã€å©šæ‹ç­‰æ–¹é¢çš„å†³ç­–ä¸­ï¼Œéƒ½éœ€è¦è­¦æƒ•æ½œåœ¨æ•Œäººï¼Œå°å¿ƒè°¨æ…ï¼Œåˆä½œä¸å†³æ–­å…¼é¡¾ï¼Œæ–¹èƒ½æˆåŠŸã€‚\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Comparing result for query: åœ°æ°´å¸ˆå¦æ˜¯ä»€ä¹ˆï¼Ÿ\n",
      "================================================================================\n",
      "ğŸ“Base model response:\n",
      "åœ¨å‘¨æ˜“ä¸­ï¼Œåœ°æ°´å¸ˆå¦æ˜¯ä¸€ä¸ªç”±åå¦ï¼ˆæ°´ï¼‰å’Œå¤å¦ï¼ˆåœ°ï¼‰ç›¸å è€Œæˆçš„å¼‚å¦ã€‚è¿™ä¸€å¦è±¡ä»£è¡¨ç€å†›é˜Ÿå‘å‰è¿›å–ï¼Œæœ‰ç€ç¨³å®šå’Œç»Ÿä¸€å›½å®¶çš„å¥½è¿ã€‚è±¡è¾ä¸­æè¿°äº†åœ°æ°´å¸ˆå¦çš„ç‰¹ç‚¹ï¼Œå³ï¼šç”¨å†›å–åŸï¼Œå¾—åœ°èƒœæ•Œã€‚\n",
      "\n",
      "åœ°æ°´å¸ˆå¦çš„å‡ºç°ï¼Œé¢„ç¤ºç€å‰ç¥¥å°å¿ƒã€‚å›°é›£åœ¨äºé‡‘æœ¨ä¹‹å¤ï¼Œè€Œåœ¨ç«åœŸä¹‹ç§‹ã€‚åœ¨äº‹ä¸šä¸Šï¼Œå¤§å‰å¤§åˆ©ï¼Œä½†å¿…é¡»è°¨æ…è¡Œäº‹ã€‚åœ¨ç»å•†ä¸­ï¼Œå¿…é¡»è°¨æ…è¡Œäº‹ï¼Œç¨³é‡è¡Œäº‹ï¼Œæ–¹èƒ½è·å¾—åˆ©çš„é¢„å…†ã€‚åœ¨æ„Ÿæƒ…æ–¹é¢ï¼Œçˆ±æƒ…ç¾æ»¡ï¼Œä½†éœ€ç–‘è™‘å’Œå…³å¿ƒå¯¹æ–¹ã€‚\n",
      "\n",
      "æ€»ä½“æ¥è¯´ï¼Œåœ°æ°´å¸ˆå¦æ˜¯ä¸€ä¸ªå…¸å‹çš„å‰ç¥¥ä¹‹å¦ï¼Œä½† also æœ‰ä¸€å®šçš„è­¦å‘Šå’Œæç¤ºã€‚     \n",
      "ğŸ‘‰Fine tuned model (models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_163659) response: \n",
      "[gMASK]sop åœ°æ°´å¸ˆå¦æ˜¯ä»€ä¹ˆï¼Ÿ åœ¨å‘¨æ˜“ä¸­ï¼Œåœ°æ°´å¸ˆå¦æ˜¯ä¸€ä¸ªç”±åå¦ï¼ˆæ°´ï¼‰å’Œå¤å¦ï¼ˆåœ°ï¼‰ç›¸å è€Œæˆçš„å¼‚å¦ã€‚è¿™ä¸€å¦è±¡ä»£è¡¨ç€å†›é˜Ÿå‘å‰è¿›å–ï¼Œæœ‰ç€å¼ºå¤§åŠ›é‡å’Œæ™ºè°‹çš„èƒœåˆ©ã€‚è±¡è¾ä¸­æè¿°äº†åœ°æ°´å¸ˆå¦çš„ç‰¹ç‚¹ï¼Œå³\"åˆå…­ï¼Œå¤æ± ä¹‹åˆ¶ï¼Œåˆæˆï¼Œè±¡è¾ã€‚\" è¿™é‡Œï¼Œå¤å¦ä»£è¡¨åœ°ï¼Œè±¡å¾å¤§æ°´ï¼ˆå¤ï¼‰ä¸å¤å®«ï¼ˆåœ°ï¼‰ç›¸å è€Œæˆã€‚å¤å®«æ˜¯å¤å¦çš„å¦å®«ï¼Œä½äºè¥¿å—æ–¹ã€‚åœ¨è¿™é‡Œï¼Œå¤å¦ä»£è¡¨æ­¢ Milizinï¼ˆåœ°ï¼‰å’Œæ­¢æˆ˜ï¼ˆå¤ï¼‰çš„æ„å›¾ï¼Œå½¢æˆä¸€ç§å’Œå¹³è§£å†³æˆ˜äº‰å±€é¢çš„æ„¿æœ›ã€‚\n",
      "\n",
      "åœ°æ°´å¸ˆå¦çš„æ ¸å¿ƒå“²å­¦æ˜¯ï¼šæ­¢ Milizinï¼ˆåœ°ï¼‰å’Œæ­¢æˆ˜ï¼ˆå¤ï¼‰ï¼Œå®‰å±å®šçŸ£ã€‚æ­¢æˆ˜ï¼šæŒ‡é€šè¿‡å’Œå¹³æ‰‹æ®µï¼Œå¦‚å¤–äº¤ã€è°ˆåˆ¤ç­‰ï¼Œæ¥åˆ¶æ­¢æˆ˜äº‰ã€‚åœ°æ°´å¸ˆå¦é¼“åŠ±äººä»¬æ­¢æˆ˜ï¼Œé¿å…æˆ˜äº‰å¸¦æ¥çš„æŸå¤±ï¼Œä¸»å¼ é€šè¿‡å’Œå¹³æ–¹å¼è§£å†³çº·äº‰ã€‚\n",
      "\n",
      "åœ¨äº‹ä¸šã€ç»å•†ã€æ±‚åã€å©šæ‹ç­‰æ–¹é¢çš„å†³ç­–ä¸­ï¼Œåœ°æ°´å¸ˆå¦éƒ½æç¤ºç€æ­¢æˆ˜å’Œç¨³å®šå‘å±•ã€‚ç»å•†æ–¹é¢ï¼Œå¼ºè°ƒç¨³å®šç»è¥ï¼Œé¿å…æˆ˜äº‰å¯¹å•†ä¸šæ´»åŠ¨çš„å½±å“ï¼ŒåŒæ—¶å¼ºè°ƒæ­¢æˆ˜å’Œç¨³å®šï¼Œå•†ä¸šæ´»åŠ¨å¾—ä»¥é¡ºåˆ©è¿›è¡Œã€‚åœ¨å©šæ‹æ–¹é¢ï¼Œè±¡å¾ç€ç¨³å®šæ„Ÿæƒ…ï¼Œé¿å…æˆ˜äº‰å¯¹æ„Ÿæƒ…å¸¦æ¥çš„å½±å“ï¼ŒåŒæ—¶å¼ºè°ƒæ­¢æˆ˜å’Œç¨³å®šï¼Œæ„Ÿæƒ…å¾—ä»¥ç¨³å®šå‘å±•ã€‚\n",
      "\n",
      "åœ°æ°´å¸ˆå¦çš„æ ¸å¿ƒå“²å­¦æ˜¯æ­¢æˆ˜å’Œç¨³å®šï¼Œé€‚åˆç»å•†ã€æ±‚åã€å©šæ‹ç­‰æ–¹é¢çš„å†³ç­–\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Comparing result for query: å¤©æ°´è®¼å¦\n",
      "================================================================================\n",
      "ğŸ“Base model response:\n",
      "å¤©æ°´è®¼å¦æ˜¯ä¸€ä¸ªå¦è±¡ï¼Œç”±åå¦ï¼ˆæ°´ï¼‰å’Œå¤å¦ï¼ˆåœ°ï¼‰ç›¸å è€Œæˆã€‚è¿™ä¸€å¦è±¡ä»£è¡¨ç€å¤©åœ°ç›¸é”™ï¼Œé¢„ç¤ºç€å›å­åº”å½“é€‚åº”å¤©åœ°ç›¸é”™ä¹‹è±¡ï¼Œé€‚åº”å˜åŒ–ï¼Œå›å­ä»¬è¦é€‚åº”å¤©åœ°ç›¸é”™ä¹‹è±¡ï¼Œé€‚åº”å˜åŒ–ï¼ŒåŒ–è§£çº·äº‰ï¼Œä»è€ŒåŒ–è§£çŸ›ç›¾ã€‚\n",
      "\n",
      "å¤©æ°´è®¼å¦çš„æ ¸å¿ƒå“²å­¦æ˜¯ï¼šå¤©åœ°ç›¸é”™ï¼Œgin4 gan4ï¼Œç›¸äº’é”™ç»¼å¤æ‚ï¼Œéš¾ä»¥ç®€å•è§£å†³ã€‚å› æ­¤ï¼Œå›å­ä»¬éœ€è¦åœ¨çŸ›ç›¾å†²çªä¸­å¯»æ±‚åŒ–è§£ï¼ŒåŒ–è§£çº·äº‰ï¼Œç¼“å’Œç¤¾ä¼šçŸ›ç›¾ï¼ŒåŒ–è§£çº·äº‰ï¼Œä»è€Œè¾¾åˆ°å¹³è¡¡å’Œè°ä¹‹å¢ƒã€‚\n",
      "\n",
      "åœ¨äº‹ä¸šã€ç»å•†ã€æ±‚åã€å©šæ‹ç­‰æ–¹é¢çš„å†³ç­–ä¸­ï¼Œéƒ½éœ€è¦æ³¨æ„å¤©åœ°ç›¸é”™ä¹‹è±¡ï¼Œå¯»æ±‚åŒ–è§£çŸ›ç›¾ï¼Œé¿å…å†²çªï¼Œå¯»æ±‚å¦¥åä¸è½¬åŒ–ã€‚åŒæ—¶ï¼Œä¹Ÿé¢„ç¤ºç€éœ€è¦é€‚åº”å˜åŒ–ï¼Œå¯»æ‰¾å¹³è¡¡ç‚¹ï¼Œæ³¨æ„ç¼“å’Œç¤¾ä¼šçŸ›ç›¾ï¼ŒåŒ–è§£çº·äº‰ï¼Œä»è€Œè¾¾åˆ°å’Œè°ä¹‹å¢ƒã€‚     \n",
      "ğŸ‘‰Fine tuned model (models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_163659) response: \n",
      "[gMASK]sop å¤©æ°´è®¼å¦å¦è±¡è¯¦è§£ è¿™æ˜¯ä¸€ç¯‡å…³äºå¤©æ°´è®¼å¦çš„æ–‡ç« ï¼Œä¸»è¦ä»‹ç»äº†è¿™ä¸ªå¦è±¡çš„ç‰¹ç‚¹ä»¥åŠå®ƒæ‰€ä»£è¡¨çš„è¿åŠ¿ã€‚\n",
      "\n",
      "åœ¨å¤©æ°´è®¼å¦ä¸­ï¼Œä¸Šå¦æ˜¯ä¹¾ï¼Œä»£è¡¨å¤©ï¼Œä¸‹å¦æ˜¯åï¼Œä»£è¡¨åœ°ã€‚ä¹¾å¦è±¡å¾ç€åˆšå¼ºï¼Œåå¦è±¡å¾ç€æŸ”é¡ºã€‚åœ¨è¿™ä¸ªå¦ä¸­ï¼Œä¸­é—´çš„çˆ»æ˜¯éœ‡ï¼Œè±¡å¾éœ‡åŠ¨ã€‚\n",
      "\n",
      "å¤©æ°´è®¼å¦çš„æ ¸å¿ƒå“²å­¦æ˜¯ï¼šéœ‡åŠ¨ä»¥æ±‚å’Œã€‚è¿™ä¸ªå¦è±¡é¢„ç¤ºç€å›å­è§‚è€…éœ€è¦ä»¥éœ‡ä¸ºæ¦œæ ·ï¼Œç§¯æå¯»æ±‚è§£å†³çº·äº‰çš„æ–¹æ³•ã€‚å›å­åœ¨ç°å®ç”Ÿæ´»ä¸­ï¼Œåº”è¯¥ä»¥æ­£ä¹‰ã€åˆšæ¯…ã€åˆšæ­£ã€è¯šå®çš„å“è´¨æ¥å¤„ç†äº‹åŠ¡ï¼Œä»¥æ±‚å¾—è§£å†³ã€‚\n",
      "\n",
      "ç„¶è€Œï¼Œå¤©æ°´è®¼å¦å¹¶éå®Œå…¨ä¸åˆ©äºå›å­ï¼Œå®ƒä¹Ÿé¢„ç¤ºç€å›å­èƒ½å¤Ÿå–å¾—æˆåŠŸã€‚åªè¦å›å­èƒ½å¤ŸåšæŒæ­£ä¹‰ï¼Œåˆšæ¯…ï¼Œè¯šå®ï¼Œ flexible and adaptableï¼Œå°±èƒ½å¤ŸæˆåŠŸè§£å†³çº·äº‰ã€‚\n",
      "\n",
      "æ€»çš„æ¥è¯´ï¼Œå¤©æ°´è®¼å¦æ˜¯ä¸€ä¸ªå‰ç¥¥ä¹‹å¦ï¼Œä½†éœ€è¦å›å­è§‚è€…ç§¯æå¯»æ±‚è§£å†³çº·äº‰çš„æ–¹æ³•ï¼Œä»¥å–å¾—æˆåŠŸã€‚\n",
      "\n",
      "================================================================================\n",
      "ğŸ” Loading PEFT model from: models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_handmade\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Comparing result for query: è§£é‡Šä¸‹ä¹¾å¦æ˜¯ä»€ä¹ˆï¼Ÿ\n",
      "================================================================================\n",
      "ğŸ“Base model response:\n",
      "ä¹¾å¦æ˜¯å…«å¦ä¹‹ä¸€ï¼Œä¹Ÿæ˜¯å…«å®«å›¾ä¹‹ä¸€ï¼Œå…¶å¦è±¡ç”±ä¸¤ä¸ªé˜´çˆ»å¤¹ä¸€ä¸ªé˜³çˆ»æ„æˆï¼Œè±¡å¾ç€å¤©ã€äº‘ã€é›·ç­‰è‡ªç„¶ç°è±¡ï¼Œä»¥åŠå›ç‹ã€é¢†å¯¼ã€çˆ¶äº²ç­‰æƒåŠ›å’Œå¨ä¸¥ã€‚ä¹¾å¦çš„å«ä¹‰åŒ…æ‹¬åˆ›é€ ã€é¢†å¯¼ã€åšå®šã€æœæ•¢ã€è¿›å±•ã€å‘å±•ç­‰ã€‚åœ¨å…«å®«å›¾ä¸­ï¼Œä¹¾å¦ä½äºè¥¿åŒ—æ–¹ä½ï¼Œä¸äº‹ä¸šã€åŠªåŠ›ã€ç§¯æã€å˜åŒ–ã€è¿›å±•ç­‰æœ‰å…³ã€‚åœ¨å‘½ç†å­¦ä¸­ï¼Œä¹¾å¦ä¹Ÿä»£è¡¨ç€å›ä¸»ã€é¢†å¯¼ã€çˆ¶äº²ç­‰æƒåŠ›äººç‰©ï¼Œä»¥åŠæ³•å¾‹ã€è§„åˆ™ã€åˆ¶åº¦ç­‰ã€‚     \n",
      "ğŸ‘‰Fine tuned model (models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_handmade) response: \n",
      "[gMASK]sop è§£é‡Šä¸‹ä¹¾å¦æ˜¯ä»€ä¹ˆï¼Ÿ\n",
      "ä¹¾å¦æ˜¯å…«å¦ä¹‹ä¸€ï¼Œä¹Ÿæ˜¯å…«å®«å›¾è¯´ã€æ˜“ç»ã€æ˜“å­¦ä¸­éå¸¸é‡è¦çš„ä¸€ä¸ªå¦ã€‚ä¹¾å¦æ˜¯ç”±ä¸¤ä¸ªé˜´çˆ»å¤¹ä¸€ä¸ªé˜³çˆ»æ„æˆï¼Œè±¡å¾ç€å¤©ã€äº‘ã€é›·ç­‰è‡ªç„¶ç°è±¡ï¼Œä»¥åŠå›ç‹ã€é¢†å¯¼ã€æƒåŠ›ç­‰è±¡å¾ã€‚ä¹¾å¦çš„å«ä¹‰éå¸¸ä¸°å¯Œï¼ŒåŒ…æ‹¬åŠ›é‡ã€åˆšå¼ºã€ç§¯æã€è¡ŒåŠ¨ã€åˆšæ¯…ã€æœæ•¢ã€åšå®šç­‰ã€‚åœ¨æ˜“ç»ä¸­ï¼Œä¹¾å¦çš„å¦è¾æ˜¯â€œå…ƒã€äº¨ã€åˆ©ã€è´â€ï¼Œè¡¨ç¤ºè¿™ä¸ªå¦å…·æœ‰æ­£å§‹ã€æ­£é€šã€æ­£åˆ©ã€æ­£è´çš„ç‰¹è´¨ã€‚ä¹¾å¦çš„äº”è¡Œå±æ€§æ˜¯â€œæœ¨â€ï¼Œåœ¨å…«å¦ä¸­å±äºé˜³å¦ï¼Œä»£è¡¨æ˜¥å­£ã€æ ‘æœ¨ã€æˆé•¿ã€å‘å±•ç­‰ã€‚\n",
      "\n",
      "ä¹¾å¦çš„å…­çˆ»åˆ†åˆ«æœ‰ä¸åŒçš„å«ä¹‰ï¼Œåˆçˆ»è¡¨ç¤ºå¤©ã€åˆç”Ÿã€åˆå£®ï¼›äºŒçˆ»è¡¨ç¤ºå¤©ã€å¤©æˆã€å¤©é•¿ï¼›ä¸‰çˆ»è¡¨ç¤ºå¤©ã€å¤©è¡Œã€å¤©å°Šï¼›å››çˆ»è¡¨ç¤ºå¤©ã€å¤©æ­£ã€å¤©å®šï¼›äº”çˆ»è¡¨ç¤ºå¤©ã€å¤©æ—‹ã€å¤©ç»ˆï¼›å…­çˆ»è¡¨ç¤ºå¤©ã€å¤©æˆã€å¤©åŠŸã€‚æ¯ä¸€çˆ»éƒ½æœ‰é˜³çˆ»å’Œé˜´çˆ»ä¸¤ç§çŠ¶æ€ï¼Œé€šè¿‡ç»„åˆå½¢æˆå››ç§ä¸åŒçš„å¦è±¡ï¼Œå³ä¹¾ã€å¤ã€éœ‡ã€å·½ã€åã€ç¦»ã€è‰®ã€å…‘ã€‚è¿™å››ç§å¦è±¡åˆ†åˆ«å¯¹åº”ä¸åŒçš„äº”è¡Œå±æ€§ã€æ€§æ ¼ç‰¹ç‚¹ã€äººç‰©ã€äº‹ç‰©ç­‰ï¼Œå¯¹äººçš„ç”Ÿè¾°å…«å­—ã€å‘½ç†ã€è¿åŠ¿ç­‰éƒ½æœ‰é‡è¦çš„å½±å“ã€‚\n",
      "\n",
      "ä¹¾å¦åœ¨å…«å®«å›¾è¯´ä¸­ä½äºåŒ—æ–¹ï¼Œä¸äº‹ä¸šã€åŠªåŠ›ã€å†³æ–­ã€é¢†å¯¼ã€è‡ªä¿¡ã€åšå®šç­‰æœ‰å…³ã€‚åœ¨æ˜“ç»ä¸­ï¼Œä¹¾å¦ä¸»è¦å¯¹åº”äºå…«å¦ä¸­çš„â€œä¹¾â€å¦ï¼Œå…·æœ‰å¼ºçƒˆçš„é¢†å¯¼åŠ›å’Œå†³æ–­åŠ›ï¼Œèƒ½å¤Ÿç§¯æåœ°æ¨åŠ¨äº‹ç‰©çš„å‘å±•å’Œè¿›æ­¥ã€‚åŒæ—¶ï¼Œä¹¾å¦ä¹Ÿè±¡å¾ç€å¤©ã€äº‘ã€é›·ç­‰è‡ªç„¶ç°è±¡ï¼Œæé†’äººä»¬åœ¨é¢å¯¹æŒ‘æˆ˜å’Œå›°éš¾æ—¶è¦åšå®šä¿¡å¿µï¼Œä¿æŒç§¯æå‘ä¸Šçš„å¿ƒæ€ï¼Œå‹‡å¾€ç›´å‰ã€‚\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Comparing result for query: å‘¨æ˜“ä¸­çš„è®¼å¦æ˜¯ä»€ä¹ˆ\n",
      "================================================================================\n",
      "ğŸ“Base model response:\n",
      "ã€Šå‘¨æ˜“ã€‹ä¸­çš„è®¼å¦ï¼ˆåˆç§°â€œæŸâ€å¦ï¼‰æ˜¯å…«å¦ä¹‹ä¸€ï¼Œå®ƒçš„å¦è±¡æ˜¯ç”±ä¸¤ä¸ªå¦ç›¸ç»„åˆè€Œæˆï¼šä¸Šå¦æ˜¯ä¹¾ï¼Œè¡¨ç¤ºå¤©ï¼›ä¸‹å¦æ˜¯å¤ï¼Œè¡¨ç¤ºåœ°ã€‚ä¹¾å¦ä¸ºé˜³ï¼Œå¤å¦ä¸ºé˜´ã€‚åœ¨å…­åå››å¦ä¸­ï¼Œè®¼å¦æ˜¯ç¬¬å…«å¦ã€‚\n",
      "\n",
      "è®¼å¦è±¡å¾ç€è¯‰è®¼ã€äº‰ç«¯ã€çº·äº‰ç­‰è¯‰è®¼äº‹ä»¶ã€‚å®ƒè¡¨ç¤ºåœ¨æŸç§ç¨‹åº¦ä¸Šï¼Œé˜³å’Œé˜´ã€äº’ç›¸å¯¹ç«‹çš„ä¸¤æä¹‹é—´å­˜åœ¨å†²çªã€‚è¿™ä¸€å¦å¯ç¤ºäººä»¬è¦å­¦ä¼šå…‹åˆ¶ã€è°¦å‘å’Œè®²é“ç†ï¼Œä»¥åŒ–è§£çŸ›ç›¾ï¼Œè¾¾æˆå’Œè°ã€‚\n",
      "\n",
      "å‘¨æ˜“ä¸­çš„å¦è¾å’Œçˆ»è¾å¯ä»¥ä¸ºäººä»¬æä¾›ä¸€äº›è§£å†³é—®é¢˜çš„æ–¹æ³•å’Œæ€è·¯ã€‚é€šè¿‡æ·±å…¥ç ”ç©¶å¦è±¡åŠå…¶å˜åŒ–ï¼Œäººä»¬å¯ä»¥ä»ä¸­æ±²å–æ™ºæ…§å’Œå¯ç¤ºï¼Œä»è€Œæ›´å¥½åœ°åº”å¯¹ç°å®ç”Ÿæ´»ä¸­çš„é—®é¢˜å’ŒæŒ‘æˆ˜ã€‚     \n",
      "ğŸ‘‰Fine tuned model (models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_handmade) response: \n",
      "[gMASK]sop å‘¨æ˜“ä¸­çš„è®¼å¦æ˜¯ä»€ä¹ˆï¼Ÿ\n",
      "å‘¨æ˜“ä¸­çš„è®¼å¦æ˜¯å…«å¦ä¹‹ä¸€ï¼Œå®ƒçš„å¦è±¡æ˜¯ç”±ä¸¤ä¸ªç¦»å­—å åŠ è€Œæˆï¼Œç¦»ä¸ºç«ï¼Œç«å¯ä»¥å…‹é‡‘ï¼Œå› æ­¤è®¼å¦è±¡å¾ç€ç«é‡‘ç›¸å…‹ã€äº‰æ–—ä¸æ–­çš„æ™¯è±¡ã€‚åœ¨å‘¨æ˜“ä¸­ï¼Œè®¼å¦è¡¨ç¤ºè¯‰è®¼ã€äº‰ç«¯ã€çŸ›ç›¾ç­‰çº·äº‰ç°è±¡ï¼Œå®ƒæé†’äººä»¬åœ¨å¤„ç†é—®é¢˜å’ŒçŸ›ç›¾æ—¶è¦ä¿æŒå†·é™ã€ç†æ™ºï¼Œé¿å…ç”¨ç«æ”»æ¥è§£å†³é—®é¢˜ï¼Œå¦åˆ™å¯èƒ½ä¼šå¯¼è‡´æ›´åŠ æ¿€çƒˆçš„äº‰æ–—ã€‚\n",
      "\n",
      "æ­¤å¤–ï¼Œè®¼å¦è¿˜ä¸ã€Šæ˜“ç»ã€‹ä¸­çš„â€œå¤©å¬â€ç†å¿µæœ‰å…³ã€‚åœ¨ã€Šæ˜“ç»ã€‹ä¸­ï¼Œå¤©å¬æ˜¯æŒ‡å¤©åœ°è‡ªç„¶è§„å¾‹çš„ä½“ç°ï¼Œå®ƒå‘Šè¯‰äººä»¬åº”è¯¥é¡ºåº”è‡ªç„¶ã€éµå¾ªè§„å¾‹ï¼Œè€Œä¸æ˜¯å¼ºè¡Œæ”¹å˜æˆ–å¯¹æŠ—ã€‚å› æ­¤ï¼Œè®¼å¦ä¹Ÿæé†’äººä»¬åœ¨å¤„ç†é—®é¢˜å’ŒçŸ›ç›¾æ—¶è¦é¡ºåº”è‡ªç„¶ã€éµå¾ªè§„å¾‹ï¼Œé¿å…å¼ºè¡Œå¯¹æŠ—ï¼Œä»¥è¾¾åˆ°å’Œè°å…±å¤„çš„ç›®çš„ã€‚\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Comparing result for query: å¸ˆå¦æ˜¯ä»€ä¹ˆï¼Ÿ\n",
      "================================================================================\n",
      "ğŸ“Base model response:\n",
      "å¸ˆå¦æ˜¯ã€Šæ˜“ç»ã€‹ä¸­çš„ç¬¬äº”å¦ï¼Œç”±ä¸¤ä¸ªé˜´çˆ»å¤¹ä¸€ä¸ªé˜³çˆ»æ„æˆï¼Œè±¡å¾ç€æ•™å¸ˆã€æ•™å¯¼ã€çŸ¥è¯†ç­‰ã€‚åœ¨ã€Šæ˜“ç»ã€‹ä¸­ï¼Œé˜³çˆ»ä»£è¡¨é˜³ï¼Œé˜´çˆ»ä»£è¡¨é˜´ï¼Œé˜´çˆ»åœ¨é˜³çˆ»ä¹‹ä¸Šï¼Œè¡¨ç¤ºæŸ”å¼±ä¹‹ä¸Šé˜³ï¼Œè±¡å¾æŸ”å¼±èƒœåˆšå¼ºï¼ŒæŸ”é¡ºèƒœåˆšç¡¬ã€‚å› æ­¤ï¼Œå¸ˆå¦è±¡å¾ç€æŸ”å¼±æœ‰åŠ›é‡ï¼Œæ•™è‚²ä½¿äººå˜æŸ”ï¼Œä½¿äººå˜æ™ºæ…§ã€‚\n",
      "\n",
      "å¸ˆå¦çš„æ„ä¹‰ä¸ä»…é™äºæ•™è‚²ï¼Œè¿˜æ¶‰åŠåˆ°æ•™å¯¼ã€çŸ¥è¯†ã€é¢†å¯¼ç­‰æ–¹é¢ã€‚åœ¨æ•™è‚²æ–¹é¢ï¼Œå¸ˆå¦å¼ºè°ƒæ•™å¸ˆçš„ä½œç”¨ï¼Œæ•™å¸ˆè¦å–„äºæ•™å¯¼å­¦ç”Ÿï¼Œå¼•å¯¼å­¦ç”Ÿå‘æ­£ç¡®çš„æ–¹å‘å‘å±•ã€‚åœ¨é¢†å¯¼æ–¹é¢ï¼Œå¸ˆå¦å¼ºè°ƒé¢†å¯¼è€…è¦å–„äºå¼•å¯¼ã€æ•™å¯¼ä¸‹å±ï¼Œå‘æŒ¥ä¸‹å±çš„æ½œåŠ›ï¼Œä½¿å›¢é˜Ÿå‘ç›®æ ‡è¿ˆè¿›ã€‚\n",
      "\n",
      "æ€»çš„æ¥è¯´ï¼Œå¸ˆå¦å‘Šè¯‰æˆ‘ä»¬ï¼Œæ•™è‚²æ˜¯åŸ¹å…»äººæ‰çš„é‡è¦æ‰‹æ®µï¼Œé¢†å¯¼è€…åœ¨ç®¡ç†ä¸­è¦æ³¨é‡å¼•å¯¼å’Œæ•™å¯¼ï¼Œä»¥ä¿ƒè¿›å›¢é˜Ÿæˆå‘˜çš„æˆé•¿å’Œå‘å±•ã€‚     \n",
      "ğŸ‘‰Fine tuned model (models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_handmade) response: \n",
      "[gMASK]sop å¸ˆå¦æ˜¯ä»€ä¹ˆï¼Ÿ\n",
      "å¸ˆå¦æ˜¯ã€Šæ˜“ç»ã€‹ä¸­çš„ç¬¬äº”å¦ï¼Œç”±ä¸¤ä¸ªé˜´çˆ»å¤¹ä¸€ä¸ªé˜³çˆ»æ„æˆï¼Œè±¡å¾ç€å†›é˜Ÿæˆ–åŠ›é‡ã€‚å¸ˆå¦çš„å«ä¹‰åŒ…æ‹¬ï¼šå†›é˜Ÿã€åŠ›é‡ã€é¢†å¯¼ã€æ•™å¯¼ç­‰ã€‚å®ƒæé†’æˆ‘ä»¬åœ¨é¢å¯¹å›°éš¾å’ŒæŒ‘æˆ˜æ—¶ï¼Œè¦å–„äºç»„ç»‡å’Œè°ƒåŠ¨åŠ›é‡ï¼Œä»¥è¾¾åˆ°å…±åŒçš„ç›®æ ‡ã€‚åŒæ—¶ï¼Œå¸ˆå¦ä¹Ÿå¼ºè°ƒäº†é¢†å¯¼çš„ä½œç”¨ï¼ŒæŒ‡å‡ºé¢†å¯¼è€…åº”è¯¥æœ‰è¿œè§å’Œæ­£ç¡®çš„å†³ç­–ï¼Œä»¥å¼•å¯¼å’Œæ¿€åŠ±éƒ¨é˜Ÿå–å¾—èƒœåˆ©ã€‚\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Comparing result for query: åœ°æ°´å¸ˆå¦æ˜¯ä»€ä¹ˆï¼Ÿ\n",
      "================================================================================\n",
      "ğŸ“Base model response:\n",
      "\"åœ°æ°´å¸ˆå¦\"æ˜¯ä¸­å›½å¤ä»£æ˜“ç»ä¸­çš„ä¸€ä¸ªå¦è±¡,ç”±ä¸¤ä¸ªå¦ç›¸ç»„åˆè€Œæˆ,åˆ†åˆ«æ˜¯â€œåœ°â€å¦å’Œâ€œæ°´â€å¦ã€‚\n",
      "\n",
      "â€œåœ°â€å¦è±¡å¾ç€â€œé¡ºä»â€å’Œâ€œé€‚åº”â€,â€œæ°´â€å¦è±¡å¾ç€â€œæµåŠ¨â€å’Œâ€œå˜åŒ–â€ã€‚å°†è¿™ä¸¤ä¸ªå¦è±¡ç»„åˆåœ¨ä¸€èµ·,æ„å‘³ç€é¡ºåº”è‡ªç„¶ã€é€‚åº”ç¯å¢ƒã€çµæ´»å˜é€šã€æµåŠ¨å‘å±•ã€‚\n",
      "\n",
      "åœ¨æ˜“ç»çš„è§£è¯»ä¸­,åœ°æ°´å¸ˆå¦è¢«è®¤ä¸ºæ˜¯ä¸€ç§â€œå’Œå®‰å…¨â€çš„å¦è±¡,è±¡å¾ç€äººä»¬åœ¨é¢å¯¹å˜åŒ–å’Œä¸ç¡®å®šæ€§æ—¶è¦ä¿æŒå†·é™å’Œæ²‰ç€,ä»¥é€‚åº”å˜åŒ–,ä¿æŒç¨³å®šå’Œå®‰å…¨ã€‚åŒæ—¶,åœ°æ°´å¸ˆå¦ä¹Ÿæé†’äººä»¬è¦æ³¨é‡ä¸å‘¨å›´ç¯å¢ƒçš„åè°ƒå’Œæ²Ÿé€š,ä»¥å®ç°å…±åŒçš„ç›®æ ‡ã€‚     \n",
      "ğŸ‘‰Fine tuned model (models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_handmade) response: \n",
      "[gMASK]sop åœ°æ°´å¸ˆå¦æ˜¯ä»€ä¹ˆï¼Ÿ\n",
      "åœ°æ°´å¸ˆå¦æ˜¯æ˜“ç»ä¸­çš„ä¸€ä¸ªå¦è±¡ï¼Œç”±ä¸¤ä¸ªå¦ç›¸ç»„åˆè€Œæˆï¼šåœ°å¦å’Œæ°´åˆ†æˆä¸¤ä¸ªå¦ï¼Œå³åœ°å¦å’Œé£å¦ã€‚åœ°å¦ä»£è¡¨åœŸåœ°ï¼Œè±¡å¾æŸ”é¡ºã€åŒ…å®¹ã€æ‰¿è½½ï¼›é£å¦ä»£è¡¨é£ï¼Œè±¡å¾å˜åŒ–ã€è‡ªç”±ã€è¿›å–ã€‚å°†ä¸¤ä¸ªå¦ç›¸ç»„åˆï¼Œå½¢æˆåœ°æ°´å¸ˆå¦ï¼Œè±¡å¾åœŸåœ°å’Œé£çš„ç›¸äº’ä½œç”¨ï¼Œå¯“æ„ç€å¤©åœ°è‡ªç„¶çš„åŠ›é‡å’Œäººç±»ç¤¾ä¼šçš„ç›¸äº’å½±å“ã€‚\n",
      "\n",
      "åœ°æ°´å¸ˆå¦çš„æ„ä¹‰ä¸»è¦ä½“ç°åœ¨ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š\n",
      "\n",
      "1. åœŸåœ°å’Œæ°´æºçš„ç›¸äº’å½±å“ï¼šåœ°æ°´å¸ˆå¦æé†’äººä»¬ï¼ŒåœŸåœ°å’Œæ°´æºæ˜¯ç›¸äº’è”ç³»ã€ç›¸äº’å½±å“çš„ã€‚åœŸåœ°æ»‹æ¶¦æ°´æºï¼Œæ°´æºæ»‹æ¶¦åœŸåœ°ï¼ŒäºŒè€…ç›¸äº’ä¿ƒè¿›ï¼Œå½¢æˆä¸€ä¸ªè‰¯å¥½çš„ç”Ÿæ€å¾ªç¯ã€‚\n",
      "\n",
      "2. æŸ”é¡ºä¸è¿›å–çš„ç»“åˆï¼šåœ°å¦è±¡å¾æŸ”é¡ºï¼Œé£å¦è±¡å¾è¿›å–ã€‚åœ°æ°´å¸ˆå¦æé†’äººä»¬ï¼Œåœ¨å¤„ç†äº‹ç‰©æ—¶è¦ä¿æŒæŸ”é¡ºçš„æ€åº¦ï¼ŒåŒæ—¶ä¹Ÿè¦æœ‰è¿›å–çš„ç²¾ç¥ï¼Œæ‰èƒ½è¾¾åˆ°æœ€å¥½çš„æ•ˆæœã€‚\n",
      "\n",
      "3. å¤©åœ°è‡ªç„¶çš„åŠ›é‡ï¼šåœ°æ°´å¸ˆå¦å¼ºè°ƒå¤©åœ°è‡ªç„¶çš„åŠ›é‡ï¼Œæé†’äººä»¬è¦é¡ºåº”è‡ªç„¶ï¼Œå‘æŒ¥è‡ªç„¶çš„åŠ›é‡ï¼Œä»¥è¾¾åˆ°æœ€å¥½çš„ç»“æœã€‚\n",
      "\n",
      "4. äººç±»ç¤¾ä¼šçš„ç›¸äº’å½±å“ï¼šåœ°æ°´å¸ˆå¦è¿˜æé†’äººä»¬ï¼ŒåœŸåœ°å’Œæ°´æºçš„ç›¸äº’ä½œç”¨ä¹Ÿåæ˜ äº†äººç±»ç¤¾ä¼šçš„ç›¸äº’å½±å“ã€‚äººç±»è¦å°Šé‡è‡ªç„¶ï¼Œä¿æŠ¤ç¯å¢ƒï¼Œå®ç°äººä¸è‡ªç„¶çš„å’Œè°å…±å¤„ã€‚\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Comparing result for query: å¤©æ°´è®¼å¦\n",
      "================================================================================\n",
      "ğŸ“Base model response:\n",
      "å¤©æ°´è®¼å¦ï¼ˆå¦è±¡ï¼šä¹¾ï¼Œå¤ï¼‰æ˜¯ã€Šæ˜“ç»ã€‹ä¸­çš„ç¬¬å…­å¦ï¼Œå±äºå…‘å®«ï¼Œç”±ä¸¤ä¸ªå¦ç›¸ç»„åˆè€Œæˆï¼šä¹¾ä¸ºå¤©ï¼Œè¡¨ç¤ºåˆšå¼ºã€ç§¯æã€è¿›å–ï¼›å¤ä¸ºåœ°ï¼Œè¡¨ç¤ºé¡ºä»ã€æ¸©é¡ºã€æ‰¿è½½ã€‚è¿™ä¸ªå¦è±¡å¾ç€å¤©åœ°ä¹‹é—´çš„å¤§å°ç›¸å› ï¼Œäº’ä¸ºä¾é ï¼Œå½¢æˆä¸€ç§å’Œè°å…±ç”Ÿçš„å±€é¢ã€‚\n",
      "\n",
      "åœ¨ã€Šæ˜“ç»ã€‹ä¸­ï¼Œå¤©æ°´è®¼å¦æ„å‘³ç€åœ¨å¤„ç†è¯‰è®¼ã€çº·äº‰ç­‰é—®é¢˜æ—¶ï¼Œåº”è¯¥é‡‡å–å…¬æ­£ã€å…¬å¹³çš„æ€åº¦ï¼ŒåŒæ—¶å…¼é¡¾åŒæ–¹çš„åˆ©ç›Šï¼ŒåŠªåŠ›è¾¾åˆ°å’Œè°å…±å¤„çš„ç›®çš„ã€‚æ­¤å¤–ï¼Œè¿™ä¸ªå¦è¿˜å‘Šè¯«æˆ‘ä»¬ï¼Œè¦æ‡‚å¾—å¤©åœ°ä¹‹é—´çš„ç›¸äº’å…³ç³»ï¼Œå°Šé‡è‡ªç„¶è§„å¾‹ï¼Œæ‰èƒ½åœ¨äº‹ç‰©å‘å±•è¿‡ç¨‹ä¸­ä¿æŒå¹³è¡¡å’Œè°ã€‚     \n",
      "ğŸ‘‰Fine tuned model (models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_handmade) response: \n",
      "[gMASK]sop å¤©æ°´è®¼å¦\n",
      "å¤©æ°´/è®¼å¦\n",
      "\n",
      "ã€Šæ˜“ç»ã€‹å¦è¾ï¼šå¤©æ— è¨€ï¼Œåœ°æ— è¯­ï¼Œ ambiï¼ˆ ambi æ˜¯å¤æ±‰è¯­â€œè¨€â€å­—ï¼Œæœ‰å¤šç§è¯»éŸ³ï¼Œæœ¬å¦ ambi è¯»ç¬¬ä¸‰å£°ï¼Œå–å…¶â€œå¤©è¨€â€ä¹‹æ„ï¼‰ã€‚\n",
      "\n",
      "ã€Šæ˜“ç»ã€‹å½–ä¼ ï¼šå¤©è¡Œå¥ï¼Œå›å­ä»¥è‡ªå¼ºä¸æ¯ï¼›åœ°è¡Œå¤ï¼Œå›å­ä»¥åšå¾·è½½ç‰©ã€‚\n",
      "\n",
      "ã€Šæ˜“ç»ã€‹è±¡ä¼ ï¼šé›·ï¼Œä¸ºå¤©ä¹‹å¿—ï¼›æ³½ï¼Œä¸ºåœ°ä¹‹å¿—ã€‚\n",
      "\n",
      "ã€Šæ˜“ç»ã€‹äº’ä¼ ï¼šäº’ä¼ ä¸ºæŸã€ç›Šã€‚\n",
      "\n",
      "ã€Šæ˜“ç»ã€‹ä¼ ï¼šå¤©æ— è¨€ï¼Œåœ°æ— è¯­ï¼Œ ambiã€‚\n",
      "\n",
      "ã€Šæ˜“ä¼ ã€‹ï¼šå¤©è¨€ï¼Œåœ°è¨€ï¼Œåœ£è´¤ä¹‹è‡³è¨€ã€‚\n",
      "\n",
      "ã€Šæ˜“ä¼ ã€‹ï¼šæœ‰è¨€ï¼Œåˆ™éšï¼›æ— è¨€ï¼Œåˆ™æ˜ã€‚\n",
      "\n",
      "ã€Šæ˜“ä¼ ã€‹ï¼šæ—¶ä¸­åˆ™è§‚ï¼Œæ—¶ä¸­åˆ™ç”¨ã€‚\n",
      "\n",
      "ã€Šæ˜“ä¼ ã€‹ï¼šçŸ¥æ­¢ä¹å…¶æ‰€ä¸èƒ½å·²è€…ï¼Œåˆ™æ— è¿‡å¤±ã€‚\n",
      "\n",
      "ã€Šæ˜“ä¼ ã€‹ï¼šå¤©è¡Œå¥ï¼Œå›å­ä»¥è‡ªå¼ºä¸æ¯ï¼›åœ°è¡Œå¤ï¼Œå›å­ä»¥åšå¾·è½½ç‰©ã€‚\n",
      "\n",
      "ã€Šæ˜“ä¼ ã€‹ï¼šå¤©æ— è¨€ï¼Œåœ°æ— è¯­ï¼Œ ambiã€‚\n",
      "\n",
      "ã€Šæ˜“ä¼ ã€‹ï¼šå¤©è¨€ï¼Œåœ°è¨€ï¼Œåœ£è´¤ä¹‹è‡³è¨€ã€‚\n",
      "\n",
      "ã€Šæ˜“ä¼ ã€‹ï¼šæœ‰è¨€ï¼Œåˆ™éšï¼›æ— è¨€ï¼Œåˆ™æ˜ã€‚\n",
      "\n",
      "ã€Šæ˜“ä¼ ã€‹ï¼šæ—¶ä¸­åˆ™è§‚ï¼Œæ—¶ä¸­åˆ™ç”¨ã€‚\n",
      "\n",
      "ã€Šæ˜“ä¼ ã€‹ï¼šçŸ¥æ­¢ä¹å…¶æ‰€ä¸èƒ½å·²è€…ï¼Œåˆ™æ— è¿‡å¤±ã€‚\n",
      "\n",
      "ã€Šæ˜“ä¼ ã€‹ï¼šå¤©è¡Œå¥ï¼Œå›å­ä»¥è‡ªå¼ºä¸æ¯ï¼›åœ°è¡Œå¤ï¼Œå›å­ä»¥åšå¾·è½½ç‰©ã€‚\n",
      "\n",
      "ã€Šæ˜“ä¼ ã€‹ï¼šå¤©æ— è¨€ï¼Œåœ°æ— è¯­ï¼Œ ambiã€‚\n",
      "\n",
      "ã€Šæ˜“ä¼ ã€‹ï¼šå¤©è¨€ï¼Œåœ°è¨€ï¼Œåœ£è´¤ä¹‹è‡³è¨€ã€‚\n",
      "\n",
      "ã€Šæ˜“ä¼ ã€‹ï¼šæœ‰è¨€ï¼Œåˆ™éšï¼›æ— è¨€ï¼Œåˆ™æ˜ã€‚\n",
      "\n",
      "ã€Šæ˜“ä¼ ã€‹ï¼šæ—¶ä¸­åˆ™è§‚ï¼Œæ—¶ä¸­åˆ™ç”¨ã€‚\n",
      "\n",
      "ã€Šæ˜“ä¼ ã€‹ï¼šçŸ¥æ­¢ä¹å…¶æ‰€ä¸èƒ½å·²è€…ï¼Œåˆ™æ— è¿‡å¤±ã€‚\n",
      "\n",
      "ã€Šæ˜“ä¼ ã€‹ï¼šå¤©è¡Œå¥ï¼Œå›å­ä»¥è‡ªå¼ºä¸æ¯ï¼›åœ°è¡Œå¤ï¼Œå›å­ä»¥åšå¾·è½½ç‰©ã€‚\n",
      "\n",
      "ã€Šæ˜“ä¼ ã€‹ï¼šå¤©æ— è¨€ï¼Œåœ°æ— è¯­ï¼Œ ambiã€‚\n",
      "\n",
      "ã€Šæ˜“ä¼ ã€‹ï¼šå¤©è¨€ï¼Œåœ°è¨€ï¼Œåœ£è´¤ä¹‹è‡³è¨€ã€‚\n",
      "\n",
      "ã€Šæ˜“ä¼ ã€‹ï¼šæœ‰è¨€ï¼Œ\n"
     ]
    }
   ],
   "source": [
    "# this cell is to evaluate the modles\n",
    "# function to free up mem and remove all variables\n",
    "def freeup_mem_deep():\n",
    "    print(\"\\nğŸ”§ Releasing GPU ...\")\n",
    "    import torch, gc\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    %reset -f\n",
    "# call to freeup mem    \n",
    "freeup_mem_deep()\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftModel, PeftConfig\n",
    "import time\n",
    "\n",
    "# ======================\n",
    "# 1. parameters setup\n",
    "# ======================\n",
    "\n",
    "# the base model\n",
    "model_name_or_path = 'THUDM/chatglm3-6b'\n",
    "\n",
    "# support multiple fine tuned models\n",
    "#\"data/zhouyi_dataset_20240118_152413.csv\",\n",
    "#\"data/zhouyi_dataset_20240118_163659.csv\",\n",
    "#\"data/zhouyi_dataset_handmade_20250811_163200.csv\",\n",
    "peft_model_paths = [\n",
    "    f\"models/{model_name_or_path}-epoch3-zhouyi_dataset_20240118_152413\",\n",
    "    f\"models/{model_name_or_path}-epoch3-zhouyi_dataset_20240118_163659\",\n",
    "    f\"models/{model_name_or_path}-epoch3-zhouyi_dataset_handmade\",\n",
    "    #can add more models for test\n",
    "]\n",
    "\n",
    "_compute_dtype_map = {\n",
    "    'fp32': torch.float32,\n",
    "    'fp16': torch.float16,\n",
    "    'bf16': torch.bfloat16\n",
    "}\n",
    "\n",
    "# init q_configï¼ˆwith 4bitï¼‰\n",
    "q_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=_compute_dtype_map['bf16']\n",
    ")\n",
    "\n",
    "# ======================\n",
    "# 2. load the base model\n",
    "# ======================\n",
    "\n",
    "print(f\"ğŸ” Loading the base model: {model_name_or_path} (not fine tuned)...\")\n",
    "base_model = AutoModel.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    quantization_config=q_config,\n",
    "    trust_remote_code=True,\n",
    "    device_map='auto',\n",
    "    revision='b098244'\n",
    ")\n",
    "base_model.requires_grad_(False)\n",
    "\n",
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True, revision='b098244')\n",
    "\n",
    "# ======================\n",
    "# 3. function to evaluate and compare the models\n",
    "# ======================\n",
    "def compare_chatglm_results(query, base_model, qlora_model, training_tag):\n",
    "    base_response, base_history = base_model.chat(tokenizer, query)\n",
    "\n",
    "    inputs = tokenizer(query, return_tensors=\"pt\").to(0)\n",
    "    ft_out = qlora_model.generate(**inputs, max_new_tokens=512)\n",
    "    ft_response = tokenizer.decode(ft_out[0], skip_special_tokens=True)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"ğŸ“Š Comparing result for query: {query}\")\n",
    "    print(\"=\"*80)\n",
    "    #print(f\" ğŸ“ Questionï¼š{query} \\\n",
    "    print(f\"ğŸ“Base model response:\\n{base_response} \\\n",
    "    \\nğŸ‘‰Fine tuned model ({training_tag}) response: \\n{ft_response}\")\n",
    "    #print(\"=\"*60)\n",
    "    return base_response, ft_response\n",
    "\n",
    "# ======================\n",
    "# 4. Evaluate and compare base model and peft model\n",
    "# ======================\n",
    "for peft_model_dir in peft_model_paths:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"ğŸ” Loading PEFT model from: {peft_model_dir}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        # Load the PEFT adapter with the base_model\n",
    "        config = PeftConfig.from_pretrained(peft_model_dir)\n",
    "        qlora_model = PeftModel.from_pretrained(base_model, peft_model_dir)\n",
    "        base_response, ft_response = compare_chatglm_results(\"è§£é‡Šä¸‹ä¹¾å¦æ˜¯ä»€ä¹ˆï¼Ÿ\", base_model, qlora_model, peft_model_dir)\n",
    "        base_response, ft_response = compare_chatglm_results(\"å‘¨æ˜“ä¸­çš„è®¼å¦æ˜¯ä»€ä¹ˆ\", base_model, qlora_model, peft_model_dir)\n",
    "        base_response, ft_response = compare_chatglm_results(\"å¸ˆå¦æ˜¯ä»€ä¹ˆï¼Ÿ\", base_model, qlora_model, peft_model_dir)\n",
    "        base_response, ft_response = compare_chatglm_results(\"åœ°æ°´å¸ˆå¦æ˜¯ä»€ä¹ˆï¼Ÿ\", base_model, qlora_model, peft_model_dir)\n",
    "        base_response, ft_response = compare_chatglm_results(\"å¤©æ°´è®¼å¦\", base_model, qlora_model, peft_model_dir)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to load the model: {peft_model_dir} with error: {e}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0576c1a422c341f88ff6bf765e19882f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "097c6f83e8ef4ba08b8d872929979683": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_4b8f705761024b2c91f7e4d8598e5d52",
       "style": "IPY_MODEL_4176e2fa6ae947f2b4fda097cbd91912",
       "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
      }
     },
     "0fc707c52fee4b198a371e4a73e0d05b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2359c7f1ec004001a7b22ae658e43299": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "268d605db027490cad432e508014aa3e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_d1d245a5adff4cf29170ecc5a41659c9",
        "IPY_MODEL_39fb305c768c46378b1760efe8432e73",
        "IPY_MODEL_43c13ec36e3044ef84f822968e2964d3"
       ],
       "layout": "IPY_MODEL_75824edf769f4cd99f1589613ed2868b"
      }
     },
     "3102855d954b466e80bbf1822f46dce7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_5c4c02b838874d9f939632032e76f4d0",
       "style": "IPY_MODEL_7c4025bdb0ec4ecaacd8401b49886613",
       "value": "â€‡7/7â€‡[00:05&lt;00:00,â€‡â€‡1.37it/s]"
      }
     },
     "3536ee372c8e43a3886b582fd068f699": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "39bfebf8713844ddb2591dfa734d1034": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "39cc873fdd644943ae1e87ebe6cf1383": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "39fb305c768c46378b1760efe8432e73": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_e89b536e97b44e8fbd97edd61e32b1c7",
       "max": 7,
       "style": "IPY_MODEL_ec6e1356f7c64bd293ee564bde7c7938",
       "value": 7
      }
     },
     "3a0bf8fccaff4581b334311e08f1c990": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4176e2fa6ae947f2b4fda097cbd91912": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "43c13ec36e3044ef84f822968e2964d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_842ffdfc3389439d8e0a71666e348a6b",
       "style": "IPY_MODEL_f00658453c8440c197747b9777b217a7",
       "value": "â€‡7/7â€‡[00:05&lt;00:00,â€‡â€‡1.37it/s]"
      }
     },
     "44a5af6567fb46c9984c7bf1cc4368da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "4530b92ccad341e6a898bf008c5c5317": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4b8f705761024b2c91f7e4d8598e5d52": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4bca913c08b34c3497cb4208804269e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_8bd1e1a3a5c24b19b9aad8827b6f383c",
       "style": "IPY_MODEL_c6c0dabca3fd4b6ab4b612aad78f5bfd",
       "value": "â€‡7/7â€‡[00:05&lt;00:00,â€‡â€‡1.28it/s]"
      }
     },
     "4c71c43319cd422a8b5c9be1b6f0f712": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4c76f991a3fa4d8cb2b563318fca777a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_a13c8dc8f03b4e4b8212e9297e1a8a82",
       "max": 7,
       "style": "IPY_MODEL_a2bb0f350e6b4123b291a844eee18614",
       "value": 7
      }
     },
     "5b555a9350ea46a9b23e1a6f063a32d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5c4369aa49704de98aa2cb37deba7c1c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_f6df7093f4724378b6f5c50f8944a725",
       "max": 7,
       "style": "IPY_MODEL_67a2f45389e147c7a21ca3152e2e2271",
       "value": 7
      }
     },
     "5c4c02b838874d9f939632032e76f4d0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5cf25613304a47988b300825366431bc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5d8476893ce2442d80a0a41da19c1e5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "60811dcd62c14e34b83e0111d68ec2f4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "62a472b89bd94294b42d7323332de4c2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_64917d22ab624211988d879762091343",
        "IPY_MODEL_96131c8ae67b42e48595c6cbbc3ddc43",
        "IPY_MODEL_3102855d954b466e80bbf1822f46dce7"
       ],
       "layout": "IPY_MODEL_4530b92ccad341e6a898bf008c5c5317"
      }
     },
     "64917d22ab624211988d879762091343": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_39bfebf8713844ddb2591dfa734d1034",
       "style": "IPY_MODEL_5b555a9350ea46a9b23e1a6f063a32d0",
       "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
      }
     },
     "64b5cd77f9f941648c8dc1df927ad663": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "67a2f45389e147c7a21ca3152e2e2271": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "687f6d3ac6634444b8d2ebc1a45ffc42": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_af9f08c315464123ace14ee80007f4ed",
       "style": "IPY_MODEL_83aea87ac26f411793a1d8f111dde75a",
       "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
      }
     },
     "6b6c96d6428f4aefbcd56bd178d8881e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6d757f0a3ad64e1a8f55ca3af9232b36": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "71d0d8a5857f4099a11097eb97ceda3e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_8d2e3fbd5f32429d93247b7e0a002b48",
       "style": "IPY_MODEL_74d8a676ba7240dd84a29f8af10bb80b",
       "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
      }
     },
     "74d8a676ba7240dd84a29f8af10bb80b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "75824edf769f4cd99f1589613ed2868b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7c4025bdb0ec4ecaacd8401b49886613": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "83aea87ac26f411793a1d8f111dde75a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "842ffdfc3389439d8e0a71666e348a6b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8bd1e1a3a5c24b19b9aad8827b6f383c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8d2e3fbd5f32429d93247b7e0a002b48": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8e485dc7dd3142b69d4444e09f98cb75": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_6d757f0a3ad64e1a8f55ca3af9232b36",
       "max": 7,
       "style": "IPY_MODEL_5d8476893ce2442d80a0a41da19c1e5b",
       "value": 7
      }
     },
     "940749c3e7d449c69d8ce71caf648a41": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "96131c8ae67b42e48595c6cbbc3ddc43": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_60811dcd62c14e34b83e0111d68ec2f4",
       "max": 7,
       "style": "IPY_MODEL_44a5af6567fb46c9984c7bf1cc4368da",
       "value": 7
      }
     },
     "965a7cb70c9e48a08a0718abf249dd43": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_687f6d3ac6634444b8d2ebc1a45ffc42",
        "IPY_MODEL_8e485dc7dd3142b69d4444e09f98cb75",
        "IPY_MODEL_9a45aa0117844cfb98cd481baee1eadf"
       ],
       "layout": "IPY_MODEL_e87defdeaae54efd85c44bf4e64fc949"
      }
     },
     "9a45aa0117844cfb98cd481baee1eadf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_64b5cd77f9f941648c8dc1df927ad663",
       "style": "IPY_MODEL_0576c1a422c341f88ff6bf765e19882f",
       "value": "â€‡7/7â€‡[00:05&lt;00:00,â€‡â€‡1.38it/s]"
      }
     },
     "a13c8dc8f03b4e4b8212e9297e1a8a82": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a2bb0f350e6b4123b291a844eee18614": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a6b9ffb6636044ecb41c602a7834fcdb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_5cf25613304a47988b300825366431bc",
       "max": 7,
       "style": "IPY_MODEL_940749c3e7d449c69d8ce71caf648a41",
       "value": 7
      }
     },
     "aa146911bb71405b8143965aa1720ea5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "af9f08c315464123ace14ee80007f4ed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bf2c5dcb272142968321bd2870712693": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c06f71261335456198fd9bc86625fe04": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c4849ecb1a8b4669a7cc4b785983efa8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_aa146911bb71405b8143965aa1720ea5",
       "style": "IPY_MODEL_3a0bf8fccaff4581b334311e08f1c990",
       "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
      }
     },
     "c6c0dabca3fd4b6ab4b612aad78f5bfd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d1d245a5adff4cf29170ecc5a41659c9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_39cc873fdd644943ae1e87ebe6cf1383",
       "style": "IPY_MODEL_3536ee372c8e43a3886b582fd068f699",
       "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
      }
     },
     "df25d981f6994fa2a4e006440f1a3af0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_71d0d8a5857f4099a11097eb97ceda3e",
        "IPY_MODEL_4c76f991a3fa4d8cb2b563318fca777a",
        "IPY_MODEL_f6d9990495554f0081176dc879b40518"
       ],
       "layout": "IPY_MODEL_c06f71261335456198fd9bc86625fe04"
      }
     },
     "e87defdeaae54efd85c44bf4e64fc949": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e89b536e97b44e8fbd97edd61e32b1c7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ec6e1356f7c64bd293ee564bde7c7938": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ede20c088f89468d99eb22ba12efd7d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_c4849ecb1a8b4669a7cc4b785983efa8",
        "IPY_MODEL_a6b9ffb6636044ecb41c602a7834fcdb",
        "IPY_MODEL_4bca913c08b34c3497cb4208804269e2"
       ],
       "layout": "IPY_MODEL_6b6c96d6428f4aefbcd56bd178d8881e"
      }
     },
     "f00658453c8440c197747b9777b217a7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f604f4549ffd462bb0607edbf76ddb4b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_2359c7f1ec004001a7b22ae658e43299",
       "style": "IPY_MODEL_0fc707c52fee4b198a371e4a73e0d05b",
       "value": "â€‡7/7â€‡[00:05&lt;00:00,â€‡â€‡1.37it/s]"
      }
     },
     "f6d9990495554f0081176dc879b40518": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_bf2c5dcb272142968321bd2870712693",
       "style": "IPY_MODEL_4c71c43319cd422a8b5c9be1b6f0f712",
       "value": "â€‡7/7â€‡[00:05&lt;00:00,â€‡â€‡1.43it/s]"
      }
     },
     "f6df7093f4724378b6f5c50f8944a725": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f6fbda0fbb6a4f5a8dff1e5dc799a987": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "faac7503f67f47caa61b8815b1cde157": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_097c6f83e8ef4ba08b8d872929979683",
        "IPY_MODEL_5c4369aa49704de98aa2cb37deba7c1c",
        "IPY_MODEL_f604f4549ffd462bb0607edbf76ddb4b"
       ],
       "layout": "IPY_MODEL_f6fbda0fbb6a4f5a8dff1e5dc799a987"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
