{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb393a61",
   "metadata": {},
   "source": [
    "# peft qlora chatglm finetune and inference with custom dataset\n",
    "\n",
    "```\n",
    "第四周作业：\n",
    "1、基于 data 目录下的数据训练 ChatGLM3 模型，使用 inference Notebook 对比微调前后的效果。------> this notebook is for this task.\n",
    "2、（可选）：将 gen_dataset Notebook 改写为 py 文件。\n",
    "作业代码：\n",
    "微调的代码：https://github.com/DjangoPeng/LLM-quickstart/blob/main/chatglm/qlora_chatglm3_timestamp.ipynb\n",
    "使用微调后模型进行推理的代码：https://github.com/DjangoPeng/LLM-quickstart/blob/main/chatglm/chatglm_inference.ipynb\n",
    "生成数据集的代码：https://github.com/RorschachWwww/LLM-quickstart/blob/main/chatglm/gen_dataset.ipynb\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fa8105c-6dda-426b-9180-ab9abbc9ce9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 12.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.9.2\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
      " _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15095MB, multi_processor_count=40)\n",
      "\n",
      "================================================================================\n",
      "🔍 Train/Eval with dataset: data/zhouyi_dataset_20240118_152413.csv\n",
      "================================================================================\n",
      "\n",
      "🔧 Releasing GPU ...\n",
      "loading dataset_name:data/zhouyi_dataset_20240118_152413.csv\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['content', 'summary'],\n",
      "        num_rows: 160\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>需卦在周易中是什么象征？</td>\n",
       "      <td>需卦\"由上卦坎（水）和下卦乾（天）组成，上卦为云，下卦为天。上卦坎为险，下卦乾为刚，象征着云浮聚于天上，待时降雨之象。预示抓到俘虏，大吉大利，有利于涉水渡河。君子观此卦象，可以宴饮安乐，待时而动。\\n\\n这个卦象表示踌躇期待，虽然刚强，但前面有险阻，应当等待，涉大川则利。时机尚未成熟，需要耐心等待，不宜冒进。谋事应审时度势，耐心等待，切勿冒险，欲速不达。自信、坚守中正，可化险为夷。情况有利时，仍得居安思危。\\n\\n需卦的核心哲学是谋事应审时度势，耐心等待，切勿冒险，欲速不达。自信、坚守中正，可以化险为夷。需要控制饮食，保持健康的生活方式。在感情和婚姻方面，需要慎重、诚实、和柔克刚。\\n\\n在行动之初，需要极大的耐心，观时待变，创造条件和机会。等待时机成熟后，大器必定晚成。在事业发展中，遇到困难和险阻时，必须十分谨慎，坦然对待小人的中伤。为人处事应谦和、坦率，多有他人相助，促使事业成功。当时机成熟后，则必然一帆风顺。\"\\n\\nsource:\"《易经》</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>请解释一下比卦。</td>\n",
       "      <td>比卦\"是周易卦象中的一枚卦，由下卦坤（地）上卦坎（水）组成，预示着吉利的变化。在卜筮时，再次占卜依然吉利，预示长期稳定无灾祸。然而，当不愿臣服的邦国未能前来朝贺时，将会带来危险。\\n\\n在《象辞》中，比卦被描述为地上有水的情景，反映了相亲相依相互依赖的意义。先王观此卦象，取法于水附大地，地纳江河之象，因此此卦被解释为建立万国，亲近诸侯。\\n\\n北宋易学家邵雍解释认为，比卦代表水在地面上流动，人际关系亲密和睦，各种事情无忧无虑。\\n\\n台湾国学大儒傅佩荣解释认为，比卦的时运是众人相贺，财运是善人相扶，家宅方面是长久美满，身体方面则需早求治心腹水肿。\\n\\n传统解卦认为，比卦预示着相亲相辅，宽宏无私，精诚团结的道理。在运势上，表示平顺，能得贵人提拔，事业宜速战速决，不宜过度迟疑。对于事业、经商、求名、婚恋等方面都有积极的影响，提醒人们待人宽厚、正直，主动热情，并谨慎选择朋友。\\n\\n总之，\"比卦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"讼卦在周易中怎样表达教育的概念？</td>\n",
       "      <td>在周易中，讼卦是一个极具深意的卦象。上卦为乾（天），下卦为坎（水），两者相背而行，代表天与水违行的状况，象征着事理乖舛和争讼之象。讼卦中有利可图，但必须警惕戒惧，事情中间吉利，但最终会有凶险。在卜卦时，利于会见贵族王公，但不利于涉水渡河。\\n\\n讼卦的核心哲学是：开始可能顺利，有所收获，但随后会遇到困难和挫折。因此，务必慎之又慎，不得固执已见，避免介入诉讼纠纷的争执之中。退让而不固执，求得化解，安于正理，可免除意外之灾。陷入争讼，即使获胜，最后还得失去，得不偿失。\\n\\n讼卦的经商指引是：和气生财，吃亏是福，切勿追求不义之财。在商业谈判中要坚持公正、公平、互利的原则，尽量避免发生冲突。\\n\\n对于决策，讼卦提醒我们，争强好胜，不安于现状，为改变命运和超越他人而奋斗。但缺乏持之以恒的毅力，容易得罪他人，带来诉讼之灾。因此，接受教训，引以为戒，可功成名就。\\n\\n讼卦所蕴含的智慧是：在面对争端和异见时，要善于退让和求和，坚守正道，谨慎处事，以避免不必要的冲突和损失。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>周易的\"乾卦讲述了什么？</td>\n",
       "      <td>\"乾卦\"\\nsummary: \"《易经》中的乾卦是六十四卦中的首卦，象征天，由六个阳爻组成，代表着刚健强劲的特性。其卦辞为“元、亨、利、贞”，预示着吉祥如意，同时也教导人们遵守天道的德行。乾卦所蕴含的核心哲学是：天道刚健，运行不已，君子观此卦象，从而以天为法，自强不息。\"\\n\\ncomment: \"在传统解卦中，乾卦预示着大吉大利，事业如日中天，但也提醒要警惕盛极必衰的道理。经商方面顺利发展，但要冷静分析形势，坚持商业道德。对于婚恋，尽管阳盛阴衰，但刚柔可相济，最终形成美满结果。总体而言，乾卦代表着充满活力和力量的时机，但也需要保持谦逊谨慎的态度，以应对可能出现的困难。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"讼卦涉及哪些哲学思想？</td>\n",
       "      <td>在周易中，讼卦是一个极具深意的卦象。上卦为乾（天），下卦为坎（水），两者相背而行，代表天与水违行的状况，象征着事理乖舛和争讼之象。讼卦中有利可图，但必须警惕戒惧，事情中间吉利，但最终会有凶险。在卜卦时，利于会见贵族王公，但不利于涉水渡河。\\n\\n讼卦的核心哲学是：开始可能顺利，有所收获，但随后会遇到困难和挫折。因此，务必慎之又慎，不得固执已见，避免介入诉讼纠纷的争执之中。退让而不固执，求得化解，安于正理，可免除意外之灾。陷入争讼，即使获胜，最后还得失去，得不偿失。\\n\\n讼卦的经商指引是：和气生财，吃亏是福，切勿追求不义之财。在商业谈判中要坚持公正、公平、互利的原则，尽量避免发生冲突。\\n\\n对于决策，讼卦提醒我们，争强好胜，不安于现状，为改变命运和超越他人而奋斗。但缺乏持之以恒的毅力，容易得罪他人，带来诉讼之灾。因此，接受教训，引以为戒，可功成名就。\\n\\n讼卦所蕴含的智慧是：在面对争端和异见时，要善于退让和求和，坚守正道，谨慎处事，以避免不必要的冲突和损失。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  The dataset doesn't have 'validation' split， not evaluating.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df25d981f6994fa2a4e006440f1a3af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n",
      "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,899,392 || all params: 6,247,483,392 || trainable%: 0.06241540401681151\n",
      "dataset_name=data/zhouyi_dataset_20240118_152413.csv\n",
      "training_args num_train_epochs: 3, logging_steps: 1, eval_steps: 1, save_steps: 10, per_device_train_batch_size: 8, , gradient_accumulation_steps: 1\n",
      "start train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 13:31, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.594100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.049100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.089700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.375100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.539200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.601600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.654100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.163400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.274700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.291900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.855600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.891600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.555700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.994600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.001400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.532300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.624300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.567800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.511100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.279900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.255300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.199300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.128700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.130100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.085500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.054700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.044700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.022400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.024000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.023200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.027700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.017500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.012300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.010400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.012800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.013300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.015600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.010100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.007500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.005400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.006100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.007200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.005700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.004700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.004500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.005700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.005400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.005100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.004700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.004800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.003800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.004400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.004600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.004100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.003500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.003300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.002700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.003900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.003400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_152413/checkpoint-10 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_152413/checkpoint-20 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_152413/checkpoint-30 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_152413/checkpoint-40 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_152413/checkpoint-50 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_152413/checkpoint-60 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end train.\n",
      "✅ fine tuned model saved to path: models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_152413\n",
      "\n",
      "================================================================================\n",
      "🔍 Train/Eval with dataset: data/zhouyi_dataset_20240118_163659.csv\n",
      "================================================================================\n",
      "\n",
      "🔧 Releasing GPU ...\n",
      "loading dataset_name:data/zhouyi_dataset_20240118_163659.csv\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['content', 'summary'],\n",
      "        num_rows: 160\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>屯卦在周易中怎样表达教育的概念？</td>\n",
       "      <td>在周易中，屯卦是一个大吉大利的卦象，预示着吉祥和大利。然而，不利于出门，但有利于建国封侯。屯卦由上卦坎（水）下卦震（雷）组成，坎为云，震为雷。预示着云行雷动的卦象。君子观此卦象，取法于云雷，用云的恩泽，雷的威严来治理国事。屯卦象征着开始困难，需要毅力和果敢才能获得吉利。身处困境需要多加辛苦努力，排除困难，方可通达，有初难后解之象。因此，对于事业创业而言，应当小心翼翼，勇往直前，灵活机动，可望获得大的成功。但也需注意到仍有困难存在，务必有他人相助，平时应多施恩惠。对于经商，起初多有挫折，必须坚定信念，积极进取，行动果断，若仍无法摆脱困境，则应退守保全，等待机会，再展宏图。对于婚恋，好事多磨，忠贞纯洁，大胆追求，能够成功。屯卦的核心哲学在于，初难后解，需要毅力和坚忍不拔的毅力和锲而不舍的奋斗精神，但也需得到贤德之人的帮助才能摆脱困境。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>周易的蒙卦讲述了什么？</td>\n",
       "      <td>蒙卦是由艮卦（山）下，坎卦（水）上组成的异卦相叠。它代表着通泰，启蒙的意义。在这里，卜者并非是在向幼稚愚昧的人取求，而是幼稚愚昧的人在向卜者求教。第一次卜筮就得到了神灵的指示。然而，如果轻慢不敬地再三卜筮的话，神灵便不会再示警。总的来说，这是一个吉利的卜问。\\n\\n蒙卦的核心在于山下有泉的形象，寓意着启蒙。君子观此卦象，应当以果敢坚毅的行动来培养自身的品德，像山泉一样果断行动。然而，此卦乃是离宫四世卦，它代表着回还往复、疑惑不前、多忧愁过失，因而属于凶卦。\\n\\n蒙卦在个人发展、事业经商、求名婚恋等方面的解释不一。在事业方面，表示事业初建，具有启蒙和通达之象，需要勇敢坚毅的行动；而在经商方面，需要务必小心谨慎，树立高尚的商业道德，不可急功近利；求名方面，需要接受良好的基础教育，陶冶情操。整体而言，此卦提示须忍耐待机而动，听取别人意见，方能通达运势。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>周易中讼卦的解释是什么？</td>\n",
       "      <td>在周易中，讼卦是一个充满警示的卦象。它由上卦乾（天）和下卦坎（水）组成，代表着天与水背道而驰，形成争讼的局面。虽然事情开始时有利可图，但必须警惕戒惧，因为中间虽然吉利，但最终会带来凶险。对于涉及大川，涉水渡河的行动不利。因此，君子观此卦象，应当慎之又慎，杜绝争讼之事，并在谋事之初谨慎行事。讼卦的核心哲学是要避免争讼，退而让人，求得化解，安于正理，方可避免意外之灾。在事业上，务必避免介入诉讼纠纷的争执之中，与其这样，不如退而让人。即使最终获胜，也难免得失不均。经商方面，要坚持公正、公平、互利的原则，避免冲突，这样会有好结果。而对于求名、婚恋和决策，也都需要慎重行事，避免盲目追求，退让让人，可助事业、婚姻和决策的发展。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>请解释一下讼卦。</td>\n",
       "      <td>在周易中，讼卦是一个充满警示的卦象。它由上卦乾（天）和下卦坎（水）组成，代表着天与水背道而驰，形成争讼的局面。虽然事情开始时有利可图，但必须警惕戒惧，因为中间虽然吉利，但最终会带来凶险。对于涉及大川，涉水渡河的行动不利。因此，君子观此卦象，应当慎之又慎，杜绝争讼之事，并在谋事之初谨慎行事。讼卦的核心哲学是要避免争讼，退而让人，求得化解，安于正理，方可避免意外之灾。在事业上，务必避免介入诉讼纠纷的争执之中，与其这样，不如退而让人。即使最终获胜，也难免得失不均。经商方面，要坚持公正、公平、互利的原则，避免冲突，这样会有好结果。而对于求名、婚恋和决策，也都需要慎重行事，避免盲目追求，退让让人，可助事业、婚姻和决策的发展。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>在周易中，需卦象征着什么？</td>\n",
       "      <td>需卦是一个占卜卦象，在周易卦象中，它由下卦乾和上卦坎组成。坎象征着云，乾象征着天，云聚于天，形成了等待时机的卦象。这是一个大吉大利的卜问，特别适合涉水渡河。根据《象辞》，君子观此卦象，可以宴饮安乐，待时而动。\\n\\n需卦的核心哲学是：稳扎稳打，不可冒失行动，观时待变，耐心等待。在事业上，需要审时度势，守中正，不可急进，自信充满，可化险为夷。在经商中，必须充满耐心，创造条件和机会，行事光明磊落，等到时机成熟后必然一帆风顺。在感情方面，亦需慎重，培养感情，以诚实、热情相待，时机成熟后可以有良好的结果。\\n\\n需卦紧随坤宫游魂卦，预示着踌躇和期待。得此卦者，需要时机尚未成熟，需要耐心等待，急进反会见凶险。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  The dataset doesn't have 'validation' split， not evaluating.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "268d605db027490cad432e508014aa3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n",
      "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,899,392 || all params: 6,247,483,392 || trainable%: 0.06241540401681151\n",
      "dataset_name=data/zhouyi_dataset_20240118_163659.csv\n",
      "training_args num_train_epochs: 3, logging_steps: 1, eval_steps: 1, save_steps: 10, per_device_train_batch_size: 8, , gradient_accumulation_steps: 1\n",
      "start train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 07:07, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.672500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.701000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.272900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.395500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.951000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.685900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.522200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.138600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.022000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.764000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.532700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.224000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.752200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.841700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.484900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.488200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.091200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.764800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.816200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.590900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.435400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.285300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.262600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.190800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.123000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.084200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.055000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.066900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.031800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.049500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.027400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.021900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.018300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.019100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.013700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.013600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.011000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.009500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.008600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.007300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.006600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.006100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.005900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.006100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.005100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.004600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.004900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.004300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.004300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.004300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.004200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.004100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.003800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.004300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.004200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.004200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end train.\n",
      "✅ fine tuned model saved to path: models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_163659\n",
      "\n",
      "================================================================================\n",
      "🔍 Train/Eval with dataset: data/zhouyi_dataset_handmade.csv\n",
      "================================================================================\n",
      "\n",
      "🔧 Releasing GPU ...\n",
      "loading dataset_name:data/zhouyi_dataset_handmade.csv\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['content', 'summary'],\n",
      "        num_rows: 8\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>坤卦</td>\n",
       "      <td>坤卦原文\\n坤。元，亨，利牝马之贞。君子有攸往，先迷后得主。利西南得朋，东北丧朋。安贞，吉。\\n象曰：地势坤，君子以厚德载物。\\n白话文解释\\n坤卦：大吉大利。占问雌马得到吉兆。君子前去旅行，先迷失路途，后来找到主人，吉利。西南行获得财物，东北行丧失财物。占问定居，得到吉兆。\\n《象辞》说：大地的形势平铺舒展，顺承天道。君子观此卦象，取法于地，以深厚的德行来承担重大的责任。\\n《断易天机》解\\n坤卦坤上坤下，为坤宫本位卦。坤卦为柔顺，为地气舒展之象，具有纯阴之性，先失道而后得主，宜往西南，西南可得到朋友。\\n北宋易学家邵雍解\\n柔顺和静，厚载之功；静守安顺，妄动招损。\\n得此卦者，宜顺从运势，以静制动，不宜独立谋事，顺从他人，一起合作，可成大事。\\n台湾国学大儒傅佩荣解\\n时运：为人厚道，声名远传。\\n财运：满载而归。\\n家宅：家庭安稳；婚嫁大吉。\\n身体：柔软运动。\\n传统解卦\\n这个卦是同卦（下坤上坤）相叠，阴性。象征地（与乾卦相反），顺从天，承载万物，伸展无穷无尽。坤卦以雌马为象征，表明地道生育抚养万物，而又依天顺时，性情温顺。它以“先迷后得”证明“坤”顺从“乾”，依随“乾”，才能把握正确方向，遵循正道，获取吉利。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>乾卦</td>\n",
       "      <td>乾卦原文\\n乾。元，亨，利，贞。\\n象曰：天行健，君子以自强不息。\\n\\n白话文解释\\n乾卦：大吉大利，吉利的贞卜。\\n《象辞》说：天道刚健，运行不已。君子观此卦象，从而以天为法，自强不息。\\n\\n《断易天机》解\\n乾象征天，六阳爻构成乾卦，为《易经》六十四卦之首。纯阳刚建，其性刚强，其行劲健，大通而至正，兆示大通而有利，但须行正道，方可永远亨通。\\n\\n北宋易学家邵雍解\\n刚健旺盛，发育之功；完事顺利，谨防太强。\\n得此卦者，天行刚健，自强不息，名利双收之象，宜把握机会，争取成果。女人得此卦则有过于刚直之嫌。\\n\\n传统解卦\\n这个卦是同卦（下乾上乾）相叠。象征天，喻龙（德才的君子），又象征纯粹的阳和健，表明兴盛强健。乾卦是根据万物变通的道理，以“元、亨、利、贞”为卦辞，表示吉祥如意，教导人遵守天道的德行。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>水天需卦</td>\n",
       "      <td>需卦原文：需。有孚，光亨，贞吉。利涉大川。象曰：云上于天，需；君子以饮食宴乐。白话文解释：需卦代表俘虏，大吉大利，适宜涉水过河。《象辞》说：上卦为坎，象征云；下卦为乾，象征天。云聚天上，待降雨，君子观此卦，宜宴饮安乐，待时而动。《断易天机》解：需卦坎上乾下，象征踌躇期待，刚强面对险阻，宜等待，涉大川利。北宋易学家邵雍解：遇阻不进，大器晚成，需耐心等待。台湾国学大儒傅佩荣解：时运需耐心等待，财运资本未集，家宅平安，身体调饮食以健康。传统解卦：异卦（下乾上坎），刚逢险，宜稳健，观时待变，必成功。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>山水蒙卦</td>\n",
       "      <td>蒙卦原文：蒙。亨。匪我求童蒙，童蒙求我。初筮告，再三渎，渎则不告。利贞。象曰：山下出泉，蒙。君子以果行育德。白话文解释：蒙卦通泰。不是我求幼稚之人，而是幼稚之人求我。初次占卜被告知，轻慢占卜则不再告知。占卜吉利。《象辞》说：卦象为山下有泉，取法于山泉果敢坚毅，培养品德。《断易天机》解：蒙卦艮上坎下，象征蒙昧，主疑惑不前，多忧愁，凶兆。北宋易学家邵雍解：智慧未开，犹豫不决，需顺师友教导启智。台湾国学大儒傅佩荣解：时运蓄德出世，财运矿业果决吉，家宅君子居吉，婚姻之始，身体驱邪保安。传统解卦：异卦（下坎上艮），山下有险仍前进，为蒙昧，把握时机行动恰时，启蒙通达之象。大象：蒙为昏无所见，宜启蒙。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>水雷屯卦</td>\n",
       "      <td>屯卦原文：屯。元，亨，利，贞。勿用，有攸往，利建侯。象曰：云，雷，屯；君子以经纶。白话文解释：屯卦大吉大利，吉利的占卜。不利于出门。有利于建国封侯。《象辞》说：屯的上卦为坎，坎为云，下卦为震，震为雷。云行于上，雷动于下，是屯卦的卦象。君子观此卦象，取法于云雷，用云的恩泽和雷的威严治理国事。《断易天机》解：屯卦坎上震下，为坎宫二世卦。屯卦显示困难，动而逢险，需刚毅果敢方为吉。北宋易学家邵雍解：万物始生，开始困难；先劳后逸，苦尽甘来。得此卦者，身处困境，宜守不宜进，需辛劳克难，初难后解。台湾国学大儒傅佩荣解：时运宜守，财运创业艰难，家宅初婚不和，身体需保元气。传统解卦：异卦（下震上坎），震为雷动，坎为雨险。雷雨交加，环境险恶。“屯”指万物始生，艰难险阻中顺时应运，终将欣荣。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  The dataset doesn't have 'validation' split， not evaluating.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965a7cb70c9e48a08a0718abf249dd43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n",
      "You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,899,392 || all params: 6,247,483,392 || trainable%: 0.06241540401681151\n",
      "dataset_name=data/zhouyi_dataset_handmade.csv\n",
      "training_args num_train_epochs: 3, logging_steps: 1, eval_steps: 1, save_steps: 10, per_device_train_batch_size: 8, , gradient_accumulation_steps: 1\n",
      "start train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/byenv/lib/python3.11/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:21, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.173000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.173000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.784700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end train.\n",
      "✅ fine tuned model saved to path: models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_handmade\n"
     ]
    }
   ],
   "source": [
    "# this cell is to train the model with custom dataset from data/zhouyi_dataset_xxx\n",
    "from datasets import load_dataset, ClassLabel, Sequence\n",
    "from transformers import AutoTokenizer, TrainingArguments, Trainer\n",
    "import torch\n",
    "from peft import TaskType, LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from peft.utils import TRANSFORMERS_MODELS_TO_LORA_TARGET_MODULES_MAPPING\n",
    "from transformers import AutoModel, BitsAndBytesConfig\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "# print ptorch info\n",
    "print(torch.__config__.show(), torch.cuda.get_device_properties(0))\n",
    "\n",
    "# ======================\n",
    "# 1. parameneters setup\n",
    "# ======================\n",
    "\n",
    "model_name_or_path = 'THUDM/chatglm3-6b'\n",
    "#train_data_path = 'data/zhouyi_dataset_20240118_163659.csv'\n",
    "#eval_data_path = None\n",
    "seed = 8\n",
    "max_input_length = 512\n",
    "max_output_length = 1536\n",
    "lora_rank = 16\n",
    "lora_alpha = 32\n",
    "lora_dropout = 0.05\n",
    "#resume_from_checkpoint = None\n",
    "prompt_text = ''\n",
    "compute_dtype = 'bf16'  # fp32 / fp16 / bf16\n",
    "\n",
    "# support multiple dataset_names to be tested\n",
    "dataset_names = [\n",
    "    \"data/zhouyi_dataset_20240118_152413.csv\",\n",
    "    \"data/zhouyi_dataset_20240118_163659.csv\",\n",
    "    \"data/zhouyi_dataset_handmade.csv\",\n",
    "    #\"shibing624/AdvertiseGen\",\n",
    "    #can add more dataset for test\n",
    "]\n",
    "\n",
    "# use small data for faster test...\n",
    "num_train_samples = 1000\n",
    "# use 0.1 of train data\n",
    "num_eval_samples = num_train_samples // 10\n",
    "\n",
    "# training paramenters setup\n",
    "per_device_train_batch_size = 8\n",
    "per_device_eval_batch_size = 8\n",
    "gradient_accumulation_steps = 1\n",
    "learning_rate = 1e-3\n",
    "num_train_epochs = 3\n",
    "#eval_steps = num_train_samples // (5 * per_device_train_batch_size * gradient_accumulation_steps)\n",
    "#save_steps = num_train_samples // (3 * per_device_train_batch_size * gradient_accumulation_steps)\n",
    "#logging_steps = num_train_samples // (15 * per_device_train_batch_size * gradient_accumulation_steps)\n",
    "logging_steps = 1\n",
    "eval_steps = 1\n",
    "save_steps = 10\n",
    "\n",
    "# dtype mapping\n",
    "_compute_dtype_map = {\n",
    "    'fp32': torch.float32,\n",
    "    'fp16': torch.float16,\n",
    "    'bf16': torch.bfloat16\n",
    "}\n",
    "\n",
    "# the tokenize function\n",
    "def tokenize_func(example, tokenizer, ignore_label_id=-100):\n",
    "    question = prompt_text + example['content']\n",
    "    if example.get('input', None) and example['input'].strip():\n",
    "        question += f'\\n{example[\"input\"]}'\n",
    "    answer = example['summary']\n",
    "    q_ids = tokenizer.encode(text=question, add_special_tokens=False)\n",
    "    a_ids = tokenizer.encode(text=answer, add_special_tokens=False)\n",
    "    if len(q_ids) > max_input_length - 2:\n",
    "        q_ids = q_ids[:max_input_length - 2]\n",
    "    if len(a_ids) > max_output_length - 1:\n",
    "        a_ids = a_ids[:max_output_length - 1]\n",
    "    input_ids = tokenizer.build_inputs_with_special_tokens(q_ids, a_ids)\n",
    "    question_length = len(q_ids) + 2\n",
    "    labels = [ignore_label_id] * question_length + input_ids[question_length:]\n",
    "    return {'input_ids': input_ids, 'labels': labels}\n",
    "\n",
    "# the DataCollator class\n",
    "class DataCollatorForChatGLM:\n",
    "    def __init__(self, pad_token_id: int, max_length: int = 2048, ignore_label_id: int = -100):\n",
    "        self.pad_token_id = pad_token_id\n",
    "        self.ignore_label_id = ignore_label_id\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __call__(self, batch: List[Dict[str, List]]) -> Dict[str, torch.Tensor]:\n",
    "        len_list = [len(d['input_ids']) for d in batch]\n",
    "        batch_max_len = max(len_list)\n",
    "\n",
    "        input_ids, labels = [], []\n",
    "        for len_of_d, d in sorted(zip(len_list, batch), key=lambda x: -x[0]):\n",
    "            pad_len = batch_max_len - len_of_d\n",
    "            ids = d['input_ids'] + [self.pad_token_id] * pad_len\n",
    "            label = d['labels'] + [self.ignore_label_id] * pad_len\n",
    "            if batch_max_len > self.max_length:\n",
    "                ids = ids[:self.max_length]\n",
    "                label = label[:self.max_length]\n",
    "            input_ids.append(torch.LongTensor(ids))\n",
    "            labels.append(torch.LongTensor(label))\n",
    "        return {\n",
    "            'input_ids': torch.stack(input_ids),\n",
    "            'labels': torch.stack(labels)\n",
    "        }\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
    "    display(HTML(df.to_html()))\n",
    "\n",
    "# function to free up mem    \n",
    "def freeup_mem():\n",
    "    print(\"\\n🔧 Releasing GPU ...\")\n",
    "    import torch, gc\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    #%reset -f\n",
    "    \n",
    "# tain/eval for the datasets\n",
    "for dataset_name in dataset_names:\n",
    "    print(f\"\\n\" + \"=\"*80)\n",
    "    print(f\"🔍 Train/Eval with dataset: {dataset_name}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # call to freeup mem    \n",
    "    freeup_mem()\n",
    "\n",
    "    # ======================\n",
    "    # 1. load dataset\n",
    "    # ======================\n",
    "    print(f\"loading dataset_name:{dataset_name}\")\n",
    "    dataset = load_dataset(\"csv\", data_files=dataset_name)\n",
    "    # print out dataset\n",
    "    print(dataset)\n",
    "\n",
    "    # show random elements\n",
    "    show_random_elements(dataset[\"train\"], num_examples=5)\n",
    "\n",
    "    eval_dataset_loaded = None\n",
    "    if 'validation' in dataset:\n",
    "        eval_dataset_loaded = dataset['validation']\n",
    "    else:\n",
    "        print(\"⚠️  The dataset doesn't have 'validation' split， not evaluating.\")\n",
    "\n",
    "    # ======================\n",
    "    # 2. set the used train/eval samples\n",
    "    # ======================\n",
    "    if num_train_samples is not None and num_train_samples > 0 \\\n",
    "    and len(dataset['train']) >= num_train_samples:\n",
    "        print(f\"num_train_samples: {num_train_samples}\")\n",
    "        dataset['train'] = dataset['train'].select(range(num_train_samples))\n",
    "    if eval_dataset_loaded is not None and num_eval_samples is not None \\\n",
    "and num_eval_samples > 0 and len(eval_dataset_loaded) >= num_eval_samples:\n",
    "        print(f\"num_eval_samples: {num_eval_samples}\")\n",
    "        eval_dataset_loaded = eval_dataset_loaded.select(range(num_eval_samples))\n",
    "\n",
    "    # ======================\n",
    "    # 3. Tokenize\n",
    "    # ======================\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True, revision='b098244')\n",
    "\n",
    "    column_names = dataset['train'].column_names\n",
    "    tokenized_train = dataset['train'].map(\n",
    "        lambda x: tokenize_func(x, tokenizer), \n",
    "        batched=False, \n",
    "        remove_columns=column_names\n",
    "    )\n",
    "    tokenized_train = tokenized_train.shuffle(seed=seed)\n",
    "    tokenized_train = tokenized_train.flatten_indices()\n",
    "\n",
    "\n",
    "    tokenized_eval = None\n",
    "    if eval_dataset_loaded is not None:\n",
    "        column_names_eval = eval_dataset_loaded.column_names\n",
    "        tokenized_eval = eval_dataset_loaded.map(\n",
    "            lambda x: tokenize_func(x, tokenizer), \n",
    "            batched=False, \n",
    "            remove_columns=column_names_eval\n",
    "        )\n",
    "\n",
    "        tokenized_eval = tokenized_eval.shuffle(seed=seed)\n",
    "        tokenized_eval = tokenized_eval.flatten_indices()\n",
    "    \n",
    "    # ======================\n",
    "    # 4. init the model, LoRA、QLoRA\n",
    "    # ======================\n",
    "    model = AutoModel.from_pretrained(\n",
    "        model_name_or_path,\n",
    "        quantization_config=BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type='nf4',\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_compute_dtype=_compute_dtype_map[compute_dtype]\n",
    "        ),\n",
    "        device_map='auto',\n",
    "        trust_remote_code=True,\n",
    "        revision='b098244'\n",
    "    )\n",
    "\n",
    "    model.supports_gradient_checkpointing = True  \n",
    "    model.gradient_checkpointing_enable()\n",
    "    model.enable_input_require_grads()\n",
    "\n",
    "    model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "\n",
    "    kbit_model = prepare_model_for_kbit_training(model)\n",
    "    target_modules = TRANSFORMERS_MODELS_TO_LORA_TARGET_MODULES_MAPPING['chatglm']\n",
    "    lora_config = LoraConfig(\n",
    "        target_modules=target_modules,\n",
    "        r=lora_rank,\n",
    "        lora_alpha=lora_alpha,\n",
    "        lora_dropout=lora_dropout,\n",
    "        bias='none',\n",
    "        inference_mode=False,\n",
    "        task_type=TaskType.CAUSAL_LM\n",
    "    )\n",
    "    qlora_model = get_peft_model(kbit_model, lora_config)\n",
    "    qlora_model.print_trainable_parameters()\n",
    "\n",
    "    # ======================\n",
    "    # 5. TrainingArguments & Trainer\n",
    "    # ======================\n",
    "\n",
    "    # Split the string by '/' and take the last part (the filename)\n",
    "    # \"data/zhouyi_dataset_20240118_163659.csv\"\n",
    "    print(f\"dataset_name={dataset_name}\")\n",
    "    filename = dataset_name.split('/')[-1]  # 'zhouyi_dataset_20240118_163659.csv'\n",
    "\n",
    "    # Split by '_' and take the parts after 'dataset'\n",
    "    # parts = filename.split('_')\n",
    "    # Assuming structure: ... dataset YYYYMMDD HHMMSS .csv\n",
    "    # date_part = parts[-2]  # '20240118'\n",
    "    # time_part = parts[-1].split('.')[0]  # '163659'\n",
    "    # timestamp = f\"{date_part}_{time_part}\"\n",
    "    # zhouyi_dataset_20240118_163659\n",
    "    part1 = filename.split('.')[-2]\n",
    "    saved_dir = f\"models/{model_name_or_path}-epoch{num_train_epochs}-{part1}\"\n",
    "    print(f\"training_args num_train_epochs: {num_train_epochs}, \\\n",
    "logging_steps: {logging_steps}, eval_steps: {eval_steps}, save_steps: {save_steps}\\\n",
    ", per_device_train_batch_size: {per_device_train_batch_size}, , gradient_accumulation_steps: {gradient_accumulation_steps}\")\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=saved_dir,\n",
    "        per_device_train_batch_size=per_device_train_batch_size,\n",
    "        per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        learning_rate=learning_rate,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        warmup_ratio=0.1,\n",
    "        evaluation_strategy=\"steps\" if eval_dataset_loaded is not None else \"no\",\n",
    "        eval_steps=eval_steps,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=save_steps,\n",
    "        logging_steps=logging_steps,\n",
    "        optim=\"adamw_torch\",\n",
    "        fp16=True,\n",
    "    )\n",
    "\n",
    "    data_collator = DataCollatorForChatGLM(pad_token_id=tokenizer.pad_token_id)\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=qlora_model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_eval,\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "\n",
    "    # ======================\n",
    "    # 6. train & auto print the train/validation loss\n",
    "    # ======================\n",
    "    print(f\"start train...\")\n",
    "    trainer.train()\n",
    "    print(f\"end train.\")\n",
    "\n",
    "    # ======================\n",
    "    # 7. saved the tuned model\n",
    "    # ======================\n",
    "    trainer.model.save_pretrained(saved_dir)\n",
    "    print(f\"✅ fine tuned model saved to path: {saved_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6409c3d9-8f9a-45cd-9390-bd1aefb41a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔧 Releasing GPU ...\n",
      "🔍 Loading the base model: THUDM/chatglm3-6b (not fine tuned)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ede20c088f89468d99eb22ba12efd7d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "🔍 Loading PEFT model from: models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_152413\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "📊 Comparing result for query: 解释下乾卦是什么？\n",
      "================================================================================\n",
      "📝Base model response:\n",
      "乾卦是周易中的一卦，代表天，象征着刚健强劲的特性。它由两个阳爻夹一个阴爻构成，象征着阳刚之气的聚集。乾卦象征着刚健、强盛、独立自主的特性，代表着锐利、直率、果敢的性格。在《易经》中，乾卦预示着健旺、强盛、独立自主的情况，并带来吉兆。\n",
      "\n",
      "乾卦的卦辞描述了阳爻在前的特性，强调刚健、锐利和果敢，并预示着可能带来成功。同时，需要注意准备好了燃料（前进）才能前进，而阴爻提示需要谨慎行事，以免带来灾难。在决策时，应当积极刚健，而谨慎柔弱，以事业成功为吉，否事业失败为凶。\n",
      "\n",
      "在古代，人们认为乾卦代表天，象征刚健、强盛、独立自主的特性。在决策时，应该积极刚健，而谨慎柔弱，以事业成功为吉，否事业失败为凶。同时，经商求谋须谨慎选择方向，同时注意合作，以利益最大化为目标。经商求谋方面，须得遇贤人，根据时势变化，抓住机遇。在事业中，需要积极刚健，同时谨慎柔弱，以事业成功为吉，否事业失败为凶。\n",
      "\n",
      "乾卦的核心哲学是：刚健强劲，阳刚之气的聚集，代表着锐利、直率、果敢的性格。在决策时，应该积极刚健，而谨慎柔弱，以事业成功为吉，否事业失败为凶。     \n",
      "👉Fine tuned model (models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_152413) response: \n",
      "[gMASK]sop 解释下乾卦是什么？ 乾卦是周易中的一卦，代表天，象征刚健强劲的特性。它由两个乾卦叠加而成，代表着刚健强劲的特性。在卜问中，乾卦预示着吉祥如意，同时也提醒面临着修养和成长的过程。在决策中，意味着刚健强劲的特性会带来吉祥如意，但需要警惕可能会带来困难。\n",
      "\n",
      "乾卦的特性包括：\n",
      "\n",
      "1. 吉祥：乾卦预示着事情顺利，带来吉祥如意。\n",
      "2. 刚健：乾卦代表刚健强劲的特性，表示事情的发展需要刚健强劲的毅力。\n",
      "3. 突出：乾卦强调刚健强劲的特性，具有突出和领导能力。\n",
      "4. 养：乾卦意味着养成了刚健强劲的特性，能够养成了坚定的品德。\n",
      "\n",
      " summary:\n",
      "\n",
      "乾卦 is a message from the I Ching, representing the天, and it symbolizes the strong and powerful nature. It is composed of two dragons, each representing strength and power, and it represents the need for determination and perseverance in the face of adversity. The message is that of success and prosperity, and it highlights the importance of being strong and resolute in the face of challenges.\n",
      "\n",
      "================================================================================\n",
      "📊 Comparing result for query: 周易中的讼卦是什么\n",
      "================================================================================\n",
      "📝Base model response:\n",
      "讼卦是周易卦象中的一枚卦，由上卦坎（水）和下卦乾（天）组成，代表天上有水，象征刚健公正。讼卦的卦义是：天上有水，人有志。 both parties are willing to fight for what they believe is right.\n",
      "\n",
      "讼卦的时运是：\n",
      "\n",
      "初爻：阳刚之卦，刚中有健，宜初入社会，刚强craftsman\n",
      "\n",
      "二爻：阳刚之卦，刚中有健，宜求名逐利，利见ancestors\n",
      "\n",
      "三爻：阳刚之卦，刚中有健，宜婚嫁之吉，宜利见夫\n",
      "\n",
      "四爻：阳刚之卦，刚中有健，宜父喜子，父利子亦利\n",
      "\n",
      "讼卦的运势指数为：利，利见财瑞\n",
      "\n",
      "讼卦的运势提示：\n",
      "\n",
      "初入社會，刚強craftsman，宜求名逐利，宜婚嫁之吉，宜利见夫，刚強中有利，宜父喜子，父利子亦利。\n",
      "\n",
      "讼卦的宜解宜决：\n",
      "\n",
      "讼卦解卦为：决吉，初凶后利。decision will be made after the initial adversity.\n",
      "\n",
      "讼卦的占卜方法：\n",
      "\n",
      "讼卦之象为天上有水，人有志。整体而言，刚健公正，说明有坚毅不屈的品质。然而，初入社会，刚强craftsman，需要求婚见瑞，利见财瑞。\n",
      "\n",
      "讼卦的数字卦象为：讼卦（6卦），象征刚健公正， both parties are willing to fight for what they believe is right.\n",
      "\n",
      "讼卦的哲学原理：\n",
      "\n",
      "讼卦表示刚健公正，但是需要 pause 一下，因为初入社会，刚强craftsman。 overall而言，刚强中有利，宜父喜子，父利子亦利。因此，讼卦的总体运气的宜解宜决为：决吉，初凶后利。     \n",
      "👉Fine tuned model (models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_152413) response: \n",
      "[gMASK]sop 周易中的讼卦是什么卦象\n",
      "\n",
      " 在周易中，讼卦是一个极具深意的卦象。上卦为乾（天），下卦为坎（水），两者相背而行，代表天与水违行的状况，象征着事理乖舛和争讼之象。讼卦中有利可图，但必须警惕戒惧，事情中间吉利，但最终会有凶险。在卜卦时，利于会见贵族王公，但不利于涉水渡河。\n",
      "\n",
      "讼卦的核心哲学是：开始可能顺利，有所收获，但随后会遇到困难和挫折。因此，务必慎之又慎，不得固执已见，避免介入诉讼纠纷的争执之中。退让而不固执，求得化解，安于正理，可免除意外之灾。陷入争讼，即使获胜，最后还得失去，得不偿失。\n",
      "\n",
      "讼卦的经商指引是：和气生财，吃亏是福，切勿追求不义之财。在商业谈判中要坚持公正、公平、互利的原则，尽量避免发生冲突。\n",
      "\n",
      "对于决策，讼卦提醒我们，争强好胜，不安于现状，为改变命运和超越他人而奋斗。但缺乏持之以恒的毅力，容易得罪他人，带来诉讼之灾。因此，接受教训，引以为戒，可功成名就。\n",
      "\n",
      "讼卦所蕴含的智慧是：在面对争端和异见时，要善于退让和求和，坚守正道，谨慎处事，以避免不必要的冲突和损失。\n",
      "\n",
      "================================================================================\n",
      "📊 Comparing result for query: 师卦是什么？\n",
      "================================================================================\n",
      "📝Base model response:\n",
      "师卦是一个由坎卦（水）上承坤卦（地）组成的卦象，代表军队和指挥军情的卦象。根据《象辞》，这一卦象被解释为“地中有水”，象征着像大地一样包容和养育众人。根据《断易天机》，只有德高望重的长者来统率军队，才能获得吉祥无咎。\n",
      "\n",
      "据北宋易学家邵雍解，得师卦者将面临困难重重，忧心劳众，宜包容别人，艰苦努力，摒除一切困难。台湾国学大儒傅佩荣解则提到，对于时运、财运、家宅和身体等方面会有相应影响。\n",
      "\n",
      "传统解卦认为，师卦具有养兵聚众、出师攻伐之象，彼此有伤，难得安宁的大象。在运势方面，预示着困难重重，需要以正规行事，谨小慎微，严于律已。在事业、经商、求名、婚恋和决策等方面，都需要保持冷静、谨慎，注意避免敌人和困难带来的不利影响，必能成功。     \n",
      "👉Fine tuned model (models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_152413) response: \n",
      "[gMASK]sop 师卦是什么？ 师卦是一个由坎卦（水）上承坤卦（地）组成的卦象，代表军队和指挥军情的卦象。根据《象辞》，这一卦象被解释为“地中有水”，象征着像大地一样包容和养育众人。根据《断易天机》，只有德高望重的长者来统率军队，才能获得吉祥无咎。\n",
      "\n",
      "\n",
      "据北宋易学家邵雍解，得师卦者将面临困难重重，忧心劳众，宜包容别人，艰苦努力，摒除一切困难。台湾国学大儒傅佩荣解则提到，对于时运、财运、家宅和身体等方面会有相应影响。\n",
      "\n",
      "\n",
      "传统解卦认为，师卦具有养兵聚众、出师攻伐之象，彼此有伤，难得安宁的大象。在运势方面，预示着困难重重，需要以正规行事，谨小慎微，严于律已。在事业、经商、求名、婚恋和决策等方面，都需要保持冷静、谨慎，注意避免敌人和困难带来的不利影响，必能成功。\n",
      "\n",
      "================================================================================\n",
      "📊 Comparing result for query: 地水师卦是什么？\n",
      "================================================================================\n",
      "📝Base model response:\n",
      "地水师卦是周易中的一卦，对应着《易经》中的卦辞，卦象是坎卦，代表水，象征润泽万物，具有滋润滋养的特点。在卜问中，表示面临困境，需要坚韧不拔的精神来应对。\n",
      "\n",
      "在解卦中，认为地水师卦预示着SCOOP（Spiritual Compass, Opportunity, Unity, Promise）卦象，即精神 compass指示方向，机会带来变化，团结带来力量， promises 带来成功。\n",
      "\n",
      "总结起来，地水师卦意味着困难中需要坚持，依靠智慧和勇气来解决问题。     \n",
      "👉Fine tuned model (models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_152413) response: \n",
      "[gMASK]sop 地水师卦是什么？ 地水师卦是一个由坎卦（水）上承坤卦（地）组成的卦象，代表的是地水师这一卦象。根据《象辞》，这一卦象被解释为“地中有水”，象征着像大地一样包容着水，以及像大地一样包容着众人心灵的卦象。根据《断易天机》，地水师卦的初爻为阳，中爻为阳，末爻为阳，表示这是一个充满活力和决心的卦象。\n",
      "\n",
      "根据《象辞》，地水师卦被解释为“地中有水”，象征着像大地一样包容着水，以及像大地一样包容着众人心灵的卦象。根据《断易天机》，地水师卦的初爻为阳，中爻为阳，末爻为阳，表示这是一个充满活力和决心的卦象。\n",
      "\n",
      "根据《象辞》，地水师卦被解释为“地中有水”，象征着像大地一样包容着水，以及像大地一样包容着众人心灵的卦象。根据《断易天机》，地水师卦的初爻为阳，中爻为阳，末爻为阳，表示这是一个充满活力和决心的卦象。\n",
      "\n",
      "地水师卦的核心哲学是：像大地一样包容着水，以及像大地一样包容着众人心灵的卦象。根据《象辞》和《断易天机》的解释，地水师卦的初爻、中爻和末爻都为阳，表示这是一个充满活力和决心的卦象。\n",
      "\n",
      "根据《象辞》，地水师卦预示着困难中有利，顺利中有险，表示先得胜后得，得胜容易失，困难中有利，得志容易迷失。根据《断易天机》，地水师卦的初爻为阳，中爻为阳，末爻为阳，表示这是一个充满活力和决心的卦象。\n",
      "\n",
      "地水师卦的核心哲学是：像大地一样包容着水，以及像大地一样包容着众人心灵的卦象。根据《象辞》和《断易天机》的解释，地水师卦的初爻、中爻和末爻都为阳，表示这是一个充满活力和决心的卦象。\n",
      "\n",
      "根据《象辞》，地水师卦预示着困难中有利，顺利中有险，表示先得胜后得，得胜容易失，\n",
      "\n",
      "================================================================================\n",
      "📊 Comparing result for query: 天水讼卦\n",
      "================================================================================\n",
      "📝Base model response:\n",
      "的天水讼卦是指卦象为乾上坎下的一卦，代表的天水卦象征着天地之间流行着大的水流。在卜卦中，这个卦象通常被解释为吉利，具有享有的运格。但是需要注意的是，天猫卦象具有双重变格，需要综合考虑卦象和变格的意义，才能得出准确的结论。\n",
      "\n",
      "在传统文化中，天猫卦象被认为具有传达消息的功能，可以预测吉利或凶险。但是，在现代社会，预测并不科学，只能靠自己的努力和判断来决定未来的走向。     \n",
      "👉Fine tuned model (models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_152413) response: \n",
      "[gMASK]sop 天水讼卦\n",
      "\n",
      "天猫国际诉称，在天猫平台上，因商家未按约定履行交易义务，造成消费者损失，请求判令商家赔偿消费者损失及承担相应责任。\n",
      "\n",
      "天猫国际认为，根据《中华人民共和国合同法》第107条规定，商家应按照约定履行交易义务。然而，商家未能按约定履行交易义务，造成消费者损失。因此，天猫国际请求判令商家赔偿消费者损失及承担相应责任。\n",
      "\n",
      "天猫国际请求法院采取的审判程序是：\n",
      "\n",
      "1. 法院应当组成合议庭，由3名以上审判人员共同审理本案；\n",
      "2. 法院应当对天猫国际提供的证据进行审查，看是否能够证明其诉讼请求；\n",
      "3. 法院应当一案一断，即针对每一个案件，都应当作出独立的判决；\n",
      "4. 法院应当适用法律，对案件进行审理。\n",
      "\n",
      "天猫国际将积极配合法院审理，希望法院能够公正审理本案。\n",
      "\n",
      "================================================================================\n",
      "🔍 Loading PEFT model from: models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_163659\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "📊 Comparing result for query: 解释下乾卦是什么？\n",
      "================================================================================\n",
      "📝Base model response:\n",
      "{'name': '乾卦是周易中的一卦，由六个阳爻组成，象征着天。它代表了一种刚健、健行、刚健不屈的意境。在周易中，阳爻代表阳刚，阴爻代表阴柔。乾卦的核心哲学是：君子观此卦象，从而结交到君子，求得走廊（卦象）的相应。', 'content': '\\n乾卦的哲学含义可以引申为：天行健，君子观于天行，从而大吉。君子应当效法天的行健，即自强不息，健行不止， Flexibility and adaptability, but with Determination and pride. 乾卦既象征君子自强不息的毅力，也暗示着在困难中坚忍不拔的意志。在事业、经商、求名、婚恋等方面的决策中，都需要借鉴乾卦的刚健与不屈。'}     \n",
      "👉Fine tuned model (models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_163659) response: \n",
      "[gMASK]sop 解释下乾卦是什么？ 在周易中，乾卦是六十四卦之首，由六个阳爻组成，象征着天。它所代表的是刚健、健行、刚健不屈的意境。乾卦的核心哲学是：天道刚健，运行不已，君子观此卦象，从而以天为法，自强不息。\n",
      "\n",
      "乾卦象征天，为大通而至正。得此卦者，名利双收，应把握机会，争取成果。然而，切勿过于骄傲自满，而应保持谦逊、冷静和警惕。在事业、经商、求名等方面，乾卦皆暗示着大吉大利，但也警示着必须坚持正道、修养德行，方能永远亨通。\n",
      "\n",
      "在婚恋方面，乾卦提示着阳盛阴衰，但也强调刚柔相济，相互补足，形成美满的结果。在决策方面，则是强调刚健、正直、公允，自强不息的实质，需要修养德行、坚定信念，方能克服困难，消除灾难。\n",
      "\n",
      "================================================================================\n",
      "📊 Comparing result for query: 周易中的讼卦是什么\n",
      "================================================================================\n",
      "📝Base model response:\n",
      "在周易中，讼卦是一个充满警示的卦象。它由上卦乾（天）和下卦坎（水）组成，代表着天与水背道而驰，形成争讼的局面。虽然事情开始时有利可图，但必须警惕戒惧，因为中间虽然吉利，但最终会带来凶险。对于涉及大川，涉水渡河的行动不利。因此，君子观此卦象，应当慎之又慎，杜绝争讼之事，并在谋事之初谨慎行事。讼卦的核心哲学是要避免争讼，退而让人，求得化解，安于正理，方可避免意外之灾。在事业上，务必避免介入诉讼纠纷的争执之中，与其这样，不如退而让人。即使最终获胜，也难免得失不均。经商方面，要坚持公正、公平、互利的原则，避免冲突，这样会有好结果。而对于求名、婚恋和决策，也都需要慎重行事，避免盲目追求，退让让人，可助事业、婚姻和决策的发展。     \n",
      "👉Fine tuned model (models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_163659) response: \n",
      "[gMASK]sop 周易中的讼卦是什么概念 在周易中，讼卦是一个充满警示的卦象。它由上卦乾（天）和下卦坎（水）组成，代表着天与水背道而驰，形成争讼的局面。虽然事情开始时有利可图，但必须警惕戒惧，因为中间虽然吉利，但最终会带来凶险。对于涉及大川，涉水渡河的行动不利。因此，君子观此卦象，应当慎之又慎，杜绝争讼之事，并在谋事之初谨慎行事。讼卦的核心哲学是要避免争讼，退而让人，求得化解，安于正理，方可避免意外之灾。在事业上，务必避免介入诉讼纠纷的争执之中，与其这样，不如退而让人。即使最终获胜，也难免得失不均。经商方面，要坚持公正、公平、互利的原则，避免冲突，这样会有好结果。而对于求名、婚恋和决策，也都需要慎重行事，避免盲目追求，退让让人，可助事业、婚姻和决策的发展。\n",
      "\n",
      "================================================================================\n",
      "📊 Comparing result for query: 师卦是什么？\n",
      "================================================================================\n",
      "📝Base model response:\n",
      "师卦，是周易中的一卦，由两个卦相合而成，代表尔斯卦。在周易中，orsa（ulb）卦为初爻，代表开始；中间爻为九阳，代表充满阳光；上卦为九阴，代表幽暗。这一卦的主要特点是刚中有柔，刚中有刚，刚中有柔，刚中有刚，上卦为坤，下卦为震。\n",
      "\n",
      "师卦的核心哲学是：天时不如地利，地利不如人时，时势造人，君子修养自身，等待时机，掌握兵法，创造胜利的条件。在事业上，这一卦提示着必须掌握时机，积极行动，充分准备，善于变通，勇于担当。在经商中，表现为掌握时机，勇敢行动，善于变通，充满自信，冷静分析，敢作敢为。\n",
      "\n",
      "师卦的吉凶指标为：初爻为吉，中间爻为凶，上卦为吉，下卦为凶。吉凶取决于爻辞的组合和卦象的搭配。在经商中，若凶爻得位，则必须谨慎行事，若吉爻得位，则可放心行动，若逢有利可为的时机则应积极行动。在事业和经商中，必须注意掌握时机，充分准备，善于变通，勇敢担当。     \n",
      "👉Fine tuned model (models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_163659) response: \n",
      "[gMASK]sop 师卦是什么？ 在周易中，师卦是一个由坎卦（水）和坤卦（地）相叠而成的异卦。这一卦象代表着军队的力量和军情的总指挥，预示着吉祥无灾。象辞中描述了地中有水的情景，寓意着君子应当像大地一样容纳和畜养大众。师卦的解释强调选择德高望重的长者来统率军队，才能获得吉祥无咎。另外，师卦也象征着困难重重，需要包容别人、艰苦努力，及时行事，严于律已。在事业、经商、求名、婚恋等方面的决策中，都需要警惕潜在敌人，小心谨慎，合作与决断兼顾，方能成功。\n",
      "\n",
      "================================================================================\n",
      "📊 Comparing result for query: 地水师卦是什么？\n",
      "================================================================================\n",
      "📝Base model response:\n",
      "在周易中，地水师卦是一个由坎卦（水）和坤卦（地）相叠而成的异卦。这一卦象代表着军队向前进取，有着稳定和统一国家的好运。象辞中描述了地水师卦的特点，即：用军取城，得地胜敌。\n",
      "\n",
      "地水师卦的出现，预示着吉祥小心。困難在于金木之夏，而在火土之秋。在事业上，大吉大利，但必须谨慎行事。在经商中，必须谨慎行事，稳重行事，方能获得利的预兆。在感情方面，爱情美满，但需疑虑和关心对方。\n",
      "\n",
      "总体来说，地水师卦是一个典型的吉祥之卦，但 also 有一定的警告和提示。     \n",
      "👉Fine tuned model (models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_163659) response: \n",
      "[gMASK]sop 地水师卦是什么？ 在周易中，地水师卦是一个由坎卦（水）和坤卦（地）相叠而成的异卦。这一卦象代表着军队向前进取，有着强大力量和智谋的胜利。象辞中描述了地水师卦的特点，即\"初六，坤池之制，初成，象辞。\" 这里，坤卦代表地，象征大水（坤）与坤宫（地）相叠而成。坤宫是坤卦的卦宫，位于西南方。在这里，坤卦代表止 Milizin（地）和止战（坤）的意图，形成一种和平解决战争局面的愿望。\n",
      "\n",
      "地水师卦的核心哲学是：止 Milizin（地）和止战（坤），安危定矣。止战：指通过和平手段，如外交、谈判等，来制止战争。地水师卦鼓励人们止战，避免战争带来的损失，主张通过和平方式解决纷争。\n",
      "\n",
      "在事业、经商、求名、婚恋等方面的决策中，地水师卦都提示着止战和稳定发展。经商方面，强调稳定经营，避免战争对商业活动的影响，同时强调止战和稳定，商业活动得以顺利进行。在婚恋方面，象征着稳定感情，避免战争对感情带来的影响，同时强调止战和稳定，感情得以稳定发展。\n",
      "\n",
      "地水师卦的核心哲学是止战和稳定，适合经商、求名、婚恋等方面的决策\n",
      "\n",
      "================================================================================\n",
      "📊 Comparing result for query: 天水讼卦\n",
      "================================================================================\n",
      "📝Base model response:\n",
      "天水讼卦是一个卦象，由坎卦（水）和坤卦（地）相叠而成。这一卦象代表着天地相错，预示着君子应当适应天地相错之象，适应变化，君子们要适应天地相错之象，适应变化，化解纷争，从而化解矛盾。\n",
      "\n",
      "天水讼卦的核心哲学是：天地相错，gin4 gan4，相互错综复杂，难以简单解决。因此，君子们需要在矛盾冲突中寻求化解，化解纷争，缓和社会矛盾，化解纷争，从而达到平衡和谐之境。\n",
      "\n",
      "在事业、经商、求名、婚恋等方面的决策中，都需要注意天地相错之象，寻求化解矛盾，避免冲突，寻求妥协与转化。同时，也预示着需要适应变化，寻找平衡点，注意缓和社会矛盾，化解纷争，从而达到和谐之境。     \n",
      "👉Fine tuned model (models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_20240118_163659) response: \n",
      "[gMASK]sop 天水讼卦卦象详解 这是一篇关于天水讼卦的文章，主要介绍了这个卦象的特点以及它所代表的运势。\n",
      "\n",
      "在天水讼卦中，上卦是乾，代表天，下卦是坎，代表地。乾卦象征着刚强，坎卦象征着柔顺。在这个卦中，中间的爻是震，象征震动。\n",
      "\n",
      "天水讼卦的核心哲学是：震动以求和。这个卦象预示着君子观者需要以震为榜样，积极寻求解决纷争的方法。君子在现实生活中，应该以正义、刚毅、刚正、诚实的品质来处理事务，以求得解决。\n",
      "\n",
      "然而，天水讼卦并非完全不利于君子，它也预示着君子能够取得成功。只要君子能够坚持正义，刚毅，诚实， flexible and adaptable，就能够成功解决纷争。\n",
      "\n",
      "总的来说，天水讼卦是一个吉祥之卦，但需要君子观者积极寻求解决纷争的方法，以取得成功。\n",
      "\n",
      "================================================================================\n",
      "🔍 Loading PEFT model from: models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_handmade\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "📊 Comparing result for query: 解释下乾卦是什么？\n",
      "================================================================================\n",
      "📝Base model response:\n",
      "乾卦是八卦之一，也是八宫图之一，其卦象由两个阴爻夹一个阳爻构成，象征着天、云、雷等自然现象，以及君王、领导、父亲等权力和威严。乾卦的含义包括创造、领导、坚定、果敢、进展、发展等。在八宫图中，乾卦位于西北方位，与事业、努力、积极、变化、进展等有关。在命理学中，乾卦也代表着君主、领导、父亲等权力人物，以及法律、规则、制度等。     \n",
      "👉Fine tuned model (models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_handmade) response: \n",
      "[gMASK]sop 解释下乾卦是什么？\n",
      "乾卦是八卦之一，也是八宫图说、易经、易学中非常重要的一个卦。乾卦是由两个阴爻夹一个阳爻构成，象征着天、云、雷等自然现象，以及君王、领导、权力等象征。乾卦的含义非常丰富，包括力量、刚强、积极、行动、刚毅、果敢、坚定等。在易经中，乾卦的卦辞是“元、亨、利、贞”，表示这个卦具有正始、正通、正利、正贞的特质。乾卦的五行属性是“木”，在八卦中属于阳卦，代表春季、树木、成长、发展等。\n",
      "\n",
      "乾卦的六爻分别有不同的含义，初爻表示天、初生、初壮；二爻表示天、天成、天长；三爻表示天、天行、天尊；四爻表示天、天正、天定；五爻表示天、天旋、天终；六爻表示天、天成、天功。每一爻都有阳爻和阴爻两种状态，通过组合形成四种不同的卦象，即乾、坤、震、巽、坎、离、艮、兑。这四种卦象分别对应不同的五行属性、性格特点、人物、事物等，对人的生辰八字、命理、运势等都有重要的影响。\n",
      "\n",
      "乾卦在八宫图说中位于北方，与事业、努力、决断、领导、自信、坚定等有关。在易经中，乾卦主要对应于八卦中的“乾”卦，具有强烈的领导力和决断力，能够积极地推动事物的发展和进步。同时，乾卦也象征着天、云、雷等自然现象，提醒人们在面对挑战和困难时要坚定信念，保持积极向上的心态，勇往直前。\n",
      "\n",
      "================================================================================\n",
      "📊 Comparing result for query: 周易中的讼卦是什么\n",
      "================================================================================\n",
      "📝Base model response:\n",
      "《周易》中的讼卦（又称“损”卦）是八卦之一，它的卦象是由两个卦相组合而成：上卦是乾，表示天；下卦是坤，表示地。乾卦为阳，坤卦为阴。在六十四卦中，讼卦是第八卦。\n",
      "\n",
      "讼卦象征着诉讼、争端、纷争等诉讼事件。它表示在某种程度上，阳和阴、互相对立的两极之间存在冲突。这一卦启示人们要学会克制、谦卑和讲道理，以化解矛盾，达成和谐。\n",
      "\n",
      "周易中的卦辞和爻辞可以为人们提供一些解决问题的方法和思路。通过深入研究卦象及其变化，人们可以从中汲取智慧和启示，从而更好地应对现实生活中的问题和挑战。     \n",
      "👉Fine tuned model (models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_handmade) response: \n",
      "[gMASK]sop 周易中的讼卦是什么？\n",
      "周易中的讼卦是八卦之一，它的卦象是由两个离字叠加而成，离为火，火可以克金，因此讼卦象征着火金相克、争斗不断的景象。在周易中，讼卦表示诉讼、争端、矛盾等纷争现象，它提醒人们在处理问题和矛盾时要保持冷静、理智，避免用火攻来解决问题，否则可能会导致更加激烈的争斗。\n",
      "\n",
      "此外，讼卦还与《易经》中的“天听”理念有关。在《易经》中，天听是指天地自然规律的体现，它告诉人们应该顺应自然、遵循规律，而不是强行改变或对抗。因此，讼卦也提醒人们在处理问题和矛盾时要顺应自然、遵循规律，避免强行对抗，以达到和谐共处的目的。\n",
      "\n",
      "================================================================================\n",
      "📊 Comparing result for query: 师卦是什么？\n",
      "================================================================================\n",
      "📝Base model response:\n",
      "师卦是《易经》中的第五卦，由两个阴爻夹一个阳爻构成，象征着教师、教导、知识等。在《易经》中，阳爻代表阳，阴爻代表阴，阴爻在阳爻之上，表示柔弱之上阳，象征柔弱胜刚强，柔顺胜刚硬。因此，师卦象征着柔弱有力量，教育使人变柔，使人变智慧。\n",
      "\n",
      "师卦的意义不仅限于教育，还涉及到教导、知识、领导等方面。在教育方面，师卦强调教师的作用，教师要善于教导学生，引导学生向正确的方向发展。在领导方面，师卦强调领导者要善于引导、教导下属，发挥下属的潜力，使团队向目标迈进。\n",
      "\n",
      "总的来说，师卦告诉我们，教育是培养人才的重要手段，领导者在管理中要注重引导和教导，以促进团队成员的成长和发展。     \n",
      "👉Fine tuned model (models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_handmade) response: \n",
      "[gMASK]sop 师卦是什么？\n",
      "师卦是《易经》中的第五卦，由两个阴爻夹一个阳爻构成，象征着军队或力量。师卦的含义包括：军队、力量、领导、教导等。它提醒我们在面对困难和挑战时，要善于组织和调动力量，以达到共同的目标。同时，师卦也强调了领导的作用，指出领导者应该有远见和正确的决策，以引导和激励部队取得胜利。\n",
      "\n",
      "================================================================================\n",
      "📊 Comparing result for query: 地水师卦是什么？\n",
      "================================================================================\n",
      "📝Base model response:\n",
      "\"地水师卦\"是中国古代易经中的一个卦象,由两个卦相组合而成,分别是“地”卦和“水”卦。\n",
      "\n",
      "“地”卦象征着“顺从”和“适应”,“水”卦象征着“流动”和“变化”。将这两个卦象组合在一起,意味着顺应自然、适应环境、灵活变通、流动发展。\n",
      "\n",
      "在易经的解读中,地水师卦被认为是一种“和安全”的卦象,象征着人们在面对变化和不确定性时要保持冷静和沉着,以适应变化,保持稳定和安全。同时,地水师卦也提醒人们要注重与周围环境的协调和沟通,以实现共同的目标。     \n",
      "👉Fine tuned model (models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_handmade) response: \n",
      "[gMASK]sop 地水师卦是什么？\n",
      "地水师卦是易经中的一个卦象，由两个卦相组合而成：地卦和水分成两个卦，即地卦和风卦。地卦代表土地，象征柔顺、包容、承载；风卦代表风，象征变化、自由、进取。将两个卦相组合，形成地水师卦，象征土地和风的相互作用，寓意着天地自然的力量和人类社会的相互影响。\n",
      "\n",
      "地水师卦的意义主要体现在以下几个方面：\n",
      "\n",
      "1. 土地和水源的相互影响：地水师卦提醒人们，土地和水源是相互联系、相互影响的。土地滋润水源，水源滋润土地，二者相互促进，形成一个良好的生态循环。\n",
      "\n",
      "2. 柔顺与进取的结合：地卦象征柔顺，风卦象征进取。地水师卦提醒人们，在处理事物时要保持柔顺的态度，同时也要有进取的精神，才能达到最好的效果。\n",
      "\n",
      "3. 天地自然的力量：地水师卦强调天地自然的力量，提醒人们要顺应自然，发挥自然的力量，以达到最好的结果。\n",
      "\n",
      "4. 人类社会的相互影响：地水师卦还提醒人们，土地和水源的相互作用也反映了人类社会的相互影响。人类要尊重自然，保护环境，实现人与自然的和谐共处。\n",
      "\n",
      "================================================================================\n",
      "📊 Comparing result for query: 天水讼卦\n",
      "================================================================================\n",
      "📝Base model response:\n",
      "天水讼卦（卦象：乾，坤）是《易经》中的第六卦，属于兑宫，由两个卦相组合而成：乾为天，表示刚强、积极、进取；坤为地，表示顺从、温顺、承载。这个卦象征着天地之间的大小相因，互为依靠，形成一种和谐共生的局面。\n",
      "\n",
      "在《易经》中，天水讼卦意味着在处理诉讼、纷争等问题时，应该采取公正、公平的态度，同时兼顾双方的利益，努力达到和谐共处的目的。此外，这个卦还告诫我们，要懂得天地之间的相互关系，尊重自然规律，才能在事物发展过程中保持平衡和谐。     \n",
      "👉Fine tuned model (models/THUDM/chatglm3-6b-epoch3-zhouyi_dataset_handmade) response: \n",
      "[gMASK]sop 天水讼卦\n",
      "天水/讼卦\n",
      "\n",
      "《易经》卦辞：天无言，地无语， ambi（ ambi 是古汉语“言”字，有多种读音，本卦 ambi 读第三声，取其“天言”之意）。\n",
      "\n",
      "《易经》彖传：天行健，君子以自强不息；地行坤，君子以厚德载物。\n",
      "\n",
      "《易经》象传：雷，为天之志；泽，为地之志。\n",
      "\n",
      "《易经》互传：互传为损、益。\n",
      "\n",
      "《易经》传：天无言，地无语， ambi。\n",
      "\n",
      "《易传》：天言，地言，圣贤之至言。\n",
      "\n",
      "《易传》：有言，则隐；无言，则明。\n",
      "\n",
      "《易传》：时中则观，时中则用。\n",
      "\n",
      "《易传》：知止乎其所不能已者，则无过失。\n",
      "\n",
      "《易传》：天行健，君子以自强不息；地行坤，君子以厚德载物。\n",
      "\n",
      "《易传》：天无言，地无语， ambi。\n",
      "\n",
      "《易传》：天言，地言，圣贤之至言。\n",
      "\n",
      "《易传》：有言，则隐；无言，则明。\n",
      "\n",
      "《易传》：时中则观，时中则用。\n",
      "\n",
      "《易传》：知止乎其所不能已者，则无过失。\n",
      "\n",
      "《易传》：天行健，君子以自强不息；地行坤，君子以厚德载物。\n",
      "\n",
      "《易传》：天无言，地无语， ambi。\n",
      "\n",
      "《易传》：天言，地言，圣贤之至言。\n",
      "\n",
      "《易传》：有言，则隐；无言，则明。\n",
      "\n",
      "《易传》：时中则观，时中则用。\n",
      "\n",
      "《易传》：知止乎其所不能已者，则无过失。\n",
      "\n",
      "《易传》：天行健，君子以自强不息；地行坤，君子以厚德载物。\n",
      "\n",
      "《易传》：天无言，地无语， ambi。\n",
      "\n",
      "《易传》：天言，地言，圣贤之至言。\n",
      "\n",
      "《易传》：有言，\n"
     ]
    }
   ],
   "source": [
    "# this cell is to evaluate the modles\n",
    "# function to free up mem and remove all variables\n",
    "def freeup_mem_deep():\n",
    "    print(\"\\n🔧 Releasing GPU ...\")\n",
    "    import torch, gc\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    %reset -f\n",
    "# call to freeup mem    \n",
    "freeup_mem_deep()\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftModel, PeftConfig\n",
    "import time\n",
    "\n",
    "# ======================\n",
    "# 1. parameters setup\n",
    "# ======================\n",
    "\n",
    "# the base model\n",
    "model_name_or_path = 'THUDM/chatglm3-6b'\n",
    "\n",
    "# support multiple fine tuned models\n",
    "#\"data/zhouyi_dataset_20240118_152413.csv\",\n",
    "#\"data/zhouyi_dataset_20240118_163659.csv\",\n",
    "#\"data/zhouyi_dataset_handmade_20250811_163200.csv\",\n",
    "peft_model_paths = [\n",
    "    f\"models/{model_name_or_path}-epoch3-zhouyi_dataset_20240118_152413\",\n",
    "    f\"models/{model_name_or_path}-epoch3-zhouyi_dataset_20240118_163659\",\n",
    "    f\"models/{model_name_or_path}-epoch3-zhouyi_dataset_handmade\",\n",
    "    #can add more models for test\n",
    "]\n",
    "\n",
    "_compute_dtype_map = {\n",
    "    'fp32': torch.float32,\n",
    "    'fp16': torch.float16,\n",
    "    'bf16': torch.bfloat16\n",
    "}\n",
    "\n",
    "# init q_config（with 4bit）\n",
    "q_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=_compute_dtype_map['bf16']\n",
    ")\n",
    "\n",
    "# ======================\n",
    "# 2. load the base model\n",
    "# ======================\n",
    "\n",
    "print(f\"🔍 Loading the base model: {model_name_or_path} (not fine tuned)...\")\n",
    "base_model = AutoModel.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    quantization_config=q_config,\n",
    "    trust_remote_code=True,\n",
    "    device_map='auto',\n",
    "    revision='b098244'\n",
    ")\n",
    "base_model.requires_grad_(False)\n",
    "\n",
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True, revision='b098244')\n",
    "\n",
    "# ======================\n",
    "# 3. function to evaluate and compare the models\n",
    "# ======================\n",
    "def compare_chatglm_results(query, base_model, qlora_model, training_tag):\n",
    "    base_response, base_history = base_model.chat(tokenizer, query)\n",
    "\n",
    "    inputs = tokenizer(query, return_tensors=\"pt\").to(0)\n",
    "    ft_out = qlora_model.generate(**inputs, max_new_tokens=512)\n",
    "    ft_response = tokenizer.decode(ft_out[0], skip_special_tokens=True)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"📊 Comparing result for query: {query}\")\n",
    "    print(\"=\"*80)\n",
    "    #print(f\" 📝 Question：{query} \\\n",
    "    print(f\"📝Base model response:\\n{base_response} \\\n",
    "    \\n👉Fine tuned model ({training_tag}) response: \\n{ft_response}\")\n",
    "    #print(\"=\"*60)\n",
    "    return base_response, ft_response\n",
    "\n",
    "# ======================\n",
    "# 4. Evaluate and compare base model and peft model\n",
    "# ======================\n",
    "for peft_model_dir in peft_model_paths:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"🔍 Loading PEFT model from: {peft_model_dir}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        # Load the PEFT adapter with the base_model\n",
    "        config = PeftConfig.from_pretrained(peft_model_dir)\n",
    "        qlora_model = PeftModel.from_pretrained(base_model, peft_model_dir)\n",
    "        base_response, ft_response = compare_chatglm_results(\"解释下乾卦是什么？\", base_model, qlora_model, peft_model_dir)\n",
    "        base_response, ft_response = compare_chatglm_results(\"周易中的讼卦是什么\", base_model, qlora_model, peft_model_dir)\n",
    "        base_response, ft_response = compare_chatglm_results(\"师卦是什么？\", base_model, qlora_model, peft_model_dir)\n",
    "        base_response, ft_response = compare_chatglm_results(\"地水师卦是什么？\", base_model, qlora_model, peft_model_dir)\n",
    "        base_response, ft_response = compare_chatglm_results(\"天水讼卦\", base_model, qlora_model, peft_model_dir)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to load the model: {peft_model_dir} with error: {e}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0576c1a422c341f88ff6bf765e19882f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "097c6f83e8ef4ba08b8d872929979683": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_4b8f705761024b2c91f7e4d8598e5d52",
       "style": "IPY_MODEL_4176e2fa6ae947f2b4fda097cbd91912",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "0fc707c52fee4b198a371e4a73e0d05b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2359c7f1ec004001a7b22ae658e43299": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "268d605db027490cad432e508014aa3e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_d1d245a5adff4cf29170ecc5a41659c9",
        "IPY_MODEL_39fb305c768c46378b1760efe8432e73",
        "IPY_MODEL_43c13ec36e3044ef84f822968e2964d3"
       ],
       "layout": "IPY_MODEL_75824edf769f4cd99f1589613ed2868b"
      }
     },
     "3102855d954b466e80bbf1822f46dce7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_5c4c02b838874d9f939632032e76f4d0",
       "style": "IPY_MODEL_7c4025bdb0ec4ecaacd8401b49886613",
       "value": " 7/7 [00:05&lt;00:00,  1.37it/s]"
      }
     },
     "3536ee372c8e43a3886b582fd068f699": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "39bfebf8713844ddb2591dfa734d1034": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "39cc873fdd644943ae1e87ebe6cf1383": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "39fb305c768c46378b1760efe8432e73": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_e89b536e97b44e8fbd97edd61e32b1c7",
       "max": 7,
       "style": "IPY_MODEL_ec6e1356f7c64bd293ee564bde7c7938",
       "value": 7
      }
     },
     "3a0bf8fccaff4581b334311e08f1c990": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4176e2fa6ae947f2b4fda097cbd91912": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "43c13ec36e3044ef84f822968e2964d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_842ffdfc3389439d8e0a71666e348a6b",
       "style": "IPY_MODEL_f00658453c8440c197747b9777b217a7",
       "value": " 7/7 [00:05&lt;00:00,  1.37it/s]"
      }
     },
     "44a5af6567fb46c9984c7bf1cc4368da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "4530b92ccad341e6a898bf008c5c5317": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4b8f705761024b2c91f7e4d8598e5d52": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4bca913c08b34c3497cb4208804269e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_8bd1e1a3a5c24b19b9aad8827b6f383c",
       "style": "IPY_MODEL_c6c0dabca3fd4b6ab4b612aad78f5bfd",
       "value": " 7/7 [00:05&lt;00:00,  1.28it/s]"
      }
     },
     "4c71c43319cd422a8b5c9be1b6f0f712": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4c76f991a3fa4d8cb2b563318fca777a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_a13c8dc8f03b4e4b8212e9297e1a8a82",
       "max": 7,
       "style": "IPY_MODEL_a2bb0f350e6b4123b291a844eee18614",
       "value": 7
      }
     },
     "5b555a9350ea46a9b23e1a6f063a32d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5c4369aa49704de98aa2cb37deba7c1c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_f6df7093f4724378b6f5c50f8944a725",
       "max": 7,
       "style": "IPY_MODEL_67a2f45389e147c7a21ca3152e2e2271",
       "value": 7
      }
     },
     "5c4c02b838874d9f939632032e76f4d0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5cf25613304a47988b300825366431bc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5d8476893ce2442d80a0a41da19c1e5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "60811dcd62c14e34b83e0111d68ec2f4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "62a472b89bd94294b42d7323332de4c2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_64917d22ab624211988d879762091343",
        "IPY_MODEL_96131c8ae67b42e48595c6cbbc3ddc43",
        "IPY_MODEL_3102855d954b466e80bbf1822f46dce7"
       ],
       "layout": "IPY_MODEL_4530b92ccad341e6a898bf008c5c5317"
      }
     },
     "64917d22ab624211988d879762091343": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_39bfebf8713844ddb2591dfa734d1034",
       "style": "IPY_MODEL_5b555a9350ea46a9b23e1a6f063a32d0",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "64b5cd77f9f941648c8dc1df927ad663": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "67a2f45389e147c7a21ca3152e2e2271": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "687f6d3ac6634444b8d2ebc1a45ffc42": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_af9f08c315464123ace14ee80007f4ed",
       "style": "IPY_MODEL_83aea87ac26f411793a1d8f111dde75a",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "6b6c96d6428f4aefbcd56bd178d8881e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6d757f0a3ad64e1a8f55ca3af9232b36": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "71d0d8a5857f4099a11097eb97ceda3e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_8d2e3fbd5f32429d93247b7e0a002b48",
       "style": "IPY_MODEL_74d8a676ba7240dd84a29f8af10bb80b",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "74d8a676ba7240dd84a29f8af10bb80b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "75824edf769f4cd99f1589613ed2868b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7c4025bdb0ec4ecaacd8401b49886613": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "83aea87ac26f411793a1d8f111dde75a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "842ffdfc3389439d8e0a71666e348a6b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8bd1e1a3a5c24b19b9aad8827b6f383c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8d2e3fbd5f32429d93247b7e0a002b48": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8e485dc7dd3142b69d4444e09f98cb75": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_6d757f0a3ad64e1a8f55ca3af9232b36",
       "max": 7,
       "style": "IPY_MODEL_5d8476893ce2442d80a0a41da19c1e5b",
       "value": 7
      }
     },
     "940749c3e7d449c69d8ce71caf648a41": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "96131c8ae67b42e48595c6cbbc3ddc43": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_60811dcd62c14e34b83e0111d68ec2f4",
       "max": 7,
       "style": "IPY_MODEL_44a5af6567fb46c9984c7bf1cc4368da",
       "value": 7
      }
     },
     "965a7cb70c9e48a08a0718abf249dd43": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_687f6d3ac6634444b8d2ebc1a45ffc42",
        "IPY_MODEL_8e485dc7dd3142b69d4444e09f98cb75",
        "IPY_MODEL_9a45aa0117844cfb98cd481baee1eadf"
       ],
       "layout": "IPY_MODEL_e87defdeaae54efd85c44bf4e64fc949"
      }
     },
     "9a45aa0117844cfb98cd481baee1eadf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_64b5cd77f9f941648c8dc1df927ad663",
       "style": "IPY_MODEL_0576c1a422c341f88ff6bf765e19882f",
       "value": " 7/7 [00:05&lt;00:00,  1.38it/s]"
      }
     },
     "a13c8dc8f03b4e4b8212e9297e1a8a82": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a2bb0f350e6b4123b291a844eee18614": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a6b9ffb6636044ecb41c602a7834fcdb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_5cf25613304a47988b300825366431bc",
       "max": 7,
       "style": "IPY_MODEL_940749c3e7d449c69d8ce71caf648a41",
       "value": 7
      }
     },
     "aa146911bb71405b8143965aa1720ea5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "af9f08c315464123ace14ee80007f4ed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bf2c5dcb272142968321bd2870712693": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c06f71261335456198fd9bc86625fe04": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c4849ecb1a8b4669a7cc4b785983efa8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_aa146911bb71405b8143965aa1720ea5",
       "style": "IPY_MODEL_3a0bf8fccaff4581b334311e08f1c990",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "c6c0dabca3fd4b6ab4b612aad78f5bfd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d1d245a5adff4cf29170ecc5a41659c9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_39cc873fdd644943ae1e87ebe6cf1383",
       "style": "IPY_MODEL_3536ee372c8e43a3886b582fd068f699",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "df25d981f6994fa2a4e006440f1a3af0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_71d0d8a5857f4099a11097eb97ceda3e",
        "IPY_MODEL_4c76f991a3fa4d8cb2b563318fca777a",
        "IPY_MODEL_f6d9990495554f0081176dc879b40518"
       ],
       "layout": "IPY_MODEL_c06f71261335456198fd9bc86625fe04"
      }
     },
     "e87defdeaae54efd85c44bf4e64fc949": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e89b536e97b44e8fbd97edd61e32b1c7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ec6e1356f7c64bd293ee564bde7c7938": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ede20c088f89468d99eb22ba12efd7d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_c4849ecb1a8b4669a7cc4b785983efa8",
        "IPY_MODEL_a6b9ffb6636044ecb41c602a7834fcdb",
        "IPY_MODEL_4bca913c08b34c3497cb4208804269e2"
       ],
       "layout": "IPY_MODEL_6b6c96d6428f4aefbcd56bd178d8881e"
      }
     },
     "f00658453c8440c197747b9777b217a7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f604f4549ffd462bb0607edbf76ddb4b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_2359c7f1ec004001a7b22ae658e43299",
       "style": "IPY_MODEL_0fc707c52fee4b198a371e4a73e0d05b",
       "value": " 7/7 [00:05&lt;00:00,  1.37it/s]"
      }
     },
     "f6d9990495554f0081176dc879b40518": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_bf2c5dcb272142968321bd2870712693",
       "style": "IPY_MODEL_4c71c43319cd422a8b5c9be1b6f0f712",
       "value": " 7/7 [00:05&lt;00:00,  1.43it/s]"
      }
     },
     "f6df7093f4724378b6f5c50f8944a725": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f6fbda0fbb6a4f5a8dff1e5dc799a987": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "faac7503f67f47caa61b8815b1cde157": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_097c6f83e8ef4ba08b8d872929979683",
        "IPY_MODEL_5c4369aa49704de98aa2cb37deba7c1c",
        "IPY_MODEL_f604f4549ffd462bb0607edbf76ddb4b"
       ],
       "layout": "IPY_MODEL_f6fbda0fbb6a4f5a8dff1e5dc799a987"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
